{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Hate Speech Detection using ML classifiers**"
      ],
      "metadata": {
        "id": "FmrsC_C8FqQW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ML classifiers vs Neural Network**"
      ],
      "metadata": {
        "id": "RkdTDsLSQipW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insatlling necesaary libraries"
      ],
      "metadata": {
        "id": "rDvnum5xRDjV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBLZGYS_B8Wf",
        "outputId": "23e1ebaa-cad5-4602-b01d-67ccdf3bc3b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-optimize in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.3.2)\n",
            "Requirement already satisfied: pyaml>=16.9 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (24.4.0)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.4.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (24.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.5.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-optimize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn\n",
        "!pip install seaborn\n",
        "!pip install xgboost\n",
        "!pip install lightgbm\n",
        "!pip install catboost\n",
        "!pip install scikit-optimize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiiFQZAHCM_y",
        "outputId": "ebc4459c-5784-43a0-a5d0-c2a30d85eb3e"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.1)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/lib/python3.10/dist-packages (from seaborn) (1.25.2)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from seaborn) (2.0.3)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.10/dist-packages (from seaborn) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.11.4)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (4.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.11.4)\n",
            "Requirement already satisfied: catboost in /usr/local/lib/python3.10/dist-packages (1.2.5)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.25.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.0.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.11.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.3.0)\n",
            "Requirement already satisfied: scikit-optimize in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.3.2)\n",
            "Requirement already satisfied: pyaml>=16.9 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (24.4.0)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.4.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (24.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas numpy seaborn matplotlib pycaret"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9O28n_zaChJf",
        "outputId": "763a72b5-7df5-4554-fa24-9ac9248a9034"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: pycaret in /usr/local/lib/python3.10/dist-packages (3.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: ipython>=5.5.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (7.34.0)\n",
            "Requirement already satisfied: ipywidgets>=7.6.5 in /usr/local/lib/python3.10/dist-packages (from pycaret) (7.7.1)\n",
            "Requirement already satisfied: tqdm>=4.62.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (4.66.4)\n",
            "Requirement already satisfied: jinja2>=3 in /usr/local/lib/python3.10/dist-packages (from pycaret) (3.1.4)\n",
            "Requirement already satisfied: scipy<=1.11.4,>=1.6.1 in /usr/local/lib/python3.10/dist-packages (from pycaret) (1.11.4)\n",
            "Requirement already satisfied: joblib<1.4,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (1.3.2)\n",
            "Requirement already satisfied: scikit-learn>1.4.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (1.4.2)\n",
            "Requirement already satisfied: pyod>=1.1.3 in /usr/local/lib/python3.10/dist-packages (from pycaret) (1.1.3)\n",
            "Requirement already satisfied: imbalanced-learn>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (0.12.2)\n",
            "Requirement already satisfied: category-encoders>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (2.6.3)\n",
            "Requirement already satisfied: lightgbm>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (4.1.0)\n",
            "Requirement already satisfied: numba>=0.55.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (0.58.1)\n",
            "Requirement already satisfied: requests>=2.27.1 in /usr/local/lib/python3.10/dist-packages (from pycaret) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.9.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (5.9.5)\n",
            "Requirement already satisfied: markupsafe>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from pycaret) (2.1.5)\n",
            "Requirement already satisfied: importlib-metadata>=4.12.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (7.1.0)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (5.10.4)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from pycaret) (2.2.1)\n",
            "Requirement already satisfied: deprecation>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (2.1.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from pycaret) (3.4.1)\n",
            "Requirement already satisfied: scikit-plot>=0.3.7 in /usr/local/lib/python3.10/dist-packages (from pycaret) (0.3.7)\n",
            "Requirement already satisfied: yellowbrick>=1.4 in /usr/local/lib/python3.10/dist-packages (from pycaret) (1.5)\n",
            "Requirement already satisfied: plotly>=5.14.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (5.15.0)\n",
            "Requirement already satisfied: kaleido>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from pycaret) (0.2.1)\n",
            "Requirement already satisfied: schemdraw==0.15 in /usr/local/lib/python3.10/dist-packages (from pycaret) (0.15)\n",
            "Requirement already satisfied: plotly-resampler>=0.8.3.1 in /usr/local/lib/python3.10/dist-packages (from pycaret) (0.10.0)\n",
            "Requirement already satisfied: statsmodels>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from pycaret) (0.14.2)\n",
            "Requirement already satisfied: sktime==0.26.0 in /usr/local/lib/python3.10/dist-packages (from pycaret) (0.26.0)\n",
            "Requirement already satisfied: tbats>=1.1.3 in /usr/local/lib/python3.10/dist-packages (from pycaret) (1.1.3)\n",
            "Requirement already satisfied: pmdarima>=2.0.4 in /usr/local/lib/python3.10/dist-packages (from pycaret) (2.0.4)\n",
            "Requirement already satisfied: wurlitzer in /usr/local/lib/python3.10/dist-packages (from pycaret) (3.1.0)\n",
            "Requirement already satisfied: scikit-base<0.8.0 in /usr/local/lib/python3.10/dist-packages (from sktime==0.26.0->pycaret) (0.7.8)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.10/dist-packages (from category-encoders>=2.4.0->pycaret) (0.5.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn>=0.12.0->pycaret) (3.5.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.12.0->pycaret) (3.18.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret) (67.7.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.5.0->pycaret) (4.9.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.6.5->pycaret) (5.5.6)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.6.5->pycaret) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.6.5->pycaret) (3.6.6)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.6.5->pycaret) (3.0.10)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat>=4.2.0->pycaret) (2.19.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=4.2.0->pycaret) (4.19.2)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from nbformat>=4.2.0->pycaret) (5.7.2)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.55.0->pycaret) (0.41.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=5.14.0->pycaret) (8.3.0)\n",
            "Requirement already satisfied: dash>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from plotly-resampler>=0.8.3.1->pycaret) (2.17.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from plotly-resampler>=0.8.3.1->pycaret) (3.10.3)\n",
            "Requirement already satisfied: tsdownsample>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from plotly-resampler>=0.8.3.1->pycaret) (0.1.3)\n",
            "Requirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in /usr/local/lib/python3.10/dist-packages (from pmdarima>=2.0.4->pycaret) (3.0.10)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from pmdarima>=2.0.4->pycaret) (2.0.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from pyod>=1.1.3->pycaret) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->pycaret) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->pycaret) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->pycaret) (2024.2.2)\n",
            "Requirement already satisfied: Flask<3.1,>=1.0.4 in /usr/local/lib/python3.10/dist-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (2.2.5)\n",
            "Requirement already satisfied: Werkzeug<3.1 in /usr/local/lib/python3.10/dist-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (3.0.3)\n",
            "Requirement already satisfied: dash-html-components==2.0.0 in /usr/local/lib/python3.10/dist-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (2.0.0)\n",
            "Requirement already satisfied: dash-core-components==2.0.0 in /usr/local/lib/python3.10/dist-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (2.0.0)\n",
            "Requirement already satisfied: dash-table==5.0.0 in /usr/local/lib/python3.10/dist-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (5.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (4.11.0)\n",
            "Requirement already satisfied: retrying in /usr/local/lib/python3.10/dist-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (1.3.4)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (1.6.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.5->pycaret) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.5->pycaret) (6.3.3)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.5.0->pycaret) (0.8.4)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret) (0.18.1)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=4.2.0->pycaret) (4.2.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.5.0->pycaret) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.5.0->pycaret) (0.2.13)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (6.5.5)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (2.2.0)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (8.1.7)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (24.0.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (23.1.0)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (6.5.4)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.20.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.0.0)\n",
            "Requirement already satisfied: jupyter-server>=1.8 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.24.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.2.4)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (4.9.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (4.12.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.3.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.10.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.3.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (21.2.0)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.8.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (2.5)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.5.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.2.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (2.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cloning the source git"
      ],
      "metadata": {
        "id": "rZpoFn27RI1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/danushkhanna/iNeuron.ai-Phishing-Domain-Detection.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5TFNiABCvvo",
        "outputId": "035b7128-cbe8-402c-c875-1799314f7012"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'iNeuron.ai-Phishing-Domain-Detection' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the required libraries"
      ],
      "metadata": {
        "id": "woSWFeW3RNkC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sklearn\n",
        "import sklearn.model_selection\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "tNPX6c6sC02b"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgbm\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from catboost import CatBoostClassifier"
      ],
      "metadata": {
        "id": "XFA5-fbeC4Pq"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skopt import gp_minimize\n",
        "from skopt.space import Real, Integer\n",
        "from skopt.utils import use_named_args\n",
        "from skopt.plots import plot_convergence\n",
        "\n",
        "import seaborn as sns\n",
        "sns.set_style(\"darkgrid\")\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "WCu74VfLC7n3"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "from pycaret.classification import *"
      ],
      "metadata": {
        "id": "uqOdhxvWC8k0"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Hate Speech Detection dataset**"
      ],
      "metadata": {
        "id": "6h5pcw1BRW1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPBjhZX1C_lk",
        "outputId": "4b8c51a4-6434-4b8d-89ff-540b728a401b"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1=pd.read_csv('/content/drive/MyDrive/Colab Notebooks/CONAN_Dataset - CONAN_English_RewardTest.csv')\n",
        "df2=pd.read_csv('/content/drive/MyDrive/Colab Notebooks/CONAN_Dataset - CONAN_English_RewardTrain.csv')\n",
        "df2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "L-ROGajtDR1O",
        "outputId": "821beea8-bafe-4141-e98c-3c4f9e02766d"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 speech  class\n",
              "0     The Arabs want to impose their religion and to...      0\n",
              "1     The Arabs are all terrorists and they want to ...      0\n",
              "2     It's a shame that there is no longer the cruci...      0\n",
              "3     Then we must castrate even Italians who rape, ...      1\n",
              "4     The Arabs do not want to impose their religion...      1\n",
              "...                                                 ...    ...\n",
              "1495  What is your problem with Muslims? They are pe...      1\n",
              "1496  Did you know that the only terrorist attacks i...      1\n",
              "1497  The Arabs want to impose their religion and to...      0\n",
              "1498           A real Islamic invasion is taking place.      0\n",
              "1499  Hi, I also condemn these acts that are so atro...      1\n",
              "\n",
              "[1500 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4c4d92b3-b179-460a-8a6c-d14d4285638b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>speech</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The Arabs want to impose their religion and to...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The Arabs are all terrorists and they want to ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>It's a shame that there is no longer the cruci...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Then we must castrate even Italians who rape, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The Arabs do not want to impose their religion...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1495</th>\n",
              "      <td>What is your problem with Muslims? They are pe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1496</th>\n",
              "      <td>Did you know that the only terrorist attacks i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1497</th>\n",
              "      <td>The Arabs want to impose their religion and to...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1498</th>\n",
              "      <td>A real Islamic invasion is taking place.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1499</th>\n",
              "      <td>Hi, I also condemn these acts that are so atro...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1500 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4c4d92b3-b179-460a-8a6c-d14d4285638b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4c4d92b3-b179-460a-8a6c-d14d4285638b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4c4d92b3-b179-460a-8a6c-d14d4285638b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d910cc2f-5d7a-4b96-97fa-095b2098ef32\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d910cc2f-5d7a-4b96-97fa-095b2098ef32')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d910cc2f-5d7a-4b96-97fa-095b2098ef32 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_35df3c43-f8b1-4d7a-bac8-9f3ece06ddc0\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df2')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_35df3c43-f8b1-4d7a-bac8-9f3ece06ddc0 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df2');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df2",
              "summary": "{\n  \"name\": \"df2\",\n  \"rows\": 1500,\n  \"fields\": [\n    {\n      \"column\": \"speech\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 786,\n        \"samples\": [\n          \"Tolerance of others' religions must be mutual. You cannot convict a person based on his faith.\",\n          \"There are also many Italian Muslims why we stop them from practising their beliefs? Why we give this opportunity only to Catholics? Why mosques bother you? And then I assure you that the number of mosques is negligible compared to the number of Catholic churches.\",\n          \"The problem lies in having a more open, secular and human mentality without blinders.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "axfZRrUyDfZK",
        "outputId": "47a16605-3cbe-4b39-b04e-d8b6bd425fe7"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              speech  class\n",
              "0  The Arabs want to impose their religion and to...      0\n",
              "1  The Arabs are all terrorists and they want to ...      0\n",
              "2  It's a shame that there is no longer the cruci...      0\n",
              "3  Then we must castrate even Italians who rape, ...      1\n",
              "4  The Arabs do not want to impose their religion...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9dd7b9c0-9b55-4b43-80e3-429be31c0a14\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>speech</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The Arabs want to impose their religion and to...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The Arabs are all terrorists and they want to ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>It's a shame that there is no longer the cruci...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Then we must castrate even Italians who rape, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The Arabs do not want to impose their religion...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9dd7b9c0-9b55-4b43-80e3-429be31c0a14')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9dd7b9c0-9b55-4b43-80e3-429be31c0a14 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9dd7b9c0-9b55-4b43-80e3-429be31c0a14');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0c7deb27-a28b-4b56-872a-c5841e3a7501\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0c7deb27-a28b-4b56-872a-c5841e3a7501')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0c7deb27-a28b-4b56-872a-c5841e3a7501 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df2",
              "summary": "{\n  \"name\": \"df2\",\n  \"rows\": 1500,\n  \"fields\": [\n    {\n      \"column\": \"speech\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 786,\n        \"samples\": [\n          \"Tolerance of others' religions must be mutual. You cannot convict a person based on his faith.\",\n          \"There are also many Italian Muslims why we stop them from practising their beliefs? Why we give this opportunity only to Catholics? Why mosques bother you? And then I assure you that the number of mosques is negligible compared to the number of Catholic churches.\",\n          \"The problem lies in having a more open, secular and human mentality without blinders.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df2.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8lcc6JCDiZd",
        "outputId": "a94d0dbe-b4c1-4ddc-858b-b49785d3cd43"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             class\n",
            "count  1500.000000\n",
            "mean      0.600667\n",
            "std       0.489925\n",
            "min       0.000000\n",
            "25%       0.000000\n",
            "50%       1.000000\n",
            "75%       1.000000\n",
            "max       1.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SETTING UP THE DATA FOR MODELLING\n",
        "\n",
        "setup(data=df2, target='class')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 725
        },
        "id": "6feDppxhEN7B",
        "outputId": "eb4c43ad-19f3-4b77-e106-a35db4e0f7e2"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7e7b8a64b8b0>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_69374_row8_col1 {\n",
              "  background-color: lightgreen;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_69374\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_69374_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
              "      <th id=\"T_69374_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_69374_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_69374_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
              "      <td id=\"T_69374_row0_col1\" class=\"data row0 col1\" >4889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_69374_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_69374_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
              "      <td id=\"T_69374_row1_col1\" class=\"data row1 col1\" >class</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_69374_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_69374_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
              "      <td id=\"T_69374_row2_col1\" class=\"data row2 col1\" >Binary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_69374_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_69374_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
              "      <td id=\"T_69374_row3_col1\" class=\"data row3 col1\" >(1500, 2)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_69374_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "      <td id=\"T_69374_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
              "      <td id=\"T_69374_row4_col1\" class=\"data row4 col1\" >(1500, 2)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_69374_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "      <td id=\"T_69374_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
              "      <td id=\"T_69374_row5_col1\" class=\"data row5 col1\" >(1050, 2)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_69374_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "      <td id=\"T_69374_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
              "      <td id=\"T_69374_row6_col1\" class=\"data row6 col1\" >(450, 2)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_69374_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "      <td id=\"T_69374_row7_col0\" class=\"data row7 col0\" >Categorical features</td>\n",
              "      <td id=\"T_69374_row7_col1\" class=\"data row7 col1\" >1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_69374_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
              "      <td id=\"T_69374_row8_col0\" class=\"data row8 col0\" >Preprocess</td>\n",
              "      <td id=\"T_69374_row8_col1\" class=\"data row8 col1\" >True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_69374_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
              "      <td id=\"T_69374_row9_col0\" class=\"data row9 col0\" >Imputation type</td>\n",
              "      <td id=\"T_69374_row9_col1\" class=\"data row9 col1\" >simple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_69374_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
              "      <td id=\"T_69374_row10_col0\" class=\"data row10 col0\" >Numeric imputation</td>\n",
              "      <td id=\"T_69374_row10_col1\" class=\"data row10 col1\" >mean</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_69374_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
              "      <td id=\"T_69374_row11_col0\" class=\"data row11 col0\" >Categorical imputation</td>\n",
              "      <td id=\"T_69374_row11_col1\" class=\"data row11 col1\" >mode</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_69374_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
              "      <td id=\"T_69374_row12_col0\" class=\"data row12 col0\" >Maximum one-hot encoding</td>\n",
              "      <td id=\"T_69374_row12_col1\" class=\"data row12 col1\" >25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_69374_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
              "      <td id=\"T_69374_row13_col0\" class=\"data row13 col0\" >Encoding method</td>\n",
              "      <td id=\"T_69374_row13_col1\" class=\"data row13 col1\" >None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_69374_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
              "      <td id=\"T_69374_row14_col0\" class=\"data row14 col0\" >Fold Generator</td>\n",
              "      <td id=\"T_69374_row14_col1\" class=\"data row14 col1\" >StratifiedKFold</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_69374_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
              "      <td id=\"T_69374_row15_col0\" class=\"data row15 col0\" >Fold Number</td>\n",
              "      <td id=\"T_69374_row15_col1\" class=\"data row15 col1\" >10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_69374_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
              "      <td id=\"T_69374_row16_col0\" class=\"data row16 col0\" >CPU Jobs</td>\n",
              "      <td id=\"T_69374_row16_col1\" class=\"data row16 col1\" >-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_69374_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
              "      <td id=\"T_69374_row17_col0\" class=\"data row17 col0\" >Use GPU</td>\n",
              "      <td id=\"T_69374_row17_col1\" class=\"data row17 col1\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_69374_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
              "      <td id=\"T_69374_row18_col0\" class=\"data row18 col0\" >Log Experiment</td>\n",
              "      <td id=\"T_69374_row18_col1\" class=\"data row18 col1\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_69374_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
              "      <td id=\"T_69374_row19_col0\" class=\"data row19 col0\" >Experiment Name</td>\n",
              "      <td id=\"T_69374_row19_col1\" class=\"data row19 col1\" >clf-default-name</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_69374_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
              "      <td id=\"T_69374_row20_col0\" class=\"data row20 col0\" >USI</td>\n",
              "      <td id=\"T_69374_row20_col1\" class=\"data row20 col1\" >6e94</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pycaret.classification.oop.ClassificationExperiment at 0x7e7b89cd5360>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preparing Data for Modeling-**"
      ],
      "metadata": {
        "id": "J958RiNumTXu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train= df2['speech']\n",
        "y_train= df2['class']"
      ],
      "metadata": {
        "id": "8Pi5UWoKEd3W"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test= df1['speech']\n",
        "y_test= df1['class']"
      ],
      "metadata": {
        "id": "oVW1Yl2zEoyb"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Assuming X_train is a pandas Series containing text data\n",
        "# Initialize TF-IDF vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Fit the vectorizer on the training data and transform it\n",
        "X_train = tfidf_vectorizer.fit_transform(X_train)\n",
        "\n",
        "# Transform the test data using the same vectorizer\n",
        "X_test = tfidf_vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "WomAXi9441Td"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tbNYkTUEuP0",
        "outputId": "7ff3ee81-b398-4518-f669-bf2c523a295e"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1500, 2246)\n",
            "(1500,)\n",
            "(301, 2246)\n",
            "(301,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a dictionary to store the results\n",
        "results = {}"
      ],
      "metadata": {
        "id": "y032q_2tE3PX"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Evaluating Various ML Models-**"
      ],
      "metadata": {
        "id": "_rxn1TFtmcEw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.Logistic regression-**"
      ],
      "metadata": {
        "id": "q7EqC_TPE_CW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "start_time = time.time()\n",
        "logistic = LogisticRegression()\n",
        "logistic.fit(X_train, y_train)\n",
        "y_pred = logistic.predict(X_test)\n",
        "\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "\n",
        "results['Logistic Regression'] = [accuracy_score(y_test, y_pred),\n",
        "                                  precision_score(y_test, y_pred, average='weighted'),\n",
        "                                  recall_score(y_test, y_pred, average='weighted'),\n",
        "                                  f1_score(y_test, y_pred, average='weighted'),\n",
        "                                  training_time]\n",
        "print(\"Accuracy:\", results['Logistic Regression'][0])\n",
        "print(\"Precision:\", results['Logistic Regression'][1])\n",
        "print(\"Recall:\", results['Logistic Regression'][2])\n",
        "print(\"F1-score:\", results['Logistic Regression'][3])\n",
        "print(\"Training Time:\", results['Logistic Regression'][4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjxAVURAE6Cf",
        "outputId": "0e40f645-bedf-445f-c655-b592bd0560b3"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8803986710963455\n",
            "Precision: 0.9035473154002786\n",
            "Recall: 0.8803986710963455\n",
            "F1-score: 0.8787125621362376\n",
            "Training Time: 0.032453060150146484\n",
            "CPU times: user 44.9 ms, sys: 831 Âµs, total: 45.8 ms\n",
            "Wall time: 56.7 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. K-Nearest Neighbors (KNN)**"
      ],
      "metadata": {
        "id": "thJBSMzpFBZb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "start_time = time.time()\n",
        "knn = KNeighborsClassifier()\n",
        "knn.fit(X_train, y_train)\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "\n",
        "results['K-Nearest Neighbors (KNN)'] = [accuracy_score(y_test, y_pred),\n",
        "                                  precision_score(y_test, y_pred, average='weighted'),\n",
        "                                  recall_score(y_test, y_pred, average='weighted'),\n",
        "                                  f1_score(y_test, y_pred, average='weighted'),\n",
        "                                  training_time]\n",
        "print(\"Accuracy:\", results['K-Nearest Neighbors (KNN)'][0])\n",
        "print(\"Precision:\", results['K-Nearest Neighbors (KNN)'][1])\n",
        "print(\"Recall:\", results['K-Nearest Neighbors (KNN)'][2])\n",
        "print(\"F1-score:\", results['K-Nearest Neighbors (KNN)'][3])\n",
        "print(\"Training Time:\", results['K-Nearest Neighbors (KNN)'][4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePCWQSiWE-MU",
        "outputId": "3a37ea25-badc-4c18-f66b-ab7a2af6a244"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9036544850498339\n",
            "Precision: 0.911707712931703\n",
            "Recall: 0.9036544850498339\n",
            "F1-score: 0.9032058745435307\n",
            "Training Time: 0.043700218200683594\n",
            "CPU times: user 59.1 ms, sys: 797 Âµs, total: 59.9 ms\n",
            "Wall time: 60.4 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Gaussian Naive Bayes (GaussianNB)**"
      ],
      "metadata": {
        "id": "cy3G5N9gFKM-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gnb = GaussianNB()\n",
        "\n",
        "# Train the classifier\n",
        "start_time = time.time()\n",
        "gnb.fit(X_train.toarray(), y_train)  # Convert sparse matrix to dense array\n",
        "training_time = time.time() - start_time\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = gnb.predict(X_test.toarray())  # Convert sparse matrix to dense array\n",
        "\n",
        "# Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"Training Time:\", training_time)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umEDxCYAFO56",
        "outputId": "0550f1fa-b696-45da-c7de-448edc6158ff"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.920265780730897\n",
            "Precision: 0.9312636040783594\n",
            "Recall: 0.920265780730897\n",
            "F1-score: 0.9197771351025491\n",
            "Training Time: 0.1601412296295166\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Decision Trees**"
      ],
      "metadata": {
        "id": "ynFNkD3zFRxX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "start_time = time.time()\n",
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(X_train, y_train)\n",
        "y_pred = dt.predict(X_test)\n",
        "\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "\n",
        "results['Decision Trees'] = [accuracy_score(y_test, y_pred),\n",
        "                                  precision_score(y_test, y_pred, average='weighted'),\n",
        "                                  recall_score(y_test, y_pred, average='weighted'),\n",
        "                                  f1_score(y_test, y_pred, average='weighted'),\n",
        "                                  training_time]\n",
        "print(\"Accuracy:\", results['Decision Trees'][0])\n",
        "print(\"Precision:\", results['Decision Trees'][1])\n",
        "print(\"Recall:\", results['Decision Trees'][2])\n",
        "print(\"F1-score:\", results['Decision Trees'][3])\n",
        "print(\"Training Time:\", results['Decision Trees'][4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpyN_LK-FQej",
        "outputId": "c1f7b197-5b20-4d8d-9270-3b692f29f539"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8604651162790697\n",
            "Precision: 0.8909883720930233\n",
            "Recall: 0.8604651162790697\n",
            "F1-score: 0.8577629225120046\n",
            "Training Time: 0.0764153003692627\n",
            "CPU times: user 76.8 ms, sys: 0 ns, total: 76.8 ms\n",
            "Wall time: 94.4 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Random Forest**"
      ],
      "metadata": {
        "id": "jH0Z2EmuFZ20"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "start_time = time.time()\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "\n",
        "results['Random Forest'] = [accuracy_score(y_test, y_pred),\n",
        "                                  precision_score(y_test, y_pred, average='weighted'),\n",
        "                                  recall_score(y_test, y_pred, average='weighted'),\n",
        "                                  f1_score(y_test, y_pred, average='weighted'),\n",
        "                                  training_time]\n",
        "print(\"Accuracy:\", results['Random Forest'][0])\n",
        "print(\"Precision:\", results['Random Forest'][1])\n",
        "print(\"Recall:\", results['Random Forest'][2])\n",
        "print(\"F1-score:\", results['Random Forest'][3])\n",
        "print(\"Training Time:\", results['Random Forest'][4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3vMlSWGFVuL",
        "outputId": "f3783b2a-9683-4175-dea2-9b62219e05a8"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8538205980066446\n",
            "Precision: 0.8869746891803952\n",
            "Recall: 0.8538205980066446\n",
            "F1-score: 0.8507043704447707\n",
            "Training Time: 0.6607911586761475\n",
            "CPU times: user 537 ms, sys: 0 ns, total: 537 ms\n",
            "Wall time: 672 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. Extra Trees**"
      ],
      "metadata": {
        "id": "INdeC4kgFcvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "start_time = time.time()\n",
        "et = ExtraTreesClassifier()\n",
        "et.fit(X_train, y_train)\n",
        "y_pred = et.predict(X_test)\n",
        "\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "\n",
        "results['Extra Trees'] = [accuracy_score(y_test, y_pred),\n",
        "                                  precision_score(y_test, y_pred, average='weighted'),\n",
        "                                  recall_score(y_test, y_pred, average='weighted'),\n",
        "                                  f1_score(y_test, y_pred, average='weighted'),\n",
        "                                  training_time]\n",
        "print(\"Accuracy:\", results['Extra Trees'][0])\n",
        "print(\"Precision:\", results['Extra Trees'][1])\n",
        "print(\"Recall:\", results['Extra Trees'][2])\n",
        "print(\"F1-score:\", results['Extra Trees'][3])\n",
        "print(\"Training Time:\", results['Extra Trees'][4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RV-BN4k6FeN1",
        "outputId": "2564875e-e5e0-45a6-e29a-f04603a8f8c5"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8538205980066446\n",
            "Precision: 0.8869746891803952\n",
            "Recall: 0.8538205980066446\n",
            "F1-score: 0.8507043704447707\n",
            "Training Time: 0.49945569038391113\n",
            "CPU times: user 493 ms, sys: 0 ns, total: 493 ms\n",
            "Wall time: 517 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. Support Vector Machines (SVM)**"
      ],
      "metadata": {
        "id": "hfOEyHCaFh6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "start_time = time.time()\n",
        "svm = SVC()\n",
        "svm.fit(X_train, y_train)\n",
        "y_pred = svm.predict(X_test)\n",
        "\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "\n",
        "results['Support Vector Machines'] = [accuracy_score(y_test, y_pred),\n",
        "                                  precision_score(y_test, y_pred, average='weighted'),\n",
        "                                  recall_score(y_test, y_pred, average='weighted'),\n",
        "                                  f1_score(y_test, y_pred, average='weighted'),\n",
        "                                  training_time]\n",
        "print(\"Accuracy:\", results['Support Vector Machines'][0])\n",
        "print(\"Precision:\", results['Support Vector Machines'][1])\n",
        "print(\"Recall:\", results['Support Vector Machines'][2])\n",
        "print(\"F1-score:\", results['Support Vector Machines'][3])\n",
        "print(\"Training Time:\", results['Support Vector Machines'][4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHqu1QAqFl2a",
        "outputId": "138efdd2-e7c2-42e8-bf94-21122ebab93c"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8538205980066446\n",
            "Precision: 0.8869746891803952\n",
            "Recall: 0.8538205980066446\n",
            "F1-score: 0.8507043704447707\n",
            "Training Time: 0.2669563293457031\n",
            "CPU times: user 250 ms, sys: 0 ns, total: 250 ms\n",
            "Wall time: 289 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8. Neural Network MLP (Multi-layer Perceptron)**"
      ],
      "metadata": {
        "id": "DCnM0mTuFqA_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "start_time = time.time()\n",
        "mlp = MLPClassifier()\n",
        "mlp.fit(X_train, y_train)\n",
        "y_pred = mlp.predict(X_test)\n",
        "\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "\n",
        "results['Neural Networks (Multi-layer Perceptron)'] = [accuracy_score(y_test, y_pred),\n",
        "                                  precision_score(y_test, y_pred, average='weighted'),\n",
        "                                  recall_score(y_test, y_pred, average='weighted'),\n",
        "                                  f1_score(y_test, y_pred, average='weighted'),\n",
        "                                  training_time]\n",
        "print(\"Accuracy:\", results['Neural Networks (Multi-layer Perceptron)'][0])\n",
        "print(\"Precision:\", results['Neural Networks (Multi-layer Perceptron)'][1])\n",
        "print(\"Recall:\", results['Neural Networks (Multi-layer Perceptron)'][2])\n",
        "print(\"F1-score:\", results['Neural Networks (Multi-layer Perceptron)'][3])\n",
        "print(\"Training Time:\", results['Neural Networks (Multi-layer Perceptron)'][4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCySSmY2FpXg",
        "outputId": "8eb3926b-04f7-4c40-8fee-1ba1bfcd0730"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.893687707641196\n",
            "Precision: 0.9123799788251615\n",
            "Recall: 0.893687707641196\n",
            "F1-score: 0.8925112039149584\n",
            "Training Time: 5.046090841293335\n",
            "CPU times: user 3.86 s, sys: 3.01 s, total: 6.86 s\n",
            "Wall time: 5.06 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9. AdaBoost**"
      ],
      "metadata": {
        "id": "FURePsNQHBoX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "start_time = time.time()\n",
        "ada = AdaBoostClassifier()\n",
        "ada.fit(X_train, y_train)\n",
        "y_pred = ada.predict(X_test)\n",
        "\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "\n",
        "results['AdaBoost'] = [accuracy_score(y_test, y_pred),\n",
        "                                  precision_score(y_test, y_pred, average='weighted'),\n",
        "                                  recall_score(y_test, y_pred, average='weighted'),\n",
        "                                  f1_score(y_test, y_pred, average='weighted'),\n",
        "                                  training_time]\n",
        "print(\"Accuracy:\", results['AdaBoost'][0])\n",
        "print(\"Precision:\", results['AdaBoost'][1])\n",
        "print(\"Recall:\", results['AdaBoost'][2])\n",
        "print(\"F1-score:\", results['AdaBoost'][3])\n",
        "print(\"Training Time:\", results['AdaBoost'][4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E19VajPaHDoO",
        "outputId": "f616c362-f877-4472-b178-67355a515512"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8704318936877077\n",
            "Precision: 0.8971681695934187\n",
            "Recall: 0.8704318936877077\n",
            "F1-score: 0.8682781656175076\n",
            "Training Time: 0.6176362037658691\n",
            "CPU times: user 514 ms, sys: 29.5 ms, total: 544 ms\n",
            "Wall time: 632 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10. XGBoost**"
      ],
      "metadata": {
        "id": "Gel0ZJOQHTQw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "start_time = time.time()\n",
        "xgboost = xgb.XGBClassifier()\n",
        "xgboost.fit(X_train, y_train)\n",
        "y_pred = xgboost.predict(X_test)\n",
        "\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "\n",
        "results['XGBoost'] = [accuracy_score(y_test, y_pred),\n",
        "                                  precision_score(y_test, y_pred, average='weighted'),\n",
        "                                  recall_score(y_test, y_pred, average='weighted'),\n",
        "                                  f1_score(y_test, y_pred, average='weighted'),\n",
        "                                  training_time]\n",
        "print(\"Accuracy:\", results['XGBoost'][0])\n",
        "print(\"Precision:\", results['XGBoost'][1])\n",
        "print(\"Recall:\", results['XGBoost'][2])\n",
        "print(\"F1-score:\", results['XGBoost'][3])\n",
        "print(\"Training Time:\", results['XGBoost'][4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67t0JFLnHSkf",
        "outputId": "5231ff63-7f24-495e-91b6-55fd66317307"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8704318936877077\n",
            "Precision: 0.8971681695934187\n",
            "Recall: 0.8704318936877077\n",
            "F1-score: 0.8682781656175076\n",
            "Training Time: 6.069357872009277\n",
            "CPU times: user 4.13 s, sys: 0 ns, total: 4.13 s\n",
            "Wall time: 6.09 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**11. Light Gradient Boosting Machine (LGBM)**"
      ],
      "metadata": {
        "id": "KfG8dOHrJqSQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgbm\n",
        "\n",
        "# Initialize LightGBM classifier\n",
        "lgbm_classifier = lgbm.LGBMClassifier()\n",
        "\n",
        "# Train the classifier\n",
        "start_time = time.time()\n",
        "lgbm_classifier.fit(X_train, y_train)\n",
        "training_time = time.time() - start_time\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = lgbm_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"Training Time:\", training_time)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KsKHaGYJpWF",
        "outputId": "55355466-7ff3-4881-e08c-4da7fdf99528"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 901, number of negative: 599\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004650 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4542\n",
            "[LightGBM] [Info] Number of data points in the train set: 1500, number of used features: 202\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.600667 -> initscore=0.408244\n",
            "[LightGBM] [Info] Start training from score 0.408244\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Accuracy: 0.867109634551495\n",
            "Precision: 0.8950865535932856\n",
            "Recall: 0.867109634551495\n",
            "F1-score: 0.8647824121660026\n",
            "Training Time: 0.38364100456237793\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**12. CatBoost**"
      ],
      "metadata": {
        "id": "EUWWiKAeJ25H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "start_time = time.time()\n",
        "cat = CatBoostClassifier()\n",
        "cat.fit(X_train, y_train)\n",
        "y_pred = cat.predict(X_test)\n",
        "\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "\n",
        "results['CatBoost'] = [accuracy_score(y_test, y_pred),\n",
        "                                  precision_score(y_test, y_pred, average='weighted'),\n",
        "                                  recall_score(y_test, y_pred, average='weighted'),\n",
        "                                  f1_score(y_test, y_pred, average='weighted'),\n",
        "                                  training_time]\n",
        "print(\"Accuracy:\", results['CatBoost'][0])\n",
        "print(\"Precision:\", results['CatBoost'][1])\n",
        "print(\"Recall:\", results['CatBoost'][2])\n",
        "print(\"F1-score:\", results['CatBoost'][3])\n",
        "print(\"Training Time:\", results['CatBoost'][4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ymFpkSEJ5dv",
        "outputId": "242318f1-7d75-4305-c5f5-5a9a70b7aa42"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate set to 0.01225\n",
            "0:\tlearn: 0.6810806\ttotal: 62.6ms\tremaining: 1m 2s\n",
            "1:\tlearn: 0.6701537\ttotal: 113ms\tremaining: 56.2s\n",
            "2:\tlearn: 0.6571809\ttotal: 203ms\tremaining: 1m 7s\n",
            "3:\tlearn: 0.6463226\ttotal: 286ms\tremaining: 1m 11s\n",
            "4:\tlearn: 0.6324722\ttotal: 338ms\tremaining: 1m 7s\n",
            "5:\tlearn: 0.6234640\ttotal: 394ms\tremaining: 1m 5s\n",
            "6:\tlearn: 0.6152077\ttotal: 463ms\tremaining: 1m 5s\n",
            "7:\tlearn: 0.6047809\ttotal: 503ms\tremaining: 1m 2s\n",
            "8:\tlearn: 0.5921031\ttotal: 544ms\tremaining: 59.9s\n",
            "9:\tlearn: 0.5843081\ttotal: 587ms\tremaining: 58.1s\n",
            "10:\tlearn: 0.5726262\ttotal: 621ms\tremaining: 55.8s\n",
            "11:\tlearn: 0.5643372\ttotal: 682ms\tremaining: 56.2s\n",
            "12:\tlearn: 0.5577445\ttotal: 773ms\tremaining: 58.7s\n",
            "13:\tlearn: 0.5492630\ttotal: 831ms\tremaining: 58.5s\n",
            "14:\tlearn: 0.5406030\ttotal: 918ms\tremaining: 1m\n",
            "15:\tlearn: 0.5334646\ttotal: 979ms\tremaining: 1m\n",
            "16:\tlearn: 0.5260592\ttotal: 1.06s\tremaining: 1m 1s\n",
            "17:\tlearn: 0.5160168\ttotal: 1.15s\tremaining: 1m 2s\n",
            "18:\tlearn: 0.5055446\ttotal: 1.24s\tremaining: 1m 4s\n",
            "19:\tlearn: 0.4994996\ttotal: 1.36s\tremaining: 1m 6s\n",
            "20:\tlearn: 0.4927043\ttotal: 1.48s\tremaining: 1m 9s\n",
            "21:\tlearn: 0.4851101\ttotal: 1.51s\tremaining: 1m 7s\n",
            "22:\tlearn: 0.4788551\ttotal: 1.55s\tremaining: 1m 5s\n",
            "23:\tlearn: 0.4727389\ttotal: 1.61s\tremaining: 1m 5s\n",
            "24:\tlearn: 0.4645408\ttotal: 1.67s\tremaining: 1m 4s\n",
            "25:\tlearn: 0.4575083\ttotal: 1.74s\tremaining: 1m 5s\n",
            "26:\tlearn: 0.4468580\ttotal: 1.82s\tremaining: 1m 5s\n",
            "27:\tlearn: 0.4397846\ttotal: 1.86s\tremaining: 1m 4s\n",
            "28:\tlearn: 0.4346788\ttotal: 1.91s\tremaining: 1m 3s\n",
            "29:\tlearn: 0.4274945\ttotal: 1.97s\tremaining: 1m 3s\n",
            "30:\tlearn: 0.4216115\ttotal: 2.03s\tremaining: 1m 3s\n",
            "31:\tlearn: 0.4140000\ttotal: 2.09s\tremaining: 1m 3s\n",
            "32:\tlearn: 0.4071219\ttotal: 2.14s\tremaining: 1m 2s\n",
            "33:\tlearn: 0.4034946\ttotal: 2.22s\tremaining: 1m 3s\n",
            "34:\tlearn: 0.3987041\ttotal: 2.3s\tremaining: 1m 3s\n",
            "35:\tlearn: 0.3952557\ttotal: 2.38s\tremaining: 1m 3s\n",
            "36:\tlearn: 0.3907685\ttotal: 2.47s\tremaining: 1m 4s\n",
            "37:\tlearn: 0.3858030\ttotal: 2.53s\tremaining: 1m 4s\n",
            "38:\tlearn: 0.3801329\ttotal: 2.59s\tremaining: 1m 3s\n",
            "39:\tlearn: 0.3754808\ttotal: 2.67s\tremaining: 1m 3s\n",
            "40:\tlearn: 0.3704369\ttotal: 2.71s\tremaining: 1m 3s\n",
            "41:\tlearn: 0.3663734\ttotal: 2.76s\tremaining: 1m 2s\n",
            "42:\tlearn: 0.3624142\ttotal: 2.83s\tremaining: 1m 2s\n",
            "43:\tlearn: 0.3572405\ttotal: 2.87s\tremaining: 1m 2s\n",
            "44:\tlearn: 0.3523054\ttotal: 2.93s\tremaining: 1m 2s\n",
            "45:\tlearn: 0.3484798\ttotal: 2.99s\tremaining: 1m 1s\n",
            "46:\tlearn: 0.3450678\ttotal: 3.04s\tremaining: 1m 1s\n",
            "47:\tlearn: 0.3416664\ttotal: 3.1s\tremaining: 1m 1s\n",
            "48:\tlearn: 0.3381269\ttotal: 3.15s\tremaining: 1m 1s\n",
            "49:\tlearn: 0.3337103\ttotal: 3.22s\tremaining: 1m 1s\n",
            "50:\tlearn: 0.3300990\ttotal: 3.27s\tremaining: 1m\n",
            "51:\tlearn: 0.3251562\ttotal: 3.35s\tremaining: 1m 1s\n",
            "52:\tlearn: 0.3210438\ttotal: 3.4s\tremaining: 1m\n",
            "53:\tlearn: 0.3177520\ttotal: 3.47s\tremaining: 1m\n",
            "54:\tlearn: 0.3150415\ttotal: 3.52s\tremaining: 1m\n",
            "55:\tlearn: 0.3117218\ttotal: 3.58s\tremaining: 1m\n",
            "56:\tlearn: 0.3076716\ttotal: 3.64s\tremaining: 1m\n",
            "57:\tlearn: 0.3033684\ttotal: 3.7s\tremaining: 1m\n",
            "58:\tlearn: 0.3001569\ttotal: 3.74s\tremaining: 59.6s\n",
            "59:\tlearn: 0.2962988\ttotal: 3.78s\tremaining: 59.3s\n",
            "60:\tlearn: 0.2938340\ttotal: 3.84s\tremaining: 59.1s\n",
            "61:\tlearn: 0.2896705\ttotal: 3.9s\tremaining: 58.9s\n",
            "62:\tlearn: 0.2876744\ttotal: 3.97s\tremaining: 59s\n",
            "63:\tlearn: 0.2850324\ttotal: 4.03s\tremaining: 59s\n",
            "64:\tlearn: 0.2827937\ttotal: 4.09s\tremaining: 58.8s\n",
            "65:\tlearn: 0.2802532\ttotal: 4.15s\tremaining: 58.7s\n",
            "66:\tlearn: 0.2771693\ttotal: 4.2s\tremaining: 58.5s\n",
            "67:\tlearn: 0.2747960\ttotal: 4.3s\tremaining: 59s\n",
            "68:\tlearn: 0.2722805\ttotal: 4.4s\tremaining: 59.4s\n",
            "69:\tlearn: 0.2705450\ttotal: 4.45s\tremaining: 59.1s\n",
            "70:\tlearn: 0.2683979\ttotal: 4.52s\tremaining: 59.1s\n",
            "71:\tlearn: 0.2663373\ttotal: 4.56s\tremaining: 58.7s\n",
            "72:\tlearn: 0.2641963\ttotal: 4.65s\tremaining: 59.1s\n",
            "73:\tlearn: 0.2622357\ttotal: 4.71s\tremaining: 59s\n",
            "74:\tlearn: 0.2597294\ttotal: 4.79s\tremaining: 59.1s\n",
            "75:\tlearn: 0.2578898\ttotal: 4.84s\tremaining: 58.9s\n",
            "76:\tlearn: 0.2557316\ttotal: 4.89s\tremaining: 58.7s\n",
            "77:\tlearn: 0.2535732\ttotal: 4.94s\tremaining: 58.5s\n",
            "78:\tlearn: 0.2511649\ttotal: 5s\tremaining: 58.2s\n",
            "79:\tlearn: 0.2490372\ttotal: 5.04s\tremaining: 58s\n",
            "80:\tlearn: 0.2475874\ttotal: 5.1s\tremaining: 57.9s\n",
            "81:\tlearn: 0.2453250\ttotal: 5.15s\tremaining: 57.7s\n",
            "82:\tlearn: 0.2431713\ttotal: 5.22s\tremaining: 57.6s\n",
            "83:\tlearn: 0.2414642\ttotal: 5.28s\tremaining: 57.6s\n",
            "84:\tlearn: 0.2397018\ttotal: 5.37s\tremaining: 57.8s\n",
            "85:\tlearn: 0.2380128\ttotal: 5.44s\tremaining: 57.8s\n",
            "86:\tlearn: 0.2355461\ttotal: 5.49s\tremaining: 57.7s\n",
            "87:\tlearn: 0.2339445\ttotal: 5.55s\tremaining: 57.5s\n",
            "88:\tlearn: 0.2320667\ttotal: 5.6s\tremaining: 57.3s\n",
            "89:\tlearn: 0.2306960\ttotal: 5.66s\tremaining: 57.2s\n",
            "90:\tlearn: 0.2287348\ttotal: 5.71s\tremaining: 57s\n",
            "91:\tlearn: 0.2271670\ttotal: 5.76s\tremaining: 56.9s\n",
            "92:\tlearn: 0.2255833\ttotal: 5.82s\tremaining: 56.8s\n",
            "93:\tlearn: 0.2228967\ttotal: 5.88s\tremaining: 56.7s\n",
            "94:\tlearn: 0.2204817\ttotal: 5.93s\tremaining: 56.5s\n",
            "95:\tlearn: 0.2188565\ttotal: 6s\tremaining: 56.5s\n",
            "96:\tlearn: 0.2168701\ttotal: 6.08s\tremaining: 56.6s\n",
            "97:\tlearn: 0.2149205\ttotal: 6.13s\tremaining: 56.4s\n",
            "98:\tlearn: 0.2128968\ttotal: 6.18s\tremaining: 56.3s\n",
            "99:\tlearn: 0.2115958\ttotal: 6.24s\tremaining: 56.2s\n",
            "100:\tlearn: 0.2096899\ttotal: 6.31s\tremaining: 56.2s\n",
            "101:\tlearn: 0.2081648\ttotal: 6.36s\tremaining: 56s\n",
            "102:\tlearn: 0.2057496\ttotal: 6.4s\tremaining: 55.7s\n",
            "103:\tlearn: 0.2046510\ttotal: 6.45s\tremaining: 55.6s\n",
            "104:\tlearn: 0.2032974\ttotal: 6.5s\tremaining: 55.4s\n",
            "105:\tlearn: 0.2018709\ttotal: 6.55s\tremaining: 55.2s\n",
            "106:\tlearn: 0.2006802\ttotal: 6.6s\tremaining: 55.1s\n",
            "107:\tlearn: 0.1996458\ttotal: 6.66s\tremaining: 55s\n",
            "108:\tlearn: 0.1984366\ttotal: 6.71s\tremaining: 54.8s\n",
            "109:\tlearn: 0.1972428\ttotal: 6.76s\tremaining: 54.7s\n",
            "110:\tlearn: 0.1956846\ttotal: 6.83s\tremaining: 54.7s\n",
            "111:\tlearn: 0.1944334\ttotal: 6.89s\tremaining: 54.6s\n",
            "112:\tlearn: 0.1931047\ttotal: 6.94s\tremaining: 54.5s\n",
            "113:\tlearn: 0.1920598\ttotal: 7s\tremaining: 54.4s\n",
            "114:\tlearn: 0.1909816\ttotal: 7.09s\tremaining: 54.6s\n",
            "115:\tlearn: 0.1899069\ttotal: 7.15s\tremaining: 54.5s\n",
            "116:\tlearn: 0.1887903\ttotal: 7.25s\tremaining: 54.8s\n",
            "117:\tlearn: 0.1868891\ttotal: 7.33s\tremaining: 54.8s\n",
            "118:\tlearn: 0.1860333\ttotal: 7.4s\tremaining: 54.8s\n",
            "119:\tlearn: 0.1847621\ttotal: 7.45s\tremaining: 54.6s\n",
            "120:\tlearn: 0.1836539\ttotal: 7.5s\tremaining: 54.5s\n",
            "121:\tlearn: 0.1819683\ttotal: 7.57s\tremaining: 54.5s\n",
            "122:\tlearn: 0.1806544\ttotal: 7.61s\tremaining: 54.3s\n",
            "123:\tlearn: 0.1799492\ttotal: 7.68s\tremaining: 54.3s\n",
            "124:\tlearn: 0.1788621\ttotal: 7.75s\tremaining: 54.3s\n",
            "125:\tlearn: 0.1780138\ttotal: 7.79s\tremaining: 54s\n",
            "126:\tlearn: 0.1769034\ttotal: 7.84s\tremaining: 53.9s\n",
            "127:\tlearn: 0.1755409\ttotal: 7.89s\tremaining: 53.7s\n",
            "128:\tlearn: 0.1747135\ttotal: 7.95s\tremaining: 53.7s\n",
            "129:\tlearn: 0.1735129\ttotal: 8.01s\tremaining: 53.6s\n",
            "130:\tlearn: 0.1717475\ttotal: 8.07s\tremaining: 53.5s\n",
            "131:\tlearn: 0.1708554\ttotal: 8.14s\tremaining: 53.6s\n",
            "132:\tlearn: 0.1699565\ttotal: 8.19s\tremaining: 53.4s\n",
            "133:\tlearn: 0.1690206\ttotal: 8.24s\tremaining: 53.2s\n",
            "134:\tlearn: 0.1685235\ttotal: 8.31s\tremaining: 53.3s\n",
            "135:\tlearn: 0.1678544\ttotal: 8.36s\tremaining: 53.1s\n",
            "136:\tlearn: 0.1671513\ttotal: 8.44s\tremaining: 53.2s\n",
            "137:\tlearn: 0.1659896\ttotal: 8.5s\tremaining: 53.1s\n",
            "138:\tlearn: 0.1651701\ttotal: 8.56s\tremaining: 53s\n",
            "139:\tlearn: 0.1644083\ttotal: 8.63s\tremaining: 53s\n",
            "140:\tlearn: 0.1633626\ttotal: 8.7s\tremaining: 53s\n",
            "141:\tlearn: 0.1628158\ttotal: 8.76s\tremaining: 52.9s\n",
            "142:\tlearn: 0.1618338\ttotal: 8.81s\tremaining: 52.8s\n",
            "143:\tlearn: 0.1611457\ttotal: 8.86s\tremaining: 52.7s\n",
            "144:\tlearn: 0.1605723\ttotal: 8.91s\tremaining: 52.6s\n",
            "145:\tlearn: 0.1591413\ttotal: 8.99s\tremaining: 52.6s\n",
            "146:\tlearn: 0.1580314\ttotal: 9.07s\tremaining: 52.6s\n",
            "147:\tlearn: 0.1571600\ttotal: 9.15s\tremaining: 52.7s\n",
            "148:\tlearn: 0.1562363\ttotal: 9.22s\tremaining: 52.7s\n",
            "149:\tlearn: 0.1556541\ttotal: 9.29s\tremaining: 52.7s\n",
            "150:\tlearn: 0.1549037\ttotal: 9.41s\tremaining: 52.9s\n",
            "151:\tlearn: 0.1542719\ttotal: 9.54s\tremaining: 53.2s\n",
            "152:\tlearn: 0.1536540\ttotal: 9.63s\tremaining: 53.3s\n",
            "153:\tlearn: 0.1527407\ttotal: 9.71s\tremaining: 53.4s\n",
            "154:\tlearn: 0.1519826\ttotal: 9.8s\tremaining: 53.4s\n",
            "155:\tlearn: 0.1513093\ttotal: 9.89s\tremaining: 53.5s\n",
            "156:\tlearn: 0.1505349\ttotal: 9.98s\tremaining: 53.6s\n",
            "157:\tlearn: 0.1498628\ttotal: 10.1s\tremaining: 53.6s\n",
            "158:\tlearn: 0.1489728\ttotal: 10.1s\tremaining: 53.6s\n",
            "159:\tlearn: 0.1481000\ttotal: 10.2s\tremaining: 53.7s\n",
            "160:\tlearn: 0.1473430\ttotal: 10.3s\tremaining: 53.9s\n",
            "161:\tlearn: 0.1466378\ttotal: 10.4s\tremaining: 54s\n",
            "162:\tlearn: 0.1460479\ttotal: 10.5s\tremaining: 54.1s\n",
            "163:\tlearn: 0.1455275\ttotal: 10.6s\tremaining: 54.1s\n",
            "164:\tlearn: 0.1449365\ttotal: 10.7s\tremaining: 54.1s\n",
            "165:\tlearn: 0.1439712\ttotal: 10.8s\tremaining: 54.2s\n",
            "166:\tlearn: 0.1432015\ttotal: 10.9s\tremaining: 54.2s\n",
            "167:\tlearn: 0.1425996\ttotal: 10.9s\tremaining: 54.1s\n",
            "168:\tlearn: 0.1419977\ttotal: 11s\tremaining: 54.1s\n",
            "169:\tlearn: 0.1412961\ttotal: 11.1s\tremaining: 54s\n",
            "170:\tlearn: 0.1406599\ttotal: 11.2s\tremaining: 54.1s\n",
            "171:\tlearn: 0.1401003\ttotal: 11.3s\tremaining: 54.3s\n",
            "172:\tlearn: 0.1395329\ttotal: 11.4s\tremaining: 54.4s\n",
            "173:\tlearn: 0.1387863\ttotal: 11.5s\tremaining: 54.5s\n",
            "174:\tlearn: 0.1380932\ttotal: 11.6s\tremaining: 54.6s\n",
            "175:\tlearn: 0.1371749\ttotal: 11.7s\tremaining: 54.8s\n",
            "176:\tlearn: 0.1364871\ttotal: 11.8s\tremaining: 54.8s\n",
            "177:\tlearn: 0.1360343\ttotal: 11.8s\tremaining: 54.7s\n",
            "178:\tlearn: 0.1352974\ttotal: 11.9s\tremaining: 54.7s\n",
            "179:\tlearn: 0.1345932\ttotal: 12s\tremaining: 54.7s\n",
            "180:\tlearn: 0.1340329\ttotal: 12.1s\tremaining: 54.6s\n",
            "181:\tlearn: 0.1335569\ttotal: 12.2s\tremaining: 54.6s\n",
            "182:\tlearn: 0.1324631\ttotal: 12.3s\tremaining: 54.8s\n",
            "183:\tlearn: 0.1317575\ttotal: 12.4s\tremaining: 54.8s\n",
            "184:\tlearn: 0.1311888\ttotal: 12.5s\tremaining: 54.9s\n",
            "185:\tlearn: 0.1308135\ttotal: 12.5s\tremaining: 54.9s\n",
            "186:\tlearn: 0.1302432\ttotal: 12.6s\tremaining: 54.7s\n",
            "187:\tlearn: 0.1297638\ttotal: 12.7s\tremaining: 54.9s\n",
            "188:\tlearn: 0.1292138\ttotal: 12.8s\tremaining: 54.9s\n",
            "189:\tlearn: 0.1287481\ttotal: 12.9s\tremaining: 54.8s\n",
            "190:\tlearn: 0.1283651\ttotal: 12.9s\tremaining: 54.7s\n",
            "191:\tlearn: 0.1276737\ttotal: 13s\tremaining: 54.6s\n",
            "192:\tlearn: 0.1268485\ttotal: 13.1s\tremaining: 54.7s\n",
            "193:\tlearn: 0.1262810\ttotal: 13.2s\tremaining: 54.7s\n",
            "194:\tlearn: 0.1251794\ttotal: 13.3s\tremaining: 54.9s\n",
            "195:\tlearn: 0.1247976\ttotal: 13.4s\tremaining: 54.8s\n",
            "196:\tlearn: 0.1242280\ttotal: 13.5s\tremaining: 54.9s\n",
            "197:\tlearn: 0.1238642\ttotal: 13.6s\tremaining: 54.9s\n",
            "198:\tlearn: 0.1233500\ttotal: 13.6s\tremaining: 54.9s\n",
            "199:\tlearn: 0.1228191\ttotal: 13.8s\tremaining: 55.1s\n",
            "200:\tlearn: 0.1222307\ttotal: 13.8s\tremaining: 55.1s\n",
            "201:\tlearn: 0.1216517\ttotal: 13.9s\tremaining: 55.1s\n",
            "202:\tlearn: 0.1210001\ttotal: 14s\tremaining: 55.1s\n",
            "203:\tlearn: 0.1206626\ttotal: 14.1s\tremaining: 55.2s\n",
            "204:\tlearn: 0.1203225\ttotal: 14.3s\tremaining: 55.3s\n",
            "205:\tlearn: 0.1198608\ttotal: 14.4s\tremaining: 55.4s\n",
            "206:\tlearn: 0.1191292\ttotal: 14.5s\tremaining: 55.5s\n",
            "207:\tlearn: 0.1186016\ttotal: 14.6s\tremaining: 55.5s\n",
            "208:\tlearn: 0.1182060\ttotal: 14.7s\tremaining: 55.6s\n",
            "209:\tlearn: 0.1179915\ttotal: 14.8s\tremaining: 55.5s\n",
            "210:\tlearn: 0.1174849\ttotal: 14.8s\tremaining: 55.4s\n",
            "211:\tlearn: 0.1170825\ttotal: 14.9s\tremaining: 55.4s\n",
            "212:\tlearn: 0.1167616\ttotal: 15s\tremaining: 55.3s\n",
            "213:\tlearn: 0.1162446\ttotal: 15s\tremaining: 55.3s\n",
            "214:\tlearn: 0.1157821\ttotal: 15.1s\tremaining: 55.2s\n",
            "215:\tlearn: 0.1151754\ttotal: 15.1s\tremaining: 55s\n",
            "216:\tlearn: 0.1146644\ttotal: 15.2s\tremaining: 54.8s\n",
            "217:\tlearn: 0.1142588\ttotal: 15.3s\tremaining: 54.7s\n",
            "218:\tlearn: 0.1135680\ttotal: 15.3s\tremaining: 54.7s\n",
            "219:\tlearn: 0.1131555\ttotal: 15.4s\tremaining: 54.6s\n",
            "220:\tlearn: 0.1126546\ttotal: 15.4s\tremaining: 54.5s\n",
            "221:\tlearn: 0.1120365\ttotal: 15.5s\tremaining: 54.3s\n",
            "222:\tlearn: 0.1114132\ttotal: 15.5s\tremaining: 54.2s\n",
            "223:\tlearn: 0.1108453\ttotal: 15.6s\tremaining: 54s\n",
            "224:\tlearn: 0.1104149\ttotal: 15.7s\tremaining: 53.9s\n",
            "225:\tlearn: 0.1099535\ttotal: 15.7s\tremaining: 53.9s\n",
            "226:\tlearn: 0.1096361\ttotal: 15.8s\tremaining: 53.7s\n",
            "227:\tlearn: 0.1091704\ttotal: 15.8s\tremaining: 53.5s\n",
            "228:\tlearn: 0.1086169\ttotal: 15.8s\tremaining: 53.3s\n",
            "229:\tlearn: 0.1081346\ttotal: 15.9s\tremaining: 53.2s\n",
            "230:\tlearn: 0.1077653\ttotal: 15.9s\tremaining: 53s\n",
            "231:\tlearn: 0.1073155\ttotal: 16s\tremaining: 52.9s\n",
            "232:\tlearn: 0.1067054\ttotal: 16s\tremaining: 52.8s\n",
            "233:\tlearn: 0.1063659\ttotal: 16.1s\tremaining: 52.8s\n",
            "234:\tlearn: 0.1058857\ttotal: 16.2s\tremaining: 52.6s\n",
            "235:\tlearn: 0.1055838\ttotal: 16.2s\tremaining: 52.5s\n",
            "236:\tlearn: 0.1053180\ttotal: 16.3s\tremaining: 52.4s\n",
            "237:\tlearn: 0.1048589\ttotal: 16.3s\tremaining: 52.3s\n",
            "238:\tlearn: 0.1045272\ttotal: 16.4s\tremaining: 52.2s\n",
            "239:\tlearn: 0.1040704\ttotal: 16.5s\tremaining: 52.2s\n",
            "240:\tlearn: 0.1037995\ttotal: 16.5s\tremaining: 52.1s\n",
            "241:\tlearn: 0.1033539\ttotal: 16.6s\tremaining: 52s\n",
            "242:\tlearn: 0.1028797\ttotal: 16.7s\tremaining: 51.9s\n",
            "243:\tlearn: 0.1026042\ttotal: 16.7s\tremaining: 51.9s\n",
            "244:\tlearn: 0.1021716\ttotal: 16.8s\tremaining: 51.8s\n",
            "245:\tlearn: 0.1017706\ttotal: 16.8s\tremaining: 51.6s\n",
            "246:\tlearn: 0.1013759\ttotal: 16.9s\tremaining: 51.5s\n",
            "247:\tlearn: 0.1011114\ttotal: 17s\tremaining: 51.4s\n",
            "248:\tlearn: 0.1008008\ttotal: 17s\tremaining: 51.3s\n",
            "249:\tlearn: 0.1004180\ttotal: 17.1s\tremaining: 51.2s\n",
            "250:\tlearn: 0.1000110\ttotal: 17.1s\tremaining: 51.1s\n",
            "251:\tlearn: 0.0994798\ttotal: 17.2s\tremaining: 51s\n",
            "252:\tlearn: 0.0991876\ttotal: 17.2s\tremaining: 50.9s\n",
            "253:\tlearn: 0.0988481\ttotal: 17.3s\tremaining: 50.7s\n",
            "254:\tlearn: 0.0985397\ttotal: 17.3s\tremaining: 50.6s\n",
            "255:\tlearn: 0.0982679\ttotal: 17.4s\tremaining: 50.5s\n",
            "256:\tlearn: 0.0979872\ttotal: 17.4s\tremaining: 50.4s\n",
            "257:\tlearn: 0.0973932\ttotal: 17.5s\tremaining: 50.3s\n",
            "258:\tlearn: 0.0970994\ttotal: 17.5s\tremaining: 50.2s\n",
            "259:\tlearn: 0.0965984\ttotal: 17.6s\tremaining: 50.1s\n",
            "260:\tlearn: 0.0962781\ttotal: 17.6s\tremaining: 50s\n",
            "261:\tlearn: 0.0960764\ttotal: 17.7s\tremaining: 49.8s\n",
            "262:\tlearn: 0.0958651\ttotal: 17.7s\tremaining: 49.7s\n",
            "263:\tlearn: 0.0954406\ttotal: 17.8s\tremaining: 49.6s\n",
            "264:\tlearn: 0.0950108\ttotal: 17.9s\tremaining: 49.5s\n",
            "265:\tlearn: 0.0946630\ttotal: 17.9s\tremaining: 49.4s\n",
            "266:\tlearn: 0.0941982\ttotal: 18s\tremaining: 49.3s\n",
            "267:\tlearn: 0.0936982\ttotal: 18s\tremaining: 49.2s\n",
            "268:\tlearn: 0.0934173\ttotal: 18.1s\tremaining: 49.1s\n",
            "269:\tlearn: 0.0932191\ttotal: 18.1s\tremaining: 49s\n",
            "270:\tlearn: 0.0928822\ttotal: 18.2s\tremaining: 48.9s\n",
            "271:\tlearn: 0.0925370\ttotal: 18.2s\tremaining: 48.8s\n",
            "272:\tlearn: 0.0918414\ttotal: 18.3s\tremaining: 48.7s\n",
            "273:\tlearn: 0.0915646\ttotal: 18.3s\tremaining: 48.6s\n",
            "274:\tlearn: 0.0911812\ttotal: 18.4s\tremaining: 48.4s\n",
            "275:\tlearn: 0.0909205\ttotal: 18.4s\tremaining: 48.3s\n",
            "276:\tlearn: 0.0905200\ttotal: 18.4s\tremaining: 48.1s\n",
            "277:\tlearn: 0.0901549\ttotal: 18.5s\tremaining: 48s\n",
            "278:\tlearn: 0.0898747\ttotal: 18.5s\tremaining: 47.8s\n",
            "279:\tlearn: 0.0894327\ttotal: 18.6s\tremaining: 47.7s\n",
            "280:\tlearn: 0.0892184\ttotal: 18.6s\tremaining: 47.6s\n",
            "281:\tlearn: 0.0889086\ttotal: 18.6s\tremaining: 47.4s\n",
            "282:\tlearn: 0.0885739\ttotal: 18.7s\tremaining: 47.3s\n",
            "283:\tlearn: 0.0879689\ttotal: 18.8s\tremaining: 47.3s\n",
            "284:\tlearn: 0.0877502\ttotal: 18.9s\tremaining: 47.3s\n",
            "285:\tlearn: 0.0873342\ttotal: 18.9s\tremaining: 47.2s\n",
            "286:\tlearn: 0.0870125\ttotal: 19s\tremaining: 47.2s\n",
            "287:\tlearn: 0.0866301\ttotal: 19.1s\tremaining: 47.1s\n",
            "288:\tlearn: 0.0859020\ttotal: 19.1s\tremaining: 47.1s\n",
            "289:\tlearn: 0.0856397\ttotal: 19.2s\tremaining: 47.1s\n",
            "290:\tlearn: 0.0850570\ttotal: 19.3s\tremaining: 46.9s\n",
            "291:\tlearn: 0.0847555\ttotal: 19.3s\tremaining: 46.9s\n",
            "292:\tlearn: 0.0844902\ttotal: 19.4s\tremaining: 46.7s\n",
            "293:\tlearn: 0.0843482\ttotal: 19.4s\tremaining: 46.6s\n",
            "294:\tlearn: 0.0842471\ttotal: 19.5s\tremaining: 46.5s\n",
            "295:\tlearn: 0.0840965\ttotal: 19.5s\tremaining: 46.4s\n",
            "296:\tlearn: 0.0838353\ttotal: 19.6s\tremaining: 46.3s\n",
            "297:\tlearn: 0.0836711\ttotal: 19.6s\tremaining: 46.2s\n",
            "298:\tlearn: 0.0835282\ttotal: 19.7s\tremaining: 46.2s\n",
            "299:\tlearn: 0.0832892\ttotal: 19.7s\tremaining: 46.1s\n",
            "300:\tlearn: 0.0829893\ttotal: 19.8s\tremaining: 46s\n",
            "301:\tlearn: 0.0826781\ttotal: 19.9s\tremaining: 46s\n",
            "302:\tlearn: 0.0824332\ttotal: 19.9s\tremaining: 45.9s\n",
            "303:\tlearn: 0.0821298\ttotal: 20s\tremaining: 45.8s\n",
            "304:\tlearn: 0.0817964\ttotal: 20.1s\tremaining: 45.7s\n",
            "305:\tlearn: 0.0815205\ttotal: 20.1s\tremaining: 45.6s\n",
            "306:\tlearn: 0.0814082\ttotal: 20.2s\tremaining: 45.5s\n",
            "307:\tlearn: 0.0810802\ttotal: 20.2s\tremaining: 45.4s\n",
            "308:\tlearn: 0.0808374\ttotal: 20.3s\tremaining: 45.4s\n",
            "309:\tlearn: 0.0806685\ttotal: 20.4s\tremaining: 45.3s\n",
            "310:\tlearn: 0.0806032\ttotal: 20.4s\tremaining: 45.2s\n",
            "311:\tlearn: 0.0805005\ttotal: 20.5s\tremaining: 45.2s\n",
            "312:\tlearn: 0.0801213\ttotal: 20.5s\tremaining: 45.1s\n",
            "313:\tlearn: 0.0797696\ttotal: 20.6s\tremaining: 45s\n",
            "314:\tlearn: 0.0795991\ttotal: 20.7s\tremaining: 44.9s\n",
            "315:\tlearn: 0.0792366\ttotal: 20.7s\tremaining: 44.8s\n",
            "316:\tlearn: 0.0789259\ttotal: 20.7s\tremaining: 44.7s\n",
            "317:\tlearn: 0.0786566\ttotal: 20.8s\tremaining: 44.6s\n",
            "318:\tlearn: 0.0783571\ttotal: 20.8s\tremaining: 44.5s\n",
            "319:\tlearn: 0.0781988\ttotal: 20.9s\tremaining: 44.4s\n",
            "320:\tlearn: 0.0780016\ttotal: 20.9s\tremaining: 44.3s\n",
            "321:\tlearn: 0.0778645\ttotal: 21s\tremaining: 44.3s\n",
            "322:\tlearn: 0.0773153\ttotal: 21.1s\tremaining: 44.2s\n",
            "323:\tlearn: 0.0772324\ttotal: 21.2s\tremaining: 44.2s\n",
            "324:\tlearn: 0.0771522\ttotal: 21.3s\tremaining: 44.2s\n",
            "325:\tlearn: 0.0769093\ttotal: 21.4s\tremaining: 44.2s\n",
            "326:\tlearn: 0.0765624\ttotal: 21.4s\tremaining: 44.1s\n",
            "327:\tlearn: 0.0764775\ttotal: 21.5s\tremaining: 44.1s\n",
            "328:\tlearn: 0.0762988\ttotal: 21.5s\tremaining: 43.9s\n",
            "329:\tlearn: 0.0758448\ttotal: 21.6s\tremaining: 43.8s\n",
            "330:\tlearn: 0.0755213\ttotal: 21.7s\tremaining: 43.8s\n",
            "331:\tlearn: 0.0752144\ttotal: 21.7s\tremaining: 43.7s\n",
            "332:\tlearn: 0.0750917\ttotal: 21.8s\tremaining: 43.7s\n",
            "333:\tlearn: 0.0748373\ttotal: 21.9s\tremaining: 43.7s\n",
            "334:\tlearn: 0.0747834\ttotal: 22s\tremaining: 43.7s\n",
            "335:\tlearn: 0.0746179\ttotal: 22.1s\tremaining: 43.6s\n",
            "336:\tlearn: 0.0745540\ttotal: 22.2s\tremaining: 43.6s\n",
            "337:\tlearn: 0.0745088\ttotal: 22.2s\tremaining: 43.5s\n",
            "338:\tlearn: 0.0742493\ttotal: 22.3s\tremaining: 43.4s\n",
            "339:\tlearn: 0.0740167\ttotal: 22.3s\tremaining: 43.4s\n",
            "340:\tlearn: 0.0738826\ttotal: 22.4s\tremaining: 43.3s\n",
            "341:\tlearn: 0.0736402\ttotal: 22.4s\tremaining: 43.2s\n",
            "342:\tlearn: 0.0733863\ttotal: 22.5s\tremaining: 43.1s\n",
            "343:\tlearn: 0.0732982\ttotal: 22.6s\tremaining: 43s\n",
            "344:\tlearn: 0.0731592\ttotal: 22.7s\tremaining: 43s\n",
            "345:\tlearn: 0.0729377\ttotal: 22.8s\tremaining: 43s\n",
            "346:\tlearn: 0.0729000\ttotal: 22.8s\tremaining: 43s\n",
            "347:\tlearn: 0.0725604\ttotal: 22.9s\tremaining: 42.9s\n",
            "348:\tlearn: 0.0722969\ttotal: 23s\tremaining: 42.8s\n",
            "349:\tlearn: 0.0719395\ttotal: 23s\tremaining: 42.8s\n",
            "350:\tlearn: 0.0716748\ttotal: 23.1s\tremaining: 42.7s\n",
            "351:\tlearn: 0.0716270\ttotal: 23.2s\tremaining: 42.6s\n",
            "352:\tlearn: 0.0715730\ttotal: 23.2s\tremaining: 42.6s\n",
            "353:\tlearn: 0.0713408\ttotal: 23.3s\tremaining: 42.6s\n",
            "354:\tlearn: 0.0710840\ttotal: 23.4s\tremaining: 42.5s\n",
            "355:\tlearn: 0.0710251\ttotal: 23.5s\tremaining: 42.5s\n",
            "356:\tlearn: 0.0707964\ttotal: 23.5s\tremaining: 42.4s\n",
            "357:\tlearn: 0.0706609\ttotal: 23.6s\tremaining: 42.4s\n",
            "358:\tlearn: 0.0704559\ttotal: 23.7s\tremaining: 42.3s\n",
            "359:\tlearn: 0.0702014\ttotal: 23.7s\tremaining: 42.2s\n",
            "360:\tlearn: 0.0700810\ttotal: 23.8s\tremaining: 42.1s\n",
            "361:\tlearn: 0.0697853\ttotal: 23.9s\tremaining: 42.1s\n",
            "362:\tlearn: 0.0696338\ttotal: 23.9s\tremaining: 42s\n",
            "363:\tlearn: 0.0695837\ttotal: 24s\tremaining: 41.9s\n",
            "364:\tlearn: 0.0694563\ttotal: 24s\tremaining: 41.8s\n",
            "365:\tlearn: 0.0693176\ttotal: 24.1s\tremaining: 41.8s\n",
            "366:\tlearn: 0.0691982\ttotal: 24.2s\tremaining: 41.7s\n",
            "367:\tlearn: 0.0689901\ttotal: 24.2s\tremaining: 41.6s\n",
            "368:\tlearn: 0.0689404\ttotal: 24.3s\tremaining: 41.5s\n",
            "369:\tlearn: 0.0686718\ttotal: 24.4s\tremaining: 41.5s\n",
            "370:\tlearn: 0.0686398\ttotal: 24.4s\tremaining: 41.4s\n",
            "371:\tlearn: 0.0685352\ttotal: 24.5s\tremaining: 41.3s\n",
            "372:\tlearn: 0.0682609\ttotal: 24.5s\tremaining: 41.2s\n",
            "373:\tlearn: 0.0681360\ttotal: 24.6s\tremaining: 41.2s\n",
            "374:\tlearn: 0.0680856\ttotal: 24.6s\tremaining: 41.1s\n",
            "375:\tlearn: 0.0677930\ttotal: 24.7s\tremaining: 41s\n",
            "376:\tlearn: 0.0673247\ttotal: 24.7s\tremaining: 40.8s\n",
            "377:\tlearn: 0.0670497\ttotal: 24.8s\tremaining: 40.7s\n",
            "378:\tlearn: 0.0668979\ttotal: 24.8s\tremaining: 40.6s\n",
            "379:\tlearn: 0.0666961\ttotal: 24.8s\tremaining: 40.5s\n",
            "380:\tlearn: 0.0664830\ttotal: 24.9s\tremaining: 40.5s\n",
            "381:\tlearn: 0.0663183\ttotal: 25s\tremaining: 40.5s\n",
            "382:\tlearn: 0.0660033\ttotal: 25.1s\tremaining: 40.5s\n",
            "383:\tlearn: 0.0658402\ttotal: 25.2s\tremaining: 40.4s\n",
            "384:\tlearn: 0.0656218\ttotal: 25.3s\tremaining: 40.4s\n",
            "385:\tlearn: 0.0655033\ttotal: 25.4s\tremaining: 40.4s\n",
            "386:\tlearn: 0.0652460\ttotal: 25.4s\tremaining: 40.3s\n",
            "387:\tlearn: 0.0650238\ttotal: 25.5s\tremaining: 40.2s\n",
            "388:\tlearn: 0.0649802\ttotal: 25.6s\tremaining: 40.2s\n",
            "389:\tlearn: 0.0647781\ttotal: 25.7s\tremaining: 40.1s\n",
            "390:\tlearn: 0.0645957\ttotal: 25.7s\tremaining: 40.1s\n",
            "391:\tlearn: 0.0644528\ttotal: 25.8s\tremaining: 40.1s\n",
            "392:\tlearn: 0.0643687\ttotal: 26s\tremaining: 40.1s\n",
            "393:\tlearn: 0.0641889\ttotal: 26s\tremaining: 40s\n",
            "394:\tlearn: 0.0639800\ttotal: 26.1s\tremaining: 40s\n",
            "395:\tlearn: 0.0636870\ttotal: 26.2s\tremaining: 39.9s\n",
            "396:\tlearn: 0.0635881\ttotal: 26.3s\tremaining: 39.9s\n",
            "397:\tlearn: 0.0634859\ttotal: 26.4s\tremaining: 39.9s\n",
            "398:\tlearn: 0.0634432\ttotal: 26.5s\tremaining: 39.9s\n",
            "399:\tlearn: 0.0633020\ttotal: 26.6s\tremaining: 40s\n",
            "400:\tlearn: 0.0632535\ttotal: 26.7s\tremaining: 39.9s\n",
            "401:\tlearn: 0.0631136\ttotal: 26.8s\tremaining: 39.9s\n",
            "402:\tlearn: 0.0629101\ttotal: 26.9s\tremaining: 39.9s\n",
            "403:\tlearn: 0.0627823\ttotal: 27s\tremaining: 39.8s\n",
            "404:\tlearn: 0.0624723\ttotal: 27.1s\tremaining: 39.8s\n",
            "405:\tlearn: 0.0622398\ttotal: 27.2s\tremaining: 39.8s\n",
            "406:\tlearn: 0.0621810\ttotal: 27.3s\tremaining: 39.8s\n",
            "407:\tlearn: 0.0621457\ttotal: 27.4s\tremaining: 39.8s\n",
            "408:\tlearn: 0.0618201\ttotal: 27.5s\tremaining: 39.8s\n",
            "409:\tlearn: 0.0616207\ttotal: 27.6s\tremaining: 39.7s\n",
            "410:\tlearn: 0.0614404\ttotal: 27.7s\tremaining: 39.7s\n",
            "411:\tlearn: 0.0613336\ttotal: 27.8s\tremaining: 39.7s\n",
            "412:\tlearn: 0.0611772\ttotal: 27.9s\tremaining: 39.7s\n",
            "413:\tlearn: 0.0609310\ttotal: 28s\tremaining: 39.7s\n",
            "414:\tlearn: 0.0606623\ttotal: 28.1s\tremaining: 39.7s\n",
            "415:\tlearn: 0.0606263\ttotal: 28.2s\tremaining: 39.6s\n",
            "416:\tlearn: 0.0605699\ttotal: 28.3s\tremaining: 39.6s\n",
            "417:\tlearn: 0.0602689\ttotal: 28.4s\tremaining: 39.5s\n",
            "418:\tlearn: 0.0602210\ttotal: 28.5s\tremaining: 39.5s\n",
            "419:\tlearn: 0.0598994\ttotal: 28.6s\tremaining: 39.5s\n",
            "420:\tlearn: 0.0598475\ttotal: 28.7s\tremaining: 39.4s\n",
            "421:\tlearn: 0.0597408\ttotal: 28.8s\tremaining: 39.4s\n",
            "422:\tlearn: 0.0596095\ttotal: 28.9s\tremaining: 39.4s\n",
            "423:\tlearn: 0.0593908\ttotal: 29s\tremaining: 39.4s\n",
            "424:\tlearn: 0.0592344\ttotal: 29.2s\tremaining: 39.5s\n",
            "425:\tlearn: 0.0590494\ttotal: 29.4s\tremaining: 39.6s\n",
            "426:\tlearn: 0.0588447\ttotal: 29.5s\tremaining: 39.7s\n",
            "427:\tlearn: 0.0587191\ttotal: 29.7s\tremaining: 39.7s\n",
            "428:\tlearn: 0.0585765\ttotal: 29.9s\tremaining: 39.8s\n",
            "429:\tlearn: 0.0583136\ttotal: 30.1s\tremaining: 39.9s\n",
            "430:\tlearn: 0.0581177\ttotal: 30.3s\tremaining: 40s\n",
            "431:\tlearn: 0.0580753\ttotal: 30.4s\tremaining: 40s\n",
            "432:\tlearn: 0.0578447\ttotal: 30.6s\tremaining: 40.1s\n",
            "433:\tlearn: 0.0577897\ttotal: 30.8s\tremaining: 40.1s\n",
            "434:\tlearn: 0.0575517\ttotal: 30.9s\tremaining: 40.2s\n",
            "435:\tlearn: 0.0573465\ttotal: 31.1s\tremaining: 40.2s\n",
            "436:\tlearn: 0.0571637\ttotal: 31.2s\tremaining: 40.2s\n",
            "437:\tlearn: 0.0570478\ttotal: 31.3s\tremaining: 40.1s\n",
            "438:\tlearn: 0.0569042\ttotal: 31.3s\tremaining: 40.1s\n",
            "439:\tlearn: 0.0567605\ttotal: 31.4s\tremaining: 40s\n",
            "440:\tlearn: 0.0564753\ttotal: 31.5s\tremaining: 39.9s\n",
            "441:\tlearn: 0.0562574\ttotal: 31.6s\tremaining: 39.8s\n",
            "442:\tlearn: 0.0562251\ttotal: 31.6s\tremaining: 39.8s\n",
            "443:\tlearn: 0.0562021\ttotal: 31.7s\tremaining: 39.7s\n",
            "444:\tlearn: 0.0561052\ttotal: 31.7s\tremaining: 39.6s\n",
            "445:\tlearn: 0.0559168\ttotal: 31.8s\tremaining: 39.5s\n",
            "446:\tlearn: 0.0556570\ttotal: 31.8s\tremaining: 39.4s\n",
            "447:\tlearn: 0.0555133\ttotal: 31.9s\tremaining: 39.3s\n",
            "448:\tlearn: 0.0554629\ttotal: 32s\tremaining: 39.2s\n",
            "449:\tlearn: 0.0553093\ttotal: 32.1s\tremaining: 39.2s\n",
            "450:\tlearn: 0.0552113\ttotal: 32.1s\tremaining: 39.1s\n",
            "451:\tlearn: 0.0551904\ttotal: 32.2s\tremaining: 39s\n",
            "452:\tlearn: 0.0550678\ttotal: 32.2s\tremaining: 38.9s\n",
            "453:\tlearn: 0.0550415\ttotal: 32.3s\tremaining: 38.9s\n",
            "454:\tlearn: 0.0550014\ttotal: 32.4s\tremaining: 38.8s\n",
            "455:\tlearn: 0.0549702\ttotal: 32.4s\tremaining: 38.7s\n",
            "456:\tlearn: 0.0549370\ttotal: 32.5s\tremaining: 38.6s\n",
            "457:\tlearn: 0.0549156\ttotal: 32.6s\tremaining: 38.6s\n",
            "458:\tlearn: 0.0547706\ttotal: 32.6s\tremaining: 38.5s\n",
            "459:\tlearn: 0.0546001\ttotal: 32.7s\tremaining: 38.4s\n",
            "460:\tlearn: 0.0544666\ttotal: 32.7s\tremaining: 38.3s\n",
            "461:\tlearn: 0.0544356\ttotal: 32.8s\tremaining: 38.2s\n",
            "462:\tlearn: 0.0544148\ttotal: 32.8s\tremaining: 38.1s\n",
            "463:\tlearn: 0.0542364\ttotal: 32.9s\tremaining: 38s\n",
            "464:\tlearn: 0.0541264\ttotal: 32.9s\tremaining: 37.9s\n",
            "465:\tlearn: 0.0539919\ttotal: 33s\tremaining: 37.8s\n",
            "466:\tlearn: 0.0537867\ttotal: 33.1s\tremaining: 37.7s\n",
            "467:\tlearn: 0.0536824\ttotal: 33.1s\tremaining: 37.7s\n",
            "468:\tlearn: 0.0535464\ttotal: 33.2s\tremaining: 37.6s\n",
            "469:\tlearn: 0.0535277\ttotal: 33.3s\tremaining: 37.5s\n",
            "470:\tlearn: 0.0535087\ttotal: 33.3s\tremaining: 37.4s\n",
            "471:\tlearn: 0.0533210\ttotal: 33.4s\tremaining: 37.3s\n",
            "472:\tlearn: 0.0531095\ttotal: 33.4s\tremaining: 37.3s\n",
            "473:\tlearn: 0.0529323\ttotal: 33.5s\tremaining: 37.2s\n",
            "474:\tlearn: 0.0528878\ttotal: 33.5s\tremaining: 37.1s\n",
            "475:\tlearn: 0.0528443\ttotal: 33.6s\tremaining: 37s\n",
            "476:\tlearn: 0.0528086\ttotal: 33.6s\tremaining: 36.9s\n",
            "477:\tlearn: 0.0526074\ttotal: 33.7s\tremaining: 36.8s\n",
            "478:\tlearn: 0.0525815\ttotal: 33.8s\tremaining: 36.7s\n",
            "479:\tlearn: 0.0523802\ttotal: 33.8s\tremaining: 36.6s\n",
            "480:\tlearn: 0.0521694\ttotal: 33.9s\tremaining: 36.5s\n",
            "481:\tlearn: 0.0520419\ttotal: 33.9s\tremaining: 36.5s\n",
            "482:\tlearn: 0.0520130\ttotal: 34s\tremaining: 36.4s\n",
            "483:\tlearn: 0.0518537\ttotal: 34s\tremaining: 36.3s\n",
            "484:\tlearn: 0.0518241\ttotal: 34.1s\tremaining: 36.2s\n",
            "485:\tlearn: 0.0517944\ttotal: 34.1s\tremaining: 36.1s\n",
            "486:\tlearn: 0.0517617\ttotal: 34.2s\tremaining: 36s\n",
            "487:\tlearn: 0.0516833\ttotal: 34.2s\tremaining: 35.9s\n",
            "488:\tlearn: 0.0515537\ttotal: 34.3s\tremaining: 35.8s\n",
            "489:\tlearn: 0.0515350\ttotal: 34.4s\tremaining: 35.8s\n",
            "490:\tlearn: 0.0514256\ttotal: 34.4s\tremaining: 35.7s\n",
            "491:\tlearn: 0.0512256\ttotal: 34.5s\tremaining: 35.6s\n",
            "492:\tlearn: 0.0511906\ttotal: 34.5s\tremaining: 35.5s\n",
            "493:\tlearn: 0.0509816\ttotal: 34.6s\tremaining: 35.5s\n",
            "494:\tlearn: 0.0508388\ttotal: 34.7s\tremaining: 35.4s\n",
            "495:\tlearn: 0.0506428\ttotal: 34.7s\tremaining: 35.3s\n",
            "496:\tlearn: 0.0506197\ttotal: 34.8s\tremaining: 35.2s\n",
            "497:\tlearn: 0.0504064\ttotal: 34.9s\tremaining: 35.1s\n",
            "498:\tlearn: 0.0502447\ttotal: 34.9s\tremaining: 35s\n",
            "499:\tlearn: 0.0502200\ttotal: 35s\tremaining: 35s\n",
            "500:\tlearn: 0.0500923\ttotal: 35s\tremaining: 34.9s\n",
            "501:\tlearn: 0.0500579\ttotal: 35.1s\tremaining: 34.8s\n",
            "502:\tlearn: 0.0499186\ttotal: 35.1s\tremaining: 34.7s\n",
            "503:\tlearn: 0.0497769\ttotal: 35.2s\tremaining: 34.7s\n",
            "504:\tlearn: 0.0497346\ttotal: 35.3s\tremaining: 34.6s\n",
            "505:\tlearn: 0.0497051\ttotal: 35.3s\tremaining: 34.5s\n",
            "506:\tlearn: 0.0495150\ttotal: 35.4s\tremaining: 34.4s\n",
            "507:\tlearn: 0.0494899\ttotal: 35.4s\tremaining: 34.3s\n",
            "508:\tlearn: 0.0492851\ttotal: 35.5s\tremaining: 34.2s\n",
            "509:\tlearn: 0.0492327\ttotal: 35.6s\tremaining: 34.2s\n",
            "510:\tlearn: 0.0491616\ttotal: 35.6s\tremaining: 34.1s\n",
            "511:\tlearn: 0.0490078\ttotal: 35.7s\tremaining: 34s\n",
            "512:\tlearn: 0.0489555\ttotal: 35.8s\tremaining: 34s\n",
            "513:\tlearn: 0.0487587\ttotal: 35.9s\tremaining: 33.9s\n",
            "514:\tlearn: 0.0485656\ttotal: 35.9s\tremaining: 33.8s\n",
            "515:\tlearn: 0.0484503\ttotal: 36s\tremaining: 33.7s\n",
            "516:\tlearn: 0.0483650\ttotal: 36s\tremaining: 33.7s\n",
            "517:\tlearn: 0.0483433\ttotal: 36.1s\tremaining: 33.6s\n",
            "518:\tlearn: 0.0481624\ttotal: 36.1s\tremaining: 33.5s\n",
            "519:\tlearn: 0.0481313\ttotal: 36.2s\tremaining: 33.4s\n",
            "520:\tlearn: 0.0481006\ttotal: 36.3s\tremaining: 33.4s\n",
            "521:\tlearn: 0.0478907\ttotal: 36.4s\tremaining: 33.3s\n",
            "522:\tlearn: 0.0477701\ttotal: 36.4s\tremaining: 33.2s\n",
            "523:\tlearn: 0.0477515\ttotal: 36.5s\tremaining: 33.2s\n",
            "524:\tlearn: 0.0475670\ttotal: 36.6s\tremaining: 33.1s\n",
            "525:\tlearn: 0.0475331\ttotal: 36.6s\tremaining: 33s\n",
            "526:\tlearn: 0.0474577\ttotal: 36.7s\tremaining: 32.9s\n",
            "527:\tlearn: 0.0473552\ttotal: 36.7s\tremaining: 32.8s\n",
            "528:\tlearn: 0.0473338\ttotal: 36.8s\tremaining: 32.8s\n",
            "529:\tlearn: 0.0471567\ttotal: 36.8s\tremaining: 32.7s\n",
            "530:\tlearn: 0.0469989\ttotal: 36.9s\tremaining: 32.6s\n",
            "531:\tlearn: 0.0469834\ttotal: 37s\tremaining: 32.5s\n",
            "532:\tlearn: 0.0468618\ttotal: 37s\tremaining: 32.4s\n",
            "533:\tlearn: 0.0468440\ttotal: 37.1s\tremaining: 32.4s\n",
            "534:\tlearn: 0.0466798\ttotal: 37.2s\tremaining: 32.3s\n",
            "535:\tlearn: 0.0466541\ttotal: 37.2s\tremaining: 32.2s\n",
            "536:\tlearn: 0.0465174\ttotal: 37.3s\tremaining: 32.1s\n",
            "537:\tlearn: 0.0463450\ttotal: 37.3s\tremaining: 32.1s\n",
            "538:\tlearn: 0.0461735\ttotal: 37.4s\tremaining: 32s\n",
            "539:\tlearn: 0.0461569\ttotal: 37.4s\tremaining: 31.9s\n",
            "540:\tlearn: 0.0460068\ttotal: 37.5s\tremaining: 31.8s\n",
            "541:\tlearn: 0.0459623\ttotal: 37.6s\tremaining: 31.8s\n",
            "542:\tlearn: 0.0459384\ttotal: 37.7s\tremaining: 31.7s\n",
            "543:\tlearn: 0.0457166\ttotal: 37.7s\tremaining: 31.6s\n",
            "544:\tlearn: 0.0455906\ttotal: 37.8s\tremaining: 31.6s\n",
            "545:\tlearn: 0.0455477\ttotal: 37.9s\tremaining: 31.5s\n",
            "546:\tlearn: 0.0455229\ttotal: 37.9s\tremaining: 31.4s\n",
            "547:\tlearn: 0.0455020\ttotal: 38s\tremaining: 31.3s\n",
            "548:\tlearn: 0.0453651\ttotal: 38s\tremaining: 31.2s\n",
            "549:\tlearn: 0.0453373\ttotal: 38.1s\tremaining: 31.2s\n",
            "550:\tlearn: 0.0451862\ttotal: 38.1s\tremaining: 31.1s\n",
            "551:\tlearn: 0.0451555\ttotal: 38.2s\tremaining: 31s\n",
            "552:\tlearn: 0.0451306\ttotal: 38.3s\tremaining: 31s\n",
            "553:\tlearn: 0.0450431\ttotal: 38.4s\tremaining: 30.9s\n",
            "554:\tlearn: 0.0450259\ttotal: 38.4s\tremaining: 30.8s\n",
            "555:\tlearn: 0.0448718\ttotal: 38.5s\tremaining: 30.7s\n",
            "556:\tlearn: 0.0446626\ttotal: 38.5s\tremaining: 30.6s\n",
            "557:\tlearn: 0.0446136\ttotal: 38.6s\tremaining: 30.6s\n",
            "558:\tlearn: 0.0445736\ttotal: 38.6s\tremaining: 30.5s\n",
            "559:\tlearn: 0.0445387\ttotal: 38.7s\tremaining: 30.4s\n",
            "560:\tlearn: 0.0443290\ttotal: 38.7s\tremaining: 30.3s\n",
            "561:\tlearn: 0.0442566\ttotal: 38.8s\tremaining: 30.2s\n",
            "562:\tlearn: 0.0441419\ttotal: 38.8s\tremaining: 30.1s\n",
            "563:\tlearn: 0.0440059\ttotal: 38.9s\tremaining: 30.1s\n",
            "564:\tlearn: 0.0438731\ttotal: 38.9s\tremaining: 30s\n",
            "565:\tlearn: 0.0438481\ttotal: 39s\tremaining: 29.9s\n",
            "566:\tlearn: 0.0437148\ttotal: 39s\tremaining: 29.8s\n",
            "567:\tlearn: 0.0435516\ttotal: 39.1s\tremaining: 29.7s\n",
            "568:\tlearn: 0.0435291\ttotal: 39.1s\tremaining: 29.6s\n",
            "569:\tlearn: 0.0434070\ttotal: 39.2s\tremaining: 29.6s\n",
            "570:\tlearn: 0.0433872\ttotal: 39.4s\tremaining: 29.6s\n",
            "571:\tlearn: 0.0433680\ttotal: 39.5s\tremaining: 29.5s\n",
            "572:\tlearn: 0.0432375\ttotal: 39.5s\tremaining: 29.4s\n",
            "573:\tlearn: 0.0432064\ttotal: 39.6s\tremaining: 29.4s\n",
            "574:\tlearn: 0.0431711\ttotal: 39.6s\tremaining: 29.3s\n",
            "575:\tlearn: 0.0429462\ttotal: 39.7s\tremaining: 29.2s\n",
            "576:\tlearn: 0.0427448\ttotal: 39.7s\tremaining: 29.1s\n",
            "577:\tlearn: 0.0426045\ttotal: 39.8s\tremaining: 29s\n",
            "578:\tlearn: 0.0424483\ttotal: 39.8s\tremaining: 29s\n",
            "579:\tlearn: 0.0424288\ttotal: 39.9s\tremaining: 28.9s\n",
            "580:\tlearn: 0.0424099\ttotal: 39.9s\tremaining: 28.8s\n",
            "581:\tlearn: 0.0423826\ttotal: 40s\tremaining: 28.7s\n",
            "582:\tlearn: 0.0422955\ttotal: 40.1s\tremaining: 28.6s\n",
            "583:\tlearn: 0.0421996\ttotal: 40.1s\tremaining: 28.6s\n",
            "584:\tlearn: 0.0420567\ttotal: 40.2s\tremaining: 28.5s\n",
            "585:\tlearn: 0.0419095\ttotal: 40.2s\tremaining: 28.4s\n",
            "586:\tlearn: 0.0418795\ttotal: 40.3s\tremaining: 28.4s\n",
            "587:\tlearn: 0.0416881\ttotal: 40.4s\tremaining: 28.3s\n",
            "588:\tlearn: 0.0415075\ttotal: 40.4s\tremaining: 28.2s\n",
            "589:\tlearn: 0.0413773\ttotal: 40.5s\tremaining: 28.2s\n",
            "590:\tlearn: 0.0412441\ttotal: 40.6s\tremaining: 28.1s\n",
            "591:\tlearn: 0.0412183\ttotal: 40.6s\tremaining: 28s\n",
            "592:\tlearn: 0.0410803\ttotal: 40.7s\tremaining: 27.9s\n",
            "593:\tlearn: 0.0409343\ttotal: 40.7s\tremaining: 27.8s\n",
            "594:\tlearn: 0.0409163\ttotal: 40.7s\tremaining: 27.7s\n",
            "595:\tlearn: 0.0408913\ttotal: 40.8s\tremaining: 27.7s\n",
            "596:\tlearn: 0.0406634\ttotal: 40.9s\tremaining: 27.6s\n",
            "597:\tlearn: 0.0405676\ttotal: 40.9s\tremaining: 27.5s\n",
            "598:\tlearn: 0.0403578\ttotal: 41s\tremaining: 27.5s\n",
            "599:\tlearn: 0.0402300\ttotal: 41.1s\tremaining: 27.4s\n",
            "600:\tlearn: 0.0401402\ttotal: 41.2s\tremaining: 27.3s\n",
            "601:\tlearn: 0.0399292\ttotal: 41.3s\tremaining: 27.3s\n",
            "602:\tlearn: 0.0397250\ttotal: 41.4s\tremaining: 27.2s\n",
            "603:\tlearn: 0.0395447\ttotal: 41.5s\tremaining: 27.2s\n",
            "604:\tlearn: 0.0395263\ttotal: 41.5s\tremaining: 27.1s\n",
            "605:\tlearn: 0.0395020\ttotal: 41.6s\tremaining: 27.1s\n",
            "606:\tlearn: 0.0394125\ttotal: 41.7s\tremaining: 27s\n",
            "607:\tlearn: 0.0393905\ttotal: 41.8s\tremaining: 26.9s\n",
            "608:\tlearn: 0.0392822\ttotal: 41.9s\tremaining: 26.9s\n",
            "609:\tlearn: 0.0392436\ttotal: 41.9s\tremaining: 26.8s\n",
            "610:\tlearn: 0.0392226\ttotal: 42s\tremaining: 26.7s\n",
            "611:\tlearn: 0.0390979\ttotal: 42.1s\tremaining: 26.7s\n",
            "612:\tlearn: 0.0390213\ttotal: 42.1s\tremaining: 26.6s\n",
            "613:\tlearn: 0.0388780\ttotal: 42.2s\tremaining: 26.6s\n",
            "614:\tlearn: 0.0388642\ttotal: 42.3s\tremaining: 26.5s\n",
            "615:\tlearn: 0.0386942\ttotal: 42.4s\tremaining: 26.4s\n",
            "616:\tlearn: 0.0386717\ttotal: 42.5s\tremaining: 26.4s\n",
            "617:\tlearn: 0.0386528\ttotal: 42.5s\tremaining: 26.3s\n",
            "618:\tlearn: 0.0385422\ttotal: 42.6s\tremaining: 26.2s\n",
            "619:\tlearn: 0.0383088\ttotal: 42.7s\tremaining: 26.1s\n",
            "620:\tlearn: 0.0382429\ttotal: 42.7s\tremaining: 26.1s\n",
            "621:\tlearn: 0.0379604\ttotal: 42.8s\tremaining: 26s\n",
            "622:\tlearn: 0.0377960\ttotal: 42.9s\tremaining: 25.9s\n",
            "623:\tlearn: 0.0375101\ttotal: 42.9s\tremaining: 25.9s\n",
            "624:\tlearn: 0.0374602\ttotal: 43s\tremaining: 25.8s\n",
            "625:\tlearn: 0.0373183\ttotal: 43.1s\tremaining: 25.8s\n",
            "626:\tlearn: 0.0372349\ttotal: 43.2s\tremaining: 25.7s\n",
            "627:\tlearn: 0.0372138\ttotal: 43.3s\tremaining: 25.6s\n",
            "628:\tlearn: 0.0372004\ttotal: 43.3s\tremaining: 25.6s\n",
            "629:\tlearn: 0.0371716\ttotal: 43.4s\tremaining: 25.5s\n",
            "630:\tlearn: 0.0370206\ttotal: 43.5s\tremaining: 25.5s\n",
            "631:\tlearn: 0.0368612\ttotal: 43.6s\tremaining: 25.4s\n",
            "632:\tlearn: 0.0368441\ttotal: 43.7s\tremaining: 25.3s\n",
            "633:\tlearn: 0.0368314\ttotal: 43.8s\tremaining: 25.3s\n",
            "634:\tlearn: 0.0368104\ttotal: 43.9s\tremaining: 25.2s\n",
            "635:\tlearn: 0.0367638\ttotal: 44s\tremaining: 25.2s\n",
            "636:\tlearn: 0.0366786\ttotal: 44.1s\tremaining: 25.2s\n",
            "637:\tlearn: 0.0366624\ttotal: 44.3s\tremaining: 25.1s\n",
            "638:\tlearn: 0.0365275\ttotal: 44.4s\tremaining: 25.1s\n",
            "639:\tlearn: 0.0364369\ttotal: 44.5s\tremaining: 25s\n",
            "640:\tlearn: 0.0363189\ttotal: 44.5s\tremaining: 24.9s\n",
            "641:\tlearn: 0.0361984\ttotal: 44.6s\tremaining: 24.9s\n",
            "642:\tlearn: 0.0361830\ttotal: 44.7s\tremaining: 24.8s\n",
            "643:\tlearn: 0.0361594\ttotal: 44.9s\tremaining: 24.8s\n",
            "644:\tlearn: 0.0361130\ttotal: 44.9s\tremaining: 24.7s\n",
            "645:\tlearn: 0.0359510\ttotal: 45s\tremaining: 24.7s\n",
            "646:\tlearn: 0.0359333\ttotal: 45.1s\tremaining: 24.6s\n",
            "647:\tlearn: 0.0359139\ttotal: 45.2s\tremaining: 24.5s\n",
            "648:\tlearn: 0.0359019\ttotal: 45.2s\tremaining: 24.5s\n",
            "649:\tlearn: 0.0358249\ttotal: 45.4s\tremaining: 24.4s\n",
            "650:\tlearn: 0.0357245\ttotal: 45.4s\tremaining: 24.4s\n",
            "651:\tlearn: 0.0356284\ttotal: 45.5s\tremaining: 24.3s\n",
            "652:\tlearn: 0.0353943\ttotal: 45.6s\tremaining: 24.2s\n",
            "653:\tlearn: 0.0353158\ttotal: 45.7s\tremaining: 24.2s\n",
            "654:\tlearn: 0.0351888\ttotal: 45.8s\tremaining: 24.1s\n",
            "655:\tlearn: 0.0350406\ttotal: 45.9s\tremaining: 24.1s\n",
            "656:\tlearn: 0.0349635\ttotal: 46s\tremaining: 24s\n",
            "657:\tlearn: 0.0349451\ttotal: 46.2s\tremaining: 24s\n",
            "658:\tlearn: 0.0349327\ttotal: 46.3s\tremaining: 23.9s\n",
            "659:\tlearn: 0.0349189\ttotal: 46.4s\tremaining: 23.9s\n",
            "660:\tlearn: 0.0348171\ttotal: 46.5s\tremaining: 23.9s\n",
            "661:\tlearn: 0.0347989\ttotal: 46.6s\tremaining: 23.8s\n",
            "662:\tlearn: 0.0347858\ttotal: 46.7s\tremaining: 23.7s\n",
            "663:\tlearn: 0.0346423\ttotal: 46.8s\tremaining: 23.7s\n",
            "664:\tlearn: 0.0346268\ttotal: 46.8s\tremaining: 23.6s\n",
            "665:\tlearn: 0.0345058\ttotal: 46.9s\tremaining: 23.5s\n",
            "666:\tlearn: 0.0344490\ttotal: 47s\tremaining: 23.5s\n",
            "667:\tlearn: 0.0344353\ttotal: 47.1s\tremaining: 23.4s\n",
            "668:\tlearn: 0.0344188\ttotal: 47.2s\tremaining: 23.3s\n",
            "669:\tlearn: 0.0342666\ttotal: 47.2s\tremaining: 23.3s\n",
            "670:\tlearn: 0.0341225\ttotal: 47.3s\tremaining: 23.2s\n",
            "671:\tlearn: 0.0341029\ttotal: 47.3s\tremaining: 23.1s\n",
            "672:\tlearn: 0.0340890\ttotal: 47.4s\tremaining: 23s\n",
            "673:\tlearn: 0.0338915\ttotal: 47.4s\tremaining: 22.9s\n",
            "674:\tlearn: 0.0338756\ttotal: 47.5s\tremaining: 22.9s\n",
            "675:\tlearn: 0.0338581\ttotal: 47.5s\tremaining: 22.8s\n",
            "676:\tlearn: 0.0337067\ttotal: 47.6s\tremaining: 22.7s\n",
            "677:\tlearn: 0.0335942\ttotal: 47.6s\tremaining: 22.6s\n",
            "678:\tlearn: 0.0335818\ttotal: 47.7s\tremaining: 22.5s\n",
            "679:\tlearn: 0.0335668\ttotal: 47.7s\tremaining: 22.5s\n",
            "680:\tlearn: 0.0334563\ttotal: 47.8s\tremaining: 22.4s\n",
            "681:\tlearn: 0.0334432\ttotal: 47.8s\tremaining: 22.3s\n",
            "682:\tlearn: 0.0334324\ttotal: 47.9s\tremaining: 22.2s\n",
            "683:\tlearn: 0.0332334\ttotal: 48s\tremaining: 22.2s\n",
            "684:\tlearn: 0.0330551\ttotal: 48s\tremaining: 22.1s\n",
            "685:\tlearn: 0.0329551\ttotal: 48.1s\tremaining: 22s\n",
            "686:\tlearn: 0.0329446\ttotal: 48.1s\tremaining: 21.9s\n",
            "687:\tlearn: 0.0328064\ttotal: 48.2s\tremaining: 21.8s\n",
            "688:\tlearn: 0.0327169\ttotal: 48.2s\tremaining: 21.8s\n",
            "689:\tlearn: 0.0326421\ttotal: 48.3s\tremaining: 21.7s\n",
            "690:\tlearn: 0.0326245\ttotal: 48.3s\tremaining: 21.6s\n",
            "691:\tlearn: 0.0324521\ttotal: 48.4s\tremaining: 21.5s\n",
            "692:\tlearn: 0.0324403\ttotal: 48.4s\tremaining: 21.4s\n",
            "693:\tlearn: 0.0324279\ttotal: 48.4s\tremaining: 21.4s\n",
            "694:\tlearn: 0.0324177\ttotal: 48.5s\tremaining: 21.3s\n",
            "695:\tlearn: 0.0323755\ttotal: 48.5s\tremaining: 21.2s\n",
            "696:\tlearn: 0.0323382\ttotal: 48.6s\tremaining: 21.1s\n",
            "697:\tlearn: 0.0322219\ttotal: 48.6s\tremaining: 21s\n",
            "698:\tlearn: 0.0322072\ttotal: 48.7s\tremaining: 21s\n",
            "699:\tlearn: 0.0320410\ttotal: 48.8s\tremaining: 20.9s\n",
            "700:\tlearn: 0.0319309\ttotal: 48.9s\tremaining: 20.8s\n",
            "701:\tlearn: 0.0319191\ttotal: 48.9s\tremaining: 20.8s\n",
            "702:\tlearn: 0.0318515\ttotal: 49s\tremaining: 20.7s\n",
            "703:\tlearn: 0.0318403\ttotal: 49s\tremaining: 20.6s\n",
            "704:\tlearn: 0.0316931\ttotal: 49.1s\tremaining: 20.5s\n",
            "705:\tlearn: 0.0315481\ttotal: 49.2s\tremaining: 20.5s\n",
            "706:\tlearn: 0.0315385\ttotal: 49.2s\tremaining: 20.4s\n",
            "707:\tlearn: 0.0314884\ttotal: 49.3s\tremaining: 20.3s\n",
            "708:\tlearn: 0.0314719\ttotal: 49.3s\tremaining: 20.2s\n",
            "709:\tlearn: 0.0313668\ttotal: 49.4s\tremaining: 20.2s\n",
            "710:\tlearn: 0.0312868\ttotal: 49.4s\tremaining: 20.1s\n",
            "711:\tlearn: 0.0312745\ttotal: 49.5s\tremaining: 20s\n",
            "712:\tlearn: 0.0312421\ttotal: 49.5s\tremaining: 19.9s\n",
            "713:\tlearn: 0.0311813\ttotal: 49.5s\tremaining: 19.8s\n",
            "714:\tlearn: 0.0311544\ttotal: 49.6s\tremaining: 19.8s\n",
            "715:\tlearn: 0.0310408\ttotal: 49.6s\tremaining: 19.7s\n",
            "716:\tlearn: 0.0309571\ttotal: 49.7s\tremaining: 19.6s\n",
            "717:\tlearn: 0.0308187\ttotal: 49.8s\tremaining: 19.5s\n",
            "718:\tlearn: 0.0307890\ttotal: 49.8s\tremaining: 19.5s\n",
            "719:\tlearn: 0.0306824\ttotal: 49.9s\tremaining: 19.4s\n",
            "720:\tlearn: 0.0305334\ttotal: 50s\tremaining: 19.3s\n",
            "721:\tlearn: 0.0305197\ttotal: 50.1s\tremaining: 19.3s\n",
            "722:\tlearn: 0.0303834\ttotal: 50.1s\tremaining: 19.2s\n",
            "723:\tlearn: 0.0302887\ttotal: 50.2s\tremaining: 19.1s\n",
            "724:\tlearn: 0.0301161\ttotal: 50.2s\tremaining: 19.1s\n",
            "725:\tlearn: 0.0300774\ttotal: 50.3s\tremaining: 19s\n",
            "726:\tlearn: 0.0300618\ttotal: 50.4s\tremaining: 18.9s\n",
            "727:\tlearn: 0.0299684\ttotal: 50.4s\tremaining: 18.8s\n",
            "728:\tlearn: 0.0298638\ttotal: 50.5s\tremaining: 18.8s\n",
            "729:\tlearn: 0.0297825\ttotal: 50.5s\tremaining: 18.7s\n",
            "730:\tlearn: 0.0296898\ttotal: 50.5s\tremaining: 18.6s\n",
            "731:\tlearn: 0.0296810\ttotal: 50.6s\tremaining: 18.5s\n",
            "732:\tlearn: 0.0295036\ttotal: 50.6s\tremaining: 18.4s\n",
            "733:\tlearn: 0.0292899\ttotal: 50.6s\tremaining: 18.3s\n",
            "734:\tlearn: 0.0292781\ttotal: 50.6s\tremaining: 18.3s\n",
            "735:\tlearn: 0.0292680\ttotal: 50.7s\tremaining: 18.2s\n",
            "736:\tlearn: 0.0292591\ttotal: 50.7s\tremaining: 18.1s\n",
            "737:\tlearn: 0.0292512\ttotal: 50.7s\tremaining: 18s\n",
            "738:\tlearn: 0.0290921\ttotal: 50.8s\tremaining: 17.9s\n",
            "739:\tlearn: 0.0290838\ttotal: 50.8s\tremaining: 17.8s\n",
            "740:\tlearn: 0.0289767\ttotal: 50.8s\tremaining: 17.8s\n",
            "741:\tlearn: 0.0289642\ttotal: 50.9s\tremaining: 17.7s\n",
            "742:\tlearn: 0.0289498\ttotal: 50.9s\tremaining: 17.6s\n",
            "743:\tlearn: 0.0289279\ttotal: 50.9s\tremaining: 17.5s\n",
            "744:\tlearn: 0.0288247\ttotal: 50.9s\tremaining: 17.4s\n",
            "745:\tlearn: 0.0287092\ttotal: 51s\tremaining: 17.4s\n",
            "746:\tlearn: 0.0286429\ttotal: 51s\tremaining: 17.3s\n",
            "747:\tlearn: 0.0286348\ttotal: 51s\tremaining: 17.2s\n",
            "748:\tlearn: 0.0285315\ttotal: 51.1s\tremaining: 17.1s\n",
            "749:\tlearn: 0.0283987\ttotal: 51.1s\tremaining: 17s\n",
            "750:\tlearn: 0.0283775\ttotal: 51.1s\tremaining: 16.9s\n",
            "751:\tlearn: 0.0283696\ttotal: 51.1s\tremaining: 16.9s\n",
            "752:\tlearn: 0.0282356\ttotal: 51.2s\tremaining: 16.8s\n",
            "753:\tlearn: 0.0282272\ttotal: 51.2s\tremaining: 16.7s\n",
            "754:\tlearn: 0.0282200\ttotal: 51.2s\tremaining: 16.6s\n",
            "755:\tlearn: 0.0282100\ttotal: 51.3s\tremaining: 16.5s\n",
            "756:\tlearn: 0.0281971\ttotal: 51.3s\tremaining: 16.5s\n",
            "757:\tlearn: 0.0280934\ttotal: 51.3s\tremaining: 16.4s\n",
            "758:\tlearn: 0.0280775\ttotal: 51.3s\tremaining: 16.3s\n",
            "759:\tlearn: 0.0280604\ttotal: 51.4s\tremaining: 16.2s\n",
            "760:\tlearn: 0.0278910\ttotal: 51.4s\tremaining: 16.1s\n",
            "761:\tlearn: 0.0276646\ttotal: 51.4s\tremaining: 16.1s\n",
            "762:\tlearn: 0.0275134\ttotal: 51.5s\tremaining: 16s\n",
            "763:\tlearn: 0.0274994\ttotal: 51.5s\tremaining: 15.9s\n",
            "764:\tlearn: 0.0274032\ttotal: 51.5s\tremaining: 15.8s\n",
            "765:\tlearn: 0.0272454\ttotal: 51.5s\tremaining: 15.7s\n",
            "766:\tlearn: 0.0272350\ttotal: 51.6s\tremaining: 15.7s\n",
            "767:\tlearn: 0.0271380\ttotal: 51.6s\tremaining: 15.6s\n",
            "768:\tlearn: 0.0271245\ttotal: 51.6s\tremaining: 15.5s\n",
            "769:\tlearn: 0.0270163\ttotal: 51.6s\tremaining: 15.4s\n",
            "770:\tlearn: 0.0269978\ttotal: 51.7s\tremaining: 15.3s\n",
            "771:\tlearn: 0.0269909\ttotal: 51.7s\tremaining: 15.3s\n",
            "772:\tlearn: 0.0269820\ttotal: 51.7s\tremaining: 15.2s\n",
            "773:\tlearn: 0.0268698\ttotal: 51.8s\tremaining: 15.1s\n",
            "774:\tlearn: 0.0267677\ttotal: 51.8s\tremaining: 15s\n",
            "775:\tlearn: 0.0267597\ttotal: 51.8s\tremaining: 15s\n",
            "776:\tlearn: 0.0267417\ttotal: 51.9s\tremaining: 14.9s\n",
            "777:\tlearn: 0.0267347\ttotal: 51.9s\tremaining: 14.8s\n",
            "778:\tlearn: 0.0266863\ttotal: 51.9s\tremaining: 14.7s\n",
            "779:\tlearn: 0.0266785\ttotal: 52s\tremaining: 14.7s\n",
            "780:\tlearn: 0.0265877\ttotal: 52s\tremaining: 14.6s\n",
            "781:\tlearn: 0.0265690\ttotal: 52s\tremaining: 14.5s\n",
            "782:\tlearn: 0.0265625\ttotal: 52s\tremaining: 14.4s\n",
            "783:\tlearn: 0.0264952\ttotal: 52.1s\tremaining: 14.3s\n",
            "784:\tlearn: 0.0264875\ttotal: 52.1s\tremaining: 14.3s\n",
            "785:\tlearn: 0.0264049\ttotal: 52.1s\tremaining: 14.2s\n",
            "786:\tlearn: 0.0263976\ttotal: 52.2s\tremaining: 14.1s\n",
            "787:\tlearn: 0.0263415\ttotal: 52.2s\tremaining: 14s\n",
            "788:\tlearn: 0.0263304\ttotal: 52.2s\tremaining: 14s\n",
            "789:\tlearn: 0.0263239\ttotal: 52.2s\tremaining: 13.9s\n",
            "790:\tlearn: 0.0263175\ttotal: 52.3s\tremaining: 13.8s\n",
            "791:\tlearn: 0.0263097\ttotal: 52.3s\tremaining: 13.7s\n",
            "792:\tlearn: 0.0263034\ttotal: 52.3s\tremaining: 13.7s\n",
            "793:\tlearn: 0.0261924\ttotal: 52.3s\tremaining: 13.6s\n",
            "794:\tlearn: 0.0261320\ttotal: 52.4s\tremaining: 13.5s\n",
            "795:\tlearn: 0.0261146\ttotal: 52.4s\tremaining: 13.4s\n",
            "796:\tlearn: 0.0260321\ttotal: 52.4s\tremaining: 13.4s\n",
            "797:\tlearn: 0.0260200\ttotal: 52.5s\tremaining: 13.3s\n",
            "798:\tlearn: 0.0260124\ttotal: 52.5s\tremaining: 13.2s\n",
            "799:\tlearn: 0.0259495\ttotal: 52.5s\tremaining: 13.1s\n",
            "800:\tlearn: 0.0259432\ttotal: 52.5s\tremaining: 13.1s\n",
            "801:\tlearn: 0.0258783\ttotal: 52.6s\tremaining: 13s\n",
            "802:\tlearn: 0.0257452\ttotal: 52.6s\tremaining: 12.9s\n",
            "803:\tlearn: 0.0257327\ttotal: 52.6s\tremaining: 12.8s\n",
            "804:\tlearn: 0.0256357\ttotal: 52.7s\tremaining: 12.8s\n",
            "805:\tlearn: 0.0255514\ttotal: 52.7s\tremaining: 12.7s\n",
            "806:\tlearn: 0.0254936\ttotal: 52.7s\tremaining: 12.6s\n",
            "807:\tlearn: 0.0254845\ttotal: 52.8s\tremaining: 12.5s\n",
            "808:\tlearn: 0.0254726\ttotal: 52.8s\tremaining: 12.5s\n",
            "809:\tlearn: 0.0254529\ttotal: 52.8s\tremaining: 12.4s\n",
            "810:\tlearn: 0.0253417\ttotal: 52.8s\tremaining: 12.3s\n",
            "811:\tlearn: 0.0252291\ttotal: 52.9s\tremaining: 12.2s\n",
            "812:\tlearn: 0.0252124\ttotal: 52.9s\tremaining: 12.2s\n",
            "813:\tlearn: 0.0252069\ttotal: 52.9s\tremaining: 12.1s\n",
            "814:\tlearn: 0.0251995\ttotal: 53s\tremaining: 12s\n",
            "815:\tlearn: 0.0251441\ttotal: 53s\tremaining: 11.9s\n",
            "816:\tlearn: 0.0251224\ttotal: 53s\tremaining: 11.9s\n",
            "817:\tlearn: 0.0251163\ttotal: 53s\tremaining: 11.8s\n",
            "818:\tlearn: 0.0250000\ttotal: 53.1s\tremaining: 11.7s\n",
            "819:\tlearn: 0.0249009\ttotal: 53.1s\tremaining: 11.7s\n",
            "820:\tlearn: 0.0248940\ttotal: 53.1s\tremaining: 11.6s\n",
            "821:\tlearn: 0.0248809\ttotal: 53.1s\tremaining: 11.5s\n",
            "822:\tlearn: 0.0248356\ttotal: 53.2s\tremaining: 11.4s\n",
            "823:\tlearn: 0.0248262\ttotal: 53.2s\tremaining: 11.4s\n",
            "824:\tlearn: 0.0248201\ttotal: 53.2s\tremaining: 11.3s\n",
            "825:\tlearn: 0.0247234\ttotal: 53.3s\tremaining: 11.2s\n",
            "826:\tlearn: 0.0246659\ttotal: 53.3s\tremaining: 11.1s\n",
            "827:\tlearn: 0.0246589\ttotal: 53.3s\tremaining: 11.1s\n",
            "828:\tlearn: 0.0246525\ttotal: 53.3s\tremaining: 11s\n",
            "829:\tlearn: 0.0246467\ttotal: 53.4s\tremaining: 10.9s\n",
            "830:\tlearn: 0.0246339\ttotal: 53.4s\tremaining: 10.9s\n",
            "831:\tlearn: 0.0245033\ttotal: 53.4s\tremaining: 10.8s\n",
            "832:\tlearn: 0.0244977\ttotal: 53.5s\tremaining: 10.7s\n",
            "833:\tlearn: 0.0244912\ttotal: 53.5s\tremaining: 10.6s\n",
            "834:\tlearn: 0.0243788\ttotal: 53.5s\tremaining: 10.6s\n",
            "835:\tlearn: 0.0243724\ttotal: 53.5s\tremaining: 10.5s\n",
            "836:\tlearn: 0.0243560\ttotal: 53.6s\tremaining: 10.4s\n",
            "837:\tlearn: 0.0242354\ttotal: 53.6s\tremaining: 10.4s\n",
            "838:\tlearn: 0.0241857\ttotal: 53.6s\tremaining: 10.3s\n",
            "839:\tlearn: 0.0241212\ttotal: 53.7s\tremaining: 10.2s\n",
            "840:\tlearn: 0.0241059\ttotal: 53.7s\tremaining: 10.2s\n",
            "841:\tlearn: 0.0240510\ttotal: 53.7s\tremaining: 10.1s\n",
            "842:\tlearn: 0.0240365\ttotal: 53.8s\tremaining: 10s\n",
            "843:\tlearn: 0.0240307\ttotal: 53.8s\tremaining: 9.94s\n",
            "844:\tlearn: 0.0239232\ttotal: 53.8s\tremaining: 9.87s\n",
            "845:\tlearn: 0.0239179\ttotal: 53.8s\tremaining: 9.8s\n",
            "846:\tlearn: 0.0239125\ttotal: 53.9s\tremaining: 9.73s\n",
            "847:\tlearn: 0.0238163\ttotal: 53.9s\tremaining: 9.66s\n",
            "848:\tlearn: 0.0237715\ttotal: 53.9s\tremaining: 9.59s\n",
            "849:\tlearn: 0.0237615\ttotal: 54s\tremaining: 9.52s\n",
            "850:\tlearn: 0.0237497\ttotal: 54s\tremaining: 9.45s\n",
            "851:\tlearn: 0.0237446\ttotal: 54s\tremaining: 9.38s\n",
            "852:\tlearn: 0.0237343\ttotal: 54s\tremaining: 9.31s\n",
            "853:\tlearn: 0.0237290\ttotal: 54.1s\tremaining: 9.24s\n",
            "854:\tlearn: 0.0237180\ttotal: 54.1s\tremaining: 9.17s\n",
            "855:\tlearn: 0.0237127\ttotal: 54.1s\tremaining: 9.11s\n",
            "856:\tlearn: 0.0236196\ttotal: 54.2s\tremaining: 9.04s\n",
            "857:\tlearn: 0.0235020\ttotal: 54.2s\tremaining: 8.97s\n",
            "858:\tlearn: 0.0233959\ttotal: 54.2s\tremaining: 8.9s\n",
            "859:\tlearn: 0.0233579\ttotal: 54.2s\tremaining: 8.83s\n",
            "860:\tlearn: 0.0232635\ttotal: 54.3s\tremaining: 8.76s\n",
            "861:\tlearn: 0.0232368\ttotal: 54.3s\tremaining: 8.69s\n",
            "862:\tlearn: 0.0231161\ttotal: 54.3s\tremaining: 8.62s\n",
            "863:\tlearn: 0.0230342\ttotal: 54.4s\tremaining: 8.56s\n",
            "864:\tlearn: 0.0230240\ttotal: 54.4s\tremaining: 8.49s\n",
            "865:\tlearn: 0.0230161\ttotal: 54.4s\tremaining: 8.42s\n",
            "866:\tlearn: 0.0229498\ttotal: 54.4s\tremaining: 8.35s\n",
            "867:\tlearn: 0.0229447\ttotal: 54.5s\tremaining: 8.28s\n",
            "868:\tlearn: 0.0228355\ttotal: 54.5s\tremaining: 8.21s\n",
            "869:\tlearn: 0.0227916\ttotal: 54.5s\tremaining: 8.15s\n",
            "870:\tlearn: 0.0227139\ttotal: 54.6s\tremaining: 8.08s\n",
            "871:\tlearn: 0.0227035\ttotal: 54.6s\tremaining: 8.01s\n",
            "872:\tlearn: 0.0226954\ttotal: 54.6s\tremaining: 7.94s\n",
            "873:\tlearn: 0.0225985\ttotal: 54.6s\tremaining: 7.88s\n",
            "874:\tlearn: 0.0225668\ttotal: 54.7s\tremaining: 7.81s\n",
            "875:\tlearn: 0.0224527\ttotal: 54.7s\tremaining: 7.74s\n",
            "876:\tlearn: 0.0224429\ttotal: 54.7s\tremaining: 7.67s\n",
            "877:\tlearn: 0.0223755\ttotal: 54.8s\tremaining: 7.61s\n",
            "878:\tlearn: 0.0222308\ttotal: 54.8s\tremaining: 7.54s\n",
            "879:\tlearn: 0.0221305\ttotal: 54.8s\tremaining: 7.48s\n",
            "880:\tlearn: 0.0221223\ttotal: 54.9s\tremaining: 7.41s\n",
            "881:\tlearn: 0.0220929\ttotal: 54.9s\tremaining: 7.34s\n",
            "882:\tlearn: 0.0220877\ttotal: 54.9s\tremaining: 7.28s\n",
            "883:\tlearn: 0.0220776\ttotal: 54.9s\tremaining: 7.21s\n",
            "884:\tlearn: 0.0220720\ttotal: 55s\tremaining: 7.14s\n",
            "885:\tlearn: 0.0220666\ttotal: 55s\tremaining: 7.08s\n",
            "886:\tlearn: 0.0219802\ttotal: 55s\tremaining: 7.01s\n",
            "887:\tlearn: 0.0218919\ttotal: 55.1s\tremaining: 6.94s\n",
            "888:\tlearn: 0.0218871\ttotal: 55.1s\tremaining: 6.88s\n",
            "889:\tlearn: 0.0218096\ttotal: 55.1s\tremaining: 6.81s\n",
            "890:\tlearn: 0.0217994\ttotal: 55.1s\tremaining: 6.75s\n",
            "891:\tlearn: 0.0217771\ttotal: 55.2s\tremaining: 6.68s\n",
            "892:\tlearn: 0.0217725\ttotal: 55.2s\tremaining: 6.61s\n",
            "893:\tlearn: 0.0217321\ttotal: 55.2s\tremaining: 6.55s\n",
            "894:\tlearn: 0.0217237\ttotal: 55.2s\tremaining: 6.48s\n",
            "895:\tlearn: 0.0217148\ttotal: 55.3s\tremaining: 6.42s\n",
            "896:\tlearn: 0.0217105\ttotal: 55.3s\tremaining: 6.35s\n",
            "897:\tlearn: 0.0217065\ttotal: 55.3s\tremaining: 6.29s\n",
            "898:\tlearn: 0.0216255\ttotal: 55.4s\tremaining: 6.22s\n",
            "899:\tlearn: 0.0216160\ttotal: 55.4s\tremaining: 6.15s\n",
            "900:\tlearn: 0.0215317\ttotal: 55.4s\tremaining: 6.09s\n",
            "901:\tlearn: 0.0214415\ttotal: 55.4s\tremaining: 6.02s\n",
            "902:\tlearn: 0.0213960\ttotal: 55.5s\tremaining: 5.96s\n",
            "903:\tlearn: 0.0213407\ttotal: 55.5s\tremaining: 5.89s\n",
            "904:\tlearn: 0.0213321\ttotal: 55.5s\tremaining: 5.83s\n",
            "905:\tlearn: 0.0213230\ttotal: 55.6s\tremaining: 5.76s\n",
            "906:\tlearn: 0.0213185\ttotal: 55.6s\tremaining: 5.7s\n",
            "907:\tlearn: 0.0212486\ttotal: 55.6s\tremaining: 5.63s\n",
            "908:\tlearn: 0.0212396\ttotal: 55.6s\tremaining: 5.57s\n",
            "909:\tlearn: 0.0212310\ttotal: 55.7s\tremaining: 5.5s\n",
            "910:\tlearn: 0.0211183\ttotal: 55.7s\tremaining: 5.44s\n",
            "911:\tlearn: 0.0210341\ttotal: 55.7s\tremaining: 5.38s\n",
            "912:\tlearn: 0.0209750\ttotal: 55.8s\tremaining: 5.31s\n",
            "913:\tlearn: 0.0209049\ttotal: 55.8s\tremaining: 5.25s\n",
            "914:\tlearn: 0.0208570\ttotal: 55.8s\tremaining: 5.18s\n",
            "915:\tlearn: 0.0208475\ttotal: 55.9s\tremaining: 5.12s\n",
            "916:\tlearn: 0.0208403\ttotal: 55.9s\tremaining: 5.06s\n",
            "917:\tlearn: 0.0207789\ttotal: 55.9s\tremaining: 4.99s\n",
            "918:\tlearn: 0.0206912\ttotal: 55.9s\tremaining: 4.93s\n",
            "919:\tlearn: 0.0206384\ttotal: 56s\tremaining: 4.87s\n",
            "920:\tlearn: 0.0205593\ttotal: 56s\tremaining: 4.8s\n",
            "921:\tlearn: 0.0205011\ttotal: 56s\tremaining: 4.74s\n",
            "922:\tlearn: 0.0204425\ttotal: 56.1s\tremaining: 4.68s\n",
            "923:\tlearn: 0.0203945\ttotal: 56.1s\tremaining: 4.61s\n",
            "924:\tlearn: 0.0203320\ttotal: 56.1s\tremaining: 4.55s\n",
            "925:\tlearn: 0.0203202\ttotal: 56.1s\tremaining: 4.49s\n",
            "926:\tlearn: 0.0203111\ttotal: 56.2s\tremaining: 4.42s\n",
            "927:\tlearn: 0.0202568\ttotal: 56.2s\tremaining: 4.36s\n",
            "928:\tlearn: 0.0202502\ttotal: 56.2s\tremaining: 4.3s\n",
            "929:\tlearn: 0.0201877\ttotal: 56.3s\tremaining: 4.23s\n",
            "930:\tlearn: 0.0201839\ttotal: 56.3s\tremaining: 4.17s\n",
            "931:\tlearn: 0.0201007\ttotal: 56.3s\tremaining: 4.11s\n",
            "932:\tlearn: 0.0200230\ttotal: 56.4s\tremaining: 4.05s\n",
            "933:\tlearn: 0.0200117\ttotal: 56.4s\tremaining: 3.98s\n",
            "934:\tlearn: 0.0200029\ttotal: 56.4s\tremaining: 3.92s\n",
            "935:\tlearn: 0.0199989\ttotal: 56.4s\tremaining: 3.86s\n",
            "936:\tlearn: 0.0199910\ttotal: 56.5s\tremaining: 3.8s\n",
            "937:\tlearn: 0.0199869\ttotal: 56.5s\tremaining: 3.73s\n",
            "938:\tlearn: 0.0198989\ttotal: 56.5s\tremaining: 3.67s\n",
            "939:\tlearn: 0.0198898\ttotal: 56.6s\tremaining: 3.61s\n",
            "940:\tlearn: 0.0198867\ttotal: 56.6s\tremaining: 3.55s\n",
            "941:\tlearn: 0.0198152\ttotal: 56.6s\tremaining: 3.48s\n",
            "942:\tlearn: 0.0197754\ttotal: 56.6s\tremaining: 3.42s\n",
            "943:\tlearn: 0.0197203\ttotal: 56.7s\tremaining: 3.36s\n",
            "944:\tlearn: 0.0196681\ttotal: 56.7s\tremaining: 3.3s\n",
            "945:\tlearn: 0.0195774\ttotal: 56.7s\tremaining: 3.24s\n",
            "946:\tlearn: 0.0195511\ttotal: 56.8s\tremaining: 3.18s\n",
            "947:\tlearn: 0.0194790\ttotal: 56.8s\tremaining: 3.12s\n",
            "948:\tlearn: 0.0194751\ttotal: 56.8s\tremaining: 3.05s\n",
            "949:\tlearn: 0.0194447\ttotal: 56.9s\tremaining: 2.99s\n",
            "950:\tlearn: 0.0194375\ttotal: 56.9s\tremaining: 2.93s\n",
            "951:\tlearn: 0.0193713\ttotal: 56.9s\tremaining: 2.87s\n",
            "952:\tlearn: 0.0192892\ttotal: 56.9s\tremaining: 2.81s\n",
            "953:\tlearn: 0.0192855\ttotal: 57s\tremaining: 2.75s\n",
            "954:\tlearn: 0.0192747\ttotal: 57s\tremaining: 2.69s\n",
            "955:\tlearn: 0.0192712\ttotal: 57s\tremaining: 2.62s\n",
            "956:\tlearn: 0.0192672\ttotal: 57.1s\tremaining: 2.56s\n",
            "957:\tlearn: 0.0191939\ttotal: 57.1s\tremaining: 2.5s\n",
            "958:\tlearn: 0.0191602\ttotal: 57.1s\tremaining: 2.44s\n",
            "959:\tlearn: 0.0190983\ttotal: 57.2s\tremaining: 2.38s\n",
            "960:\tlearn: 0.0190635\ttotal: 57.2s\tremaining: 2.32s\n",
            "961:\tlearn: 0.0189828\ttotal: 57.3s\tremaining: 2.26s\n",
            "962:\tlearn: 0.0189757\ttotal: 57.3s\tremaining: 2.2s\n",
            "963:\tlearn: 0.0189720\ttotal: 57.4s\tremaining: 2.14s\n",
            "964:\tlearn: 0.0189654\ttotal: 57.4s\tremaining: 2.08s\n",
            "965:\tlearn: 0.0189348\ttotal: 57.5s\tremaining: 2.02s\n",
            "966:\tlearn: 0.0189274\ttotal: 57.5s\tremaining: 1.96s\n",
            "967:\tlearn: 0.0188827\ttotal: 57.6s\tremaining: 1.9s\n",
            "968:\tlearn: 0.0188199\ttotal: 57.6s\tremaining: 1.84s\n",
            "969:\tlearn: 0.0187938\ttotal: 57.7s\tremaining: 1.78s\n",
            "970:\tlearn: 0.0187875\ttotal: 57.7s\tremaining: 1.72s\n",
            "971:\tlearn: 0.0187791\ttotal: 57.8s\tremaining: 1.67s\n",
            "972:\tlearn: 0.0187758\ttotal: 57.9s\tremaining: 1.6s\n",
            "973:\tlearn: 0.0187653\ttotal: 57.9s\tremaining: 1.54s\n",
            "974:\tlearn: 0.0187614\ttotal: 58s\tremaining: 1.49s\n",
            "975:\tlearn: 0.0186718\ttotal: 58s\tremaining: 1.43s\n",
            "976:\tlearn: 0.0186209\ttotal: 58.1s\tremaining: 1.37s\n",
            "977:\tlearn: 0.0186175\ttotal: 58.1s\tremaining: 1.31s\n",
            "978:\tlearn: 0.0185028\ttotal: 58.2s\tremaining: 1.25s\n",
            "979:\tlearn: 0.0184774\ttotal: 58.2s\tremaining: 1.19s\n",
            "980:\tlearn: 0.0184690\ttotal: 58.3s\tremaining: 1.13s\n",
            "981:\tlearn: 0.0183861\ttotal: 58.3s\tremaining: 1.07s\n",
            "982:\tlearn: 0.0183761\ttotal: 58.4s\tremaining: 1.01s\n",
            "983:\tlearn: 0.0183664\ttotal: 58.4s\tremaining: 950ms\n",
            "984:\tlearn: 0.0183626\ttotal: 58.5s\tremaining: 890ms\n",
            "985:\tlearn: 0.0183596\ttotal: 58.5s\tremaining: 831ms\n",
            "986:\tlearn: 0.0182800\ttotal: 58.6s\tremaining: 771ms\n",
            "987:\tlearn: 0.0182356\ttotal: 58.6s\tremaining: 712ms\n",
            "988:\tlearn: 0.0182113\ttotal: 58.7s\tremaining: 652ms\n",
            "989:\tlearn: 0.0182078\ttotal: 58.7s\tremaining: 593ms\n",
            "990:\tlearn: 0.0182043\ttotal: 58.8s\tremaining: 534ms\n",
            "991:\tlearn: 0.0182009\ttotal: 58.8s\tremaining: 474ms\n",
            "992:\tlearn: 0.0181976\ttotal: 58.9s\tremaining: 415ms\n",
            "993:\tlearn: 0.0181884\ttotal: 58.9s\tremaining: 356ms\n",
            "994:\tlearn: 0.0181444\ttotal: 59s\tremaining: 296ms\n",
            "995:\tlearn: 0.0180937\ttotal: 59s\tremaining: 237ms\n",
            "996:\tlearn: 0.0180533\ttotal: 59.1s\tremaining: 178ms\n",
            "997:\tlearn: 0.0180457\ttotal: 59.1s\tremaining: 119ms\n",
            "998:\tlearn: 0.0179745\ttotal: 59.2s\tremaining: 59.2ms\n",
            "999:\tlearn: 0.0179711\ttotal: 59.2s\tremaining: 0us\n",
            "Accuracy: 0.8837209302325582\n",
            "Precision: 0.9057196731615336\n",
            "Recall: 0.8837209302325582\n",
            "F1-score: 0.8821739226522208\n",
            "Training Time: 60.47972798347473\n",
            "CPU times: user 39.4 s, sys: 14 s, total: 53.4 s\n",
            "Wall time: 1min\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**13. Stochastic Gradient Descent (SGD)**"
      ],
      "metadata": {
        "id": "MfzCGwacnmM2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "start_time = time.time()\n",
        "sgd = SGDClassifier()\n",
        "sgd.fit(X_train, y_train)\n",
        "y_pred = sgd.predict(X_test)\n",
        "\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "\n",
        "results['Stochastic Gradient Descent (SGD)'] = [accuracy_score(y_test, y_pred),\n",
        "                                  precision_score(y_test, y_pred, average='weighted'),\n",
        "                                  recall_score(y_test, y_pred, average='weighted'),\n",
        "                                  f1_score(y_test, y_pred, average='weighted'),\n",
        "                                  training_time]\n",
        "print(\"Accuracy:\", results['Stochastic Gradient Descent (SGD)'][0])\n",
        "print(\"Precision:\", results['Stochastic Gradient Descent (SGD)'][1])\n",
        "print(\"Recall:\", results['Stochastic Gradient Descent (SGD)'][2])\n",
        "print(\"F1-score:\", results['Stochastic Gradient Descent (SGD)'][3])\n",
        "print(\"Training Time:\", results['Stochastic Gradient Descent (SGD)'][4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGYIMrV1noie",
        "outputId": "3f4450e8-3ebb-4fd8-9b53-a0a9a7c923c2"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8803986710963455\n",
            "Precision: 0.9035473154002786\n",
            "Recall: 0.8803986710963455\n",
            "F1-score: 0.8787125621362376\n",
            "Training Time: 0.008233785629272461\n",
            "CPU times: user 23.5 ms, sys: 0 ns, total: 23.5 ms\n",
            "Wall time: 27.8 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**14. Linear Discriminant Analysis (LDA)**"
      ],
      "metadata": {
        "id": "hFd3OieZKDX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "\n",
        "# Initialize Linear Discriminant Analysis (LDA)\n",
        "lda = LinearDiscriminantAnalysis()\n",
        "\n",
        "# Train the classifier\n",
        "start_time = time.time()\n",
        "lda.fit(X_train.toarray(), y_train)  # Convert sparse matrix to dense array\n",
        "training_time = time.time() - start_time\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = lda.predict(X_test.toarray())  # Convert sparse matrix to dense array\n",
        "\n",
        "# Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"Training Time:\", training_time)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaoOVVwFKERs",
        "outputId": "cdb4e3ff-7f22-418c-a31f-f40e72d36163"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9269102990033222\n",
            "Precision: 0.9331301676117203\n",
            "Recall: 0.9269102990033222\n",
            "F1-score: 0.9266626525277157\n",
            "Training Time: 5.1834142208099365\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**15. Quadratic Discriminant Analysis (QDA)**"
      ],
      "metadata": {
        "id": "r-Kr6q8VKIyi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "\n",
        "# Initialize Quadratic Discriminant Analysis (QDA)\n",
        "qda = QuadraticDiscriminantAnalysis()\n",
        "\n",
        "# Train the classifier\n",
        "start_time = time.time()\n",
        "qda.fit(X_train.toarray(), y_train)  # Convert sparse matrix to dense array\n",
        "training_time = time.time() - start_time\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = qda.predict(X_test.toarray())  # Convert sparse matrix to dense array\n",
        "\n",
        "# Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"Training Time:\", training_time)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPrQyz2rKMbZ",
        "outputId": "b8a328f1-13cd-4437-87ff-fd582db4d901"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n",
            "Training Time: 2.2483327388763428\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Networks ðŸ§ "
      ],
      "metadata": {
        "id": "oTHFBxWJKRym"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "creating NN layers and compiling with loss, metrics, optimizer configs"
      ],
      "metadata": {
        "id": "eeuS5khpopxU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training NN"
      ],
      "metadata": {
        "id": "_Q-qs1TXoqfJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Convert SparseTensor to dense numpy arrays\n",
        "X_train_dense = X_train.toarray()\n",
        "X_test_dense = X_test.toarray()\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "model.compile(loss='binary_crossentropy', metrics=['binary_accuracy'], optimizer='adam')\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "history = model.fit(X_train_dense,\n",
        "                     y_train,\n",
        "                     epochs=500,\n",
        "                     verbose=1,\n",
        "                     batch_size=32,\n",
        "                     validation_data=(X_test_dense, y_test))\n",
        "\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-3YIzhuKXLz",
        "outputId": "8f153534-86d3-4ea1-c6eb-35105299dc5f"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "47/47 [==============================] - 1s 9ms/step - loss: 0.5482 - binary_accuracy: 0.7153 - val_loss: 0.5555 - val_binary_accuracy: 0.5648\n",
            "Epoch 2/500\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.1111 - binary_accuracy: 0.9840 - val_loss: 0.3417 - val_binary_accuracy: 0.8671\n",
            "Epoch 3/500\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 0.0148 - binary_accuracy: 0.9967 - val_loss: 0.3893 - val_binary_accuracy: 0.8738\n",
            "Epoch 4/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.0047 - binary_accuracy: 1.0000 - val_loss: 0.3990 - val_binary_accuracy: 0.8738\n",
            "Epoch 5/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.0024 - binary_accuracy: 1.0000 - val_loss: 0.4449 - val_binary_accuracy: 0.8738\n",
            "Epoch 6/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.0015 - binary_accuracy: 1.0000 - val_loss: 0.4660 - val_binary_accuracy: 0.8738\n",
            "Epoch 7/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 9.9138e-04 - binary_accuracy: 1.0000 - val_loss: 0.4836 - val_binary_accuracy: 0.8738\n",
            "Epoch 8/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 7.1975e-04 - binary_accuracy: 1.0000 - val_loss: 0.5062 - val_binary_accuracy: 0.8738\n",
            "Epoch 9/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 5.4336e-04 - binary_accuracy: 1.0000 - val_loss: 0.5233 - val_binary_accuracy: 0.8738\n",
            "Epoch 10/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 4.2334e-04 - binary_accuracy: 1.0000 - val_loss: 0.5353 - val_binary_accuracy: 0.8738\n",
            "Epoch 11/500\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 3.3948e-04 - binary_accuracy: 1.0000 - val_loss: 0.5470 - val_binary_accuracy: 0.8738\n",
            "Epoch 12/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 2.7625e-04 - binary_accuracy: 1.0000 - val_loss: 0.5576 - val_binary_accuracy: 0.8738\n",
            "Epoch 13/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 2.3025e-04 - binary_accuracy: 1.0000 - val_loss: 0.5737 - val_binary_accuracy: 0.8738\n",
            "Epoch 14/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.9593e-04 - binary_accuracy: 1.0000 - val_loss: 0.5855 - val_binary_accuracy: 0.8738\n",
            "Epoch 15/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.6741e-04 - binary_accuracy: 1.0000 - val_loss: 0.5963 - val_binary_accuracy: 0.8738\n",
            "Epoch 16/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.4518e-04 - binary_accuracy: 1.0000 - val_loss: 0.6013 - val_binary_accuracy: 0.8738\n",
            "Epoch 17/500\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 1.2654e-04 - binary_accuracy: 1.0000 - val_loss: 0.6130 - val_binary_accuracy: 0.8738\n",
            "Epoch 18/500\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 1.1102e-04 - binary_accuracy: 1.0000 - val_loss: 0.6231 - val_binary_accuracy: 0.8738\n",
            "Epoch 19/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 9.8356e-05 - binary_accuracy: 1.0000 - val_loss: 0.6314 - val_binary_accuracy: 0.8738\n",
            "Epoch 20/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 8.7655e-05 - binary_accuracy: 1.0000 - val_loss: 0.6381 - val_binary_accuracy: 0.8738\n",
            "Epoch 21/500\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 7.8385e-05 - binary_accuracy: 1.0000 - val_loss: 0.6443 - val_binary_accuracy: 0.8738\n",
            "Epoch 22/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 7.0596e-05 - binary_accuracy: 1.0000 - val_loss: 0.6499 - val_binary_accuracy: 0.8738\n",
            "Epoch 23/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 6.3779e-05 - binary_accuracy: 1.0000 - val_loss: 0.6550 - val_binary_accuracy: 0.8738\n",
            "Epoch 24/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 5.7706e-05 - binary_accuracy: 1.0000 - val_loss: 0.6623 - val_binary_accuracy: 0.8738\n",
            "Epoch 25/500\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 5.2618e-05 - binary_accuracy: 1.0000 - val_loss: 0.6698 - val_binary_accuracy: 0.8738\n",
            "Epoch 26/500\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 4.7916e-05 - binary_accuracy: 1.0000 - val_loss: 0.6746 - val_binary_accuracy: 0.8738\n",
            "Epoch 27/500\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 4.3829e-05 - binary_accuracy: 1.0000 - val_loss: 0.6802 - val_binary_accuracy: 0.8738\n",
            "Epoch 28/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 4.0291e-05 - binary_accuracy: 1.0000 - val_loss: 0.6857 - val_binary_accuracy: 0.8738\n",
            "Epoch 29/500\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 3.7082e-05 - binary_accuracy: 1.0000 - val_loss: 0.6919 - val_binary_accuracy: 0.8738\n",
            "Epoch 30/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 3.4260e-05 - binary_accuracy: 1.0000 - val_loss: 0.6960 - val_binary_accuracy: 0.8738\n",
            "Epoch 31/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 3.1652e-05 - binary_accuracy: 1.0000 - val_loss: 0.7024 - val_binary_accuracy: 0.8738\n",
            "Epoch 32/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 2.9403e-05 - binary_accuracy: 1.0000 - val_loss: 0.7065 - val_binary_accuracy: 0.8738\n",
            "Epoch 33/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 2.7274e-05 - binary_accuracy: 1.0000 - val_loss: 0.7120 - val_binary_accuracy: 0.8738\n",
            "Epoch 34/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 2.5413e-05 - binary_accuracy: 1.0000 - val_loss: 0.7162 - val_binary_accuracy: 0.8738\n",
            "Epoch 35/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 2.3691e-05 - binary_accuracy: 1.0000 - val_loss: 0.7207 - val_binary_accuracy: 0.8738\n",
            "Epoch 36/500\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 2.2101e-05 - binary_accuracy: 1.0000 - val_loss: 0.7257 - val_binary_accuracy: 0.8738\n",
            "Epoch 37/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 2.0696e-05 - binary_accuracy: 1.0000 - val_loss: 0.7293 - val_binary_accuracy: 0.8738\n",
            "Epoch 38/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.9373e-05 - binary_accuracy: 1.0000 - val_loss: 0.7340 - val_binary_accuracy: 0.8738\n",
            "Epoch 39/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.8167e-05 - binary_accuracy: 1.0000 - val_loss: 0.7384 - val_binary_accuracy: 0.8738\n",
            "Epoch 40/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.7070e-05 - binary_accuracy: 1.0000 - val_loss: 0.7430 - val_binary_accuracy: 0.8738\n",
            "Epoch 41/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.6077e-05 - binary_accuracy: 1.0000 - val_loss: 0.7462 - val_binary_accuracy: 0.8738\n",
            "Epoch 42/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.5110e-05 - binary_accuracy: 1.0000 - val_loss: 0.7496 - val_binary_accuracy: 0.8738\n",
            "Epoch 43/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.4260e-05 - binary_accuracy: 1.0000 - val_loss: 0.7539 - val_binary_accuracy: 0.8738\n",
            "Epoch 44/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.3455e-05 - binary_accuracy: 1.0000 - val_loss: 0.7588 - val_binary_accuracy: 0.8738\n",
            "Epoch 45/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.2716e-05 - binary_accuracy: 1.0000 - val_loss: 0.7605 - val_binary_accuracy: 0.8738\n",
            "Epoch 46/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.2016e-05 - binary_accuracy: 1.0000 - val_loss: 0.7662 - val_binary_accuracy: 0.8738\n",
            "Epoch 47/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.1379e-05 - binary_accuracy: 1.0000 - val_loss: 0.7691 - val_binary_accuracy: 0.8738\n",
            "Epoch 48/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.0778e-05 - binary_accuracy: 1.0000 - val_loss: 0.7726 - val_binary_accuracy: 0.8738\n",
            "Epoch 49/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.0223e-05 - binary_accuracy: 1.0000 - val_loss: 0.7769 - val_binary_accuracy: 0.8738\n",
            "Epoch 50/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 9.6919e-06 - binary_accuracy: 1.0000 - val_loss: 0.7801 - val_binary_accuracy: 0.8738\n",
            "Epoch 51/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 9.2153e-06 - binary_accuracy: 1.0000 - val_loss: 0.7832 - val_binary_accuracy: 0.8738\n",
            "Epoch 52/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 8.7544e-06 - binary_accuracy: 1.0000 - val_loss: 0.7866 - val_binary_accuracy: 0.8738\n",
            "Epoch 53/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 8.3250e-06 - binary_accuracy: 1.0000 - val_loss: 0.7910 - val_binary_accuracy: 0.8738\n",
            "Epoch 54/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 7.9226e-06 - binary_accuracy: 1.0000 - val_loss: 0.7936 - val_binary_accuracy: 0.8738\n",
            "Epoch 55/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 7.5489e-06 - binary_accuracy: 1.0000 - val_loss: 0.7957 - val_binary_accuracy: 0.8738\n",
            "Epoch 56/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 7.1933e-06 - binary_accuracy: 1.0000 - val_loss: 0.7999 - val_binary_accuracy: 0.8738\n",
            "Epoch 57/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 6.8583e-06 - binary_accuracy: 1.0000 - val_loss: 0.8028 - val_binary_accuracy: 0.8738\n",
            "Epoch 58/500\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 6.5511e-06 - binary_accuracy: 1.0000 - val_loss: 0.8063 - val_binary_accuracy: 0.8738\n",
            "Epoch 59/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 6.2519e-06 - binary_accuracy: 1.0000 - val_loss: 0.8099 - val_binary_accuracy: 0.8738\n",
            "Epoch 60/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 5.9756e-06 - binary_accuracy: 1.0000 - val_loss: 0.8122 - val_binary_accuracy: 0.8738\n",
            "Epoch 61/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 5.7092e-06 - binary_accuracy: 1.0000 - val_loss: 0.8163 - val_binary_accuracy: 0.8738\n",
            "Epoch 62/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 5.4611e-06 - binary_accuracy: 1.0000 - val_loss: 0.8187 - val_binary_accuracy: 0.8738\n",
            "Epoch 63/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 5.2226e-06 - binary_accuracy: 1.0000 - val_loss: 0.8201 - val_binary_accuracy: 0.8738\n",
            "Epoch 64/500\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 4.9996e-06 - binary_accuracy: 1.0000 - val_loss: 0.8254 - val_binary_accuracy: 0.8738\n",
            "Epoch 65/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 4.7876e-06 - binary_accuracy: 1.0000 - val_loss: 0.8278 - val_binary_accuracy: 0.8738\n",
            "Epoch 66/500\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 4.5871e-06 - binary_accuracy: 1.0000 - val_loss: 0.8299 - val_binary_accuracy: 0.8738\n",
            "Epoch 67/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 4.3943e-06 - binary_accuracy: 1.0000 - val_loss: 0.8330 - val_binary_accuracy: 0.8738\n",
            "Epoch 68/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 4.2164e-06 - binary_accuracy: 1.0000 - val_loss: 0.8363 - val_binary_accuracy: 0.8738\n",
            "Epoch 69/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 4.0422e-06 - binary_accuracy: 1.0000 - val_loss: 0.8394 - val_binary_accuracy: 0.8738\n",
            "Epoch 70/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 3.8795e-06 - binary_accuracy: 1.0000 - val_loss: 0.8428 - val_binary_accuracy: 0.8738\n",
            "Epoch 71/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 3.7285e-06 - binary_accuracy: 1.0000 - val_loss: 0.8461 - val_binary_accuracy: 0.8738\n",
            "Epoch 72/500\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 3.5769e-06 - binary_accuracy: 1.0000 - val_loss: 0.8479 - val_binary_accuracy: 0.8738\n",
            "Epoch 73/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 3.4355e-06 - binary_accuracy: 1.0000 - val_loss: 0.8502 - val_binary_accuracy: 0.8738\n",
            "Epoch 74/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 3.3048e-06 - binary_accuracy: 1.0000 - val_loss: 0.8534 - val_binary_accuracy: 0.8738\n",
            "Epoch 75/500\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 3.1738e-06 - binary_accuracy: 1.0000 - val_loss: 0.8563 - val_binary_accuracy: 0.8738\n",
            "Epoch 76/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 3.0517e-06 - binary_accuracy: 1.0000 - val_loss: 0.8588 - val_binary_accuracy: 0.8738\n",
            "Epoch 77/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 2.9375e-06 - binary_accuracy: 1.0000 - val_loss: 0.8617 - val_binary_accuracy: 0.8738\n",
            "Epoch 78/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 2.8261e-06 - binary_accuracy: 1.0000 - val_loss: 0.8647 - val_binary_accuracy: 0.8738\n",
            "Epoch 79/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 2.7201e-06 - binary_accuracy: 1.0000 - val_loss: 0.8665 - val_binary_accuracy: 0.8738\n",
            "Epoch 80/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 2.6202e-06 - binary_accuracy: 1.0000 - val_loss: 0.8699 - val_binary_accuracy: 0.8738\n",
            "Epoch 81/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 2.5225e-06 - binary_accuracy: 1.0000 - val_loss: 0.8723 - val_binary_accuracy: 0.8738\n",
            "Epoch 82/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 2.4300e-06 - binary_accuracy: 1.0000 - val_loss: 0.8748 - val_binary_accuracy: 0.8738\n",
            "Epoch 83/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 2.3418e-06 - binary_accuracy: 1.0000 - val_loss: 0.8781 - val_binary_accuracy: 0.8738\n",
            "Epoch 84/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 2.2574e-06 - binary_accuracy: 1.0000 - val_loss: 0.8800 - val_binary_accuracy: 0.8738\n",
            "Epoch 85/500\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 2.1789e-06 - binary_accuracy: 1.0000 - val_loss: 0.8834 - val_binary_accuracy: 0.8738\n",
            "Epoch 86/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 2.1018e-06 - binary_accuracy: 1.0000 - val_loss: 0.8854 - val_binary_accuracy: 0.8738\n",
            "Epoch 87/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 2.0251e-06 - binary_accuracy: 1.0000 - val_loss: 0.8877 - val_binary_accuracy: 0.8738\n",
            "Epoch 88/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.9537e-06 - binary_accuracy: 1.0000 - val_loss: 0.8902 - val_binary_accuracy: 0.8738\n",
            "Epoch 89/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.8853e-06 - binary_accuracy: 1.0000 - val_loss: 0.8923 - val_binary_accuracy: 0.8738\n",
            "Epoch 90/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.8197e-06 - binary_accuracy: 1.0000 - val_loss: 0.8957 - val_binary_accuracy: 0.8738\n",
            "Epoch 91/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.7577e-06 - binary_accuracy: 1.0000 - val_loss: 0.8981 - val_binary_accuracy: 0.8738\n",
            "Epoch 92/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.6972e-06 - binary_accuracy: 1.0000 - val_loss: 0.9011 - val_binary_accuracy: 0.8738\n",
            "Epoch 93/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.6397e-06 - binary_accuracy: 1.0000 - val_loss: 0.9023 - val_binary_accuracy: 0.8738\n",
            "Epoch 94/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.5844e-06 - binary_accuracy: 1.0000 - val_loss: 0.9056 - val_binary_accuracy: 0.8738\n",
            "Epoch 95/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.5301e-06 - binary_accuracy: 1.0000 - val_loss: 0.9086 - val_binary_accuracy: 0.8738\n",
            "Epoch 96/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.4786e-06 - binary_accuracy: 1.0000 - val_loss: 0.9108 - val_binary_accuracy: 0.8738\n",
            "Epoch 97/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.4282e-06 - binary_accuracy: 1.0000 - val_loss: 0.9121 - val_binary_accuracy: 0.8738\n",
            "Epoch 98/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.3805e-06 - binary_accuracy: 1.0000 - val_loss: 0.9153 - val_binary_accuracy: 0.8738\n",
            "Epoch 99/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.3346e-06 - binary_accuracy: 1.0000 - val_loss: 0.9175 - val_binary_accuracy: 0.8738\n",
            "Epoch 100/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.2906e-06 - binary_accuracy: 1.0000 - val_loss: 0.9204 - val_binary_accuracy: 0.8738\n",
            "Epoch 101/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.2475e-06 - binary_accuracy: 1.0000 - val_loss: 0.9225 - val_binary_accuracy: 0.8738\n",
            "Epoch 102/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.2074e-06 - binary_accuracy: 1.0000 - val_loss: 0.9253 - val_binary_accuracy: 0.8738\n",
            "Epoch 103/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.1672e-06 - binary_accuracy: 1.0000 - val_loss: 0.9273 - val_binary_accuracy: 0.8738\n",
            "Epoch 104/500\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 1.1299e-06 - binary_accuracy: 1.0000 - val_loss: 0.9301 - val_binary_accuracy: 0.8738\n",
            "Epoch 105/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.0928e-06 - binary_accuracy: 1.0000 - val_loss: 0.9321 - val_binary_accuracy: 0.8738\n",
            "Epoch 106/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.0580e-06 - binary_accuracy: 1.0000 - val_loss: 0.9344 - val_binary_accuracy: 0.8738\n",
            "Epoch 107/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.0240e-06 - binary_accuracy: 1.0000 - val_loss: 0.9375 - val_binary_accuracy: 0.8738\n",
            "Epoch 108/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 9.9212e-07 - binary_accuracy: 1.0000 - val_loss: 0.9397 - val_binary_accuracy: 0.8738\n",
            "Epoch 109/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 9.6014e-07 - binary_accuracy: 1.0000 - val_loss: 0.9419 - val_binary_accuracy: 0.8738\n",
            "Epoch 110/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 9.3033e-07 - binary_accuracy: 1.0000 - val_loss: 0.9446 - val_binary_accuracy: 0.8738\n",
            "Epoch 111/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 9.0106e-07 - binary_accuracy: 1.0000 - val_loss: 0.9468 - val_binary_accuracy: 0.8738\n",
            "Epoch 112/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 8.7298e-07 - binary_accuracy: 1.0000 - val_loss: 0.9487 - val_binary_accuracy: 0.8738\n",
            "Epoch 113/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 8.4561e-07 - binary_accuracy: 1.0000 - val_loss: 0.9509 - val_binary_accuracy: 0.8738\n",
            "Epoch 114/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 8.1936e-07 - binary_accuracy: 1.0000 - val_loss: 0.9536 - val_binary_accuracy: 0.8738\n",
            "Epoch 115/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 7.9391e-07 - binary_accuracy: 1.0000 - val_loss: 0.9556 - val_binary_accuracy: 0.8738\n",
            "Epoch 116/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 7.6994e-07 - binary_accuracy: 1.0000 - val_loss: 0.9580 - val_binary_accuracy: 0.8738\n",
            "Epoch 117/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 7.4600e-07 - binary_accuracy: 1.0000 - val_loss: 0.9609 - val_binary_accuracy: 0.8738\n",
            "Epoch 118/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 7.2289e-07 - binary_accuracy: 1.0000 - val_loss: 0.9625 - val_binary_accuracy: 0.8738\n",
            "Epoch 119/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 7.0088e-07 - binary_accuracy: 1.0000 - val_loss: 0.9653 - val_binary_accuracy: 0.8738\n",
            "Epoch 120/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 6.7984e-07 - binary_accuracy: 1.0000 - val_loss: 0.9670 - val_binary_accuracy: 0.8738\n",
            "Epoch 121/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 6.5911e-07 - binary_accuracy: 1.0000 - val_loss: 0.9694 - val_binary_accuracy: 0.8738\n",
            "Epoch 122/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 6.3917e-07 - binary_accuracy: 1.0000 - val_loss: 0.9723 - val_binary_accuracy: 0.8738\n",
            "Epoch 123/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 6.1996e-07 - binary_accuracy: 1.0000 - val_loss: 0.9745 - val_binary_accuracy: 0.8738\n",
            "Epoch 124/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 6.0126e-07 - binary_accuracy: 1.0000 - val_loss: 0.9762 - val_binary_accuracy: 0.8738\n",
            "Epoch 125/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 5.8348e-07 - binary_accuracy: 1.0000 - val_loss: 0.9781 - val_binary_accuracy: 0.8738\n",
            "Epoch 126/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 5.6600e-07 - binary_accuracy: 1.0000 - val_loss: 0.9811 - val_binary_accuracy: 0.8738\n",
            "Epoch 127/500\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 5.4905e-07 - binary_accuracy: 1.0000 - val_loss: 0.9838 - val_binary_accuracy: 0.8738\n",
            "Epoch 128/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 5.3282e-07 - binary_accuracy: 1.0000 - val_loss: 0.9858 - val_binary_accuracy: 0.8738\n",
            "Epoch 129/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 5.1726e-07 - binary_accuracy: 1.0000 - val_loss: 0.9883 - val_binary_accuracy: 0.8738\n",
            "Epoch 130/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 5.0227e-07 - binary_accuracy: 1.0000 - val_loss: 0.9904 - val_binary_accuracy: 0.8738\n",
            "Epoch 131/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 4.8739e-07 - binary_accuracy: 1.0000 - val_loss: 0.9920 - val_binary_accuracy: 0.8738\n",
            "Epoch 132/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 4.7339e-07 - binary_accuracy: 1.0000 - val_loss: 0.9950 - val_binary_accuracy: 0.8738\n",
            "Epoch 133/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 4.5942e-07 - binary_accuracy: 1.0000 - val_loss: 0.9962 - val_binary_accuracy: 0.8738\n",
            "Epoch 134/500\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 4.4615e-07 - binary_accuracy: 1.0000 - val_loss: 0.9992 - val_binary_accuracy: 0.8738\n",
            "Epoch 135/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 4.3331e-07 - binary_accuracy: 1.0000 - val_loss: 1.0016 - val_binary_accuracy: 0.8738\n",
            "Epoch 136/500\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 4.2073e-07 - binary_accuracy: 1.0000 - val_loss: 1.0038 - val_binary_accuracy: 0.8738\n",
            "Epoch 137/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 4.0866e-07 - binary_accuracy: 1.0000 - val_loss: 1.0058 - val_binary_accuracy: 0.8738\n",
            "Epoch 138/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 3.9697e-07 - binary_accuracy: 1.0000 - val_loss: 1.0073 - val_binary_accuracy: 0.8738\n",
            "Epoch 139/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 3.8604e-07 - binary_accuracy: 1.0000 - val_loss: 1.0113 - val_binary_accuracy: 0.8738\n",
            "Epoch 140/500\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 3.7492e-07 - binary_accuracy: 1.0000 - val_loss: 1.0126 - val_binary_accuracy: 0.8738\n",
            "Epoch 141/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 3.6388e-07 - binary_accuracy: 1.0000 - val_loss: 1.0144 - val_binary_accuracy: 0.8738\n",
            "Epoch 142/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 3.5377e-07 - binary_accuracy: 1.0000 - val_loss: 1.0171 - val_binary_accuracy: 0.8738\n",
            "Epoch 143/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 3.4379e-07 - binary_accuracy: 1.0000 - val_loss: 1.0186 - val_binary_accuracy: 0.8738\n",
            "Epoch 144/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 3.3396e-07 - binary_accuracy: 1.0000 - val_loss: 1.0210 - val_binary_accuracy: 0.8738\n",
            "Epoch 145/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 3.2452e-07 - binary_accuracy: 1.0000 - val_loss: 1.0233 - val_binary_accuracy: 0.8738\n",
            "Epoch 146/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 3.1558e-07 - binary_accuracy: 1.0000 - val_loss: 1.0256 - val_binary_accuracy: 0.8738\n",
            "Epoch 147/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 3.0658e-07 - binary_accuracy: 1.0000 - val_loss: 1.0276 - val_binary_accuracy: 0.8738\n",
            "Epoch 148/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 2.9809e-07 - binary_accuracy: 1.0000 - val_loss: 1.0299 - val_binary_accuracy: 0.8738\n",
            "Epoch 149/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 2.8983e-07 - binary_accuracy: 1.0000 - val_loss: 1.0318 - val_binary_accuracy: 0.8738\n",
            "Epoch 150/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 2.8181e-07 - binary_accuracy: 1.0000 - val_loss: 1.0336 - val_binary_accuracy: 0.8738\n",
            "Epoch 151/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 2.7394e-07 - binary_accuracy: 1.0000 - val_loss: 1.0365 - val_binary_accuracy: 0.8738\n",
            "Epoch 152/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 2.6632e-07 - binary_accuracy: 1.0000 - val_loss: 1.0384 - val_binary_accuracy: 0.8738\n",
            "Epoch 153/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 2.5899e-07 - binary_accuracy: 1.0000 - val_loss: 1.0406 - val_binary_accuracy: 0.8738\n",
            "Epoch 154/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 2.5187e-07 - binary_accuracy: 1.0000 - val_loss: 1.0430 - val_binary_accuracy: 0.8738\n",
            "Epoch 155/500\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 2.4501e-07 - binary_accuracy: 1.0000 - val_loss: 1.0451 - val_binary_accuracy: 0.8738\n",
            "Epoch 156/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 2.3822e-07 - binary_accuracy: 1.0000 - val_loss: 1.0471 - val_binary_accuracy: 0.8738\n",
            "Epoch 157/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 2.3167e-07 - binary_accuracy: 1.0000 - val_loss: 1.0492 - val_binary_accuracy: 0.8738\n",
            "Epoch 158/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 2.2534e-07 - binary_accuracy: 1.0000 - val_loss: 1.0513 - val_binary_accuracy: 0.8738\n",
            "Epoch 159/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 2.1925e-07 - binary_accuracy: 1.0000 - val_loss: 1.0532 - val_binary_accuracy: 0.8738\n",
            "Epoch 160/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 2.1333e-07 - binary_accuracy: 1.0000 - val_loss: 1.0549 - val_binary_accuracy: 0.8738\n",
            "Epoch 161/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 2.0753e-07 - binary_accuracy: 1.0000 - val_loss: 1.0576 - val_binary_accuracy: 0.8738\n",
            "Epoch 162/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 2.0187e-07 - binary_accuracy: 1.0000 - val_loss: 1.0594 - val_binary_accuracy: 0.8738\n",
            "Epoch 163/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.9651e-07 - binary_accuracy: 1.0000 - val_loss: 1.0625 - val_binary_accuracy: 0.8738\n",
            "Epoch 164/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.9121e-07 - binary_accuracy: 1.0000 - val_loss: 1.0632 - val_binary_accuracy: 0.8738\n",
            "Epoch 165/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.8607e-07 - binary_accuracy: 1.0000 - val_loss: 1.0652 - val_binary_accuracy: 0.8738\n",
            "Epoch 166/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.8113e-07 - binary_accuracy: 1.0000 - val_loss: 1.0681 - val_binary_accuracy: 0.8738\n",
            "Epoch 167/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.7623e-07 - binary_accuracy: 1.0000 - val_loss: 1.0704 - val_binary_accuracy: 0.8738\n",
            "Epoch 168/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.7152e-07 - binary_accuracy: 1.0000 - val_loss: 1.0725 - val_binary_accuracy: 0.8738\n",
            "Epoch 169/500\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 1.6697e-07 - binary_accuracy: 1.0000 - val_loss: 1.0742 - val_binary_accuracy: 0.8738\n",
            "Epoch 170/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.6255e-07 - binary_accuracy: 1.0000 - val_loss: 1.0756 - val_binary_accuracy: 0.8738\n",
            "Epoch 171/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.5827e-07 - binary_accuracy: 1.0000 - val_loss: 1.0788 - val_binary_accuracy: 0.8738\n",
            "Epoch 172/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.5402e-07 - binary_accuracy: 1.0000 - val_loss: 1.0804 - val_binary_accuracy: 0.8738\n",
            "Epoch 173/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.5001e-07 - binary_accuracy: 1.0000 - val_loss: 1.0825 - val_binary_accuracy: 0.8738\n",
            "Epoch 174/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.4606e-07 - binary_accuracy: 1.0000 - val_loss: 1.0843 - val_binary_accuracy: 0.8738\n",
            "Epoch 175/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.4227e-07 - binary_accuracy: 1.0000 - val_loss: 1.0863 - val_binary_accuracy: 0.8738\n",
            "Epoch 176/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.3849e-07 - binary_accuracy: 1.0000 - val_loss: 1.0886 - val_binary_accuracy: 0.8738\n",
            "Epoch 177/500\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 1.3484e-07 - binary_accuracy: 1.0000 - val_loss: 1.0907 - val_binary_accuracy: 0.8738\n",
            "Epoch 178/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.3136e-07 - binary_accuracy: 1.0000 - val_loss: 1.0925 - val_binary_accuracy: 0.8738\n",
            "Epoch 179/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.2794e-07 - binary_accuracy: 1.0000 - val_loss: 1.0950 - val_binary_accuracy: 0.8738\n",
            "Epoch 180/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.2461e-07 - binary_accuracy: 1.0000 - val_loss: 1.0960 - val_binary_accuracy: 0.8738\n",
            "Epoch 181/500\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.2141e-07 - binary_accuracy: 1.0000 - val_loss: 1.0992 - val_binary_accuracy: 0.8738\n",
            "Epoch 182/500\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.1814e-07 - binary_accuracy: 1.0000 - val_loss: 1.1008 - val_binary_accuracy: 0.8738\n",
            "Epoch 183/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 1.1509e-07 - binary_accuracy: 1.0000 - val_loss: 1.1028 - val_binary_accuracy: 0.8738\n",
            "Epoch 184/500\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 1.1212e-07 - binary_accuracy: 1.0000 - val_loss: 1.1049 - val_binary_accuracy: 0.8738\n",
            "Epoch 185/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 1.0927e-07 - binary_accuracy: 1.0000 - val_loss: 1.1063 - val_binary_accuracy: 0.8738\n",
            "Epoch 186/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 1.0642e-07 - binary_accuracy: 1.0000 - val_loss: 1.1091 - val_binary_accuracy: 0.8738\n",
            "Epoch 187/500\n",
            "47/47 [==============================] - 0s 11ms/step - loss: 1.0368e-07 - binary_accuracy: 1.0000 - val_loss: 1.1108 - val_binary_accuracy: 0.8738\n",
            "Epoch 188/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 1.0101e-07 - binary_accuracy: 1.0000 - val_loss: 1.1132 - val_binary_accuracy: 0.8738\n",
            "Epoch 189/500\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 9.8443e-08 - binary_accuracy: 1.0000 - val_loss: 1.1145 - val_binary_accuracy: 0.8738\n",
            "Epoch 190/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 9.5943e-08 - binary_accuracy: 1.0000 - val_loss: 1.1167 - val_binary_accuracy: 0.8738\n",
            "Epoch 191/500\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 9.3504e-08 - binary_accuracy: 1.0000 - val_loss: 1.1177 - val_binary_accuracy: 0.8738\n",
            "Epoch 192/500\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 9.1126e-08 - binary_accuracy: 1.0000 - val_loss: 1.1211 - val_binary_accuracy: 0.8738\n",
            "Epoch 193/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 8.8815e-08 - binary_accuracy: 1.0000 - val_loss: 1.1225 - val_binary_accuracy: 0.8738\n",
            "Epoch 194/500\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 8.6537e-08 - binary_accuracy: 1.0000 - val_loss: 1.1238 - val_binary_accuracy: 0.8738\n",
            "Epoch 195/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 8.4371e-08 - binary_accuracy: 1.0000 - val_loss: 1.1260 - val_binary_accuracy: 0.8738\n",
            "Epoch 196/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 8.2227e-08 - binary_accuracy: 1.0000 - val_loss: 1.1287 - val_binary_accuracy: 0.8738\n",
            "Epoch 197/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 8.0150e-08 - binary_accuracy: 1.0000 - val_loss: 1.1304 - val_binary_accuracy: 0.8738\n",
            "Epoch 198/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 7.8143e-08 - binary_accuracy: 1.0000 - val_loss: 1.1321 - val_binary_accuracy: 0.8738\n",
            "Epoch 199/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 7.6189e-08 - binary_accuracy: 1.0000 - val_loss: 1.1341 - val_binary_accuracy: 0.8738\n",
            "Epoch 200/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 7.4285e-08 - binary_accuracy: 1.0000 - val_loss: 1.1363 - val_binary_accuracy: 0.8738\n",
            "Epoch 201/500\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 7.2416e-08 - binary_accuracy: 1.0000 - val_loss: 1.1381 - val_binary_accuracy: 0.8738\n",
            "Epoch 202/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 7.0610e-08 - binary_accuracy: 1.0000 - val_loss: 1.1401 - val_binary_accuracy: 0.8738\n",
            "Epoch 203/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 6.8896e-08 - binary_accuracy: 1.0000 - val_loss: 1.1422 - val_binary_accuracy: 0.8738\n",
            "Epoch 204/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 6.7157e-08 - binary_accuracy: 1.0000 - val_loss: 1.1435 - val_binary_accuracy: 0.8738\n",
            "Epoch 205/500\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 6.5505e-08 - binary_accuracy: 1.0000 - val_loss: 1.1458 - val_binary_accuracy: 0.8738\n",
            "Epoch 206/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 6.3881e-08 - binary_accuracy: 1.0000 - val_loss: 1.1476 - val_binary_accuracy: 0.8738\n",
            "Epoch 207/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 6.2306e-08 - binary_accuracy: 1.0000 - val_loss: 1.1493 - val_binary_accuracy: 0.8738\n",
            "Epoch 208/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 6.0799e-08 - binary_accuracy: 1.0000 - val_loss: 1.1517 - val_binary_accuracy: 0.8738\n",
            "Epoch 209/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 5.9289e-08 - binary_accuracy: 1.0000 - val_loss: 1.1533 - val_binary_accuracy: 0.8738\n",
            "Epoch 210/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 5.7846e-08 - binary_accuracy: 1.0000 - val_loss: 1.1549 - val_binary_accuracy: 0.8738\n",
            "Epoch 211/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 5.6459e-08 - binary_accuracy: 1.0000 - val_loss: 1.1572 - val_binary_accuracy: 0.8738\n",
            "Epoch 212/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 5.5079e-08 - binary_accuracy: 1.0000 - val_loss: 1.1584 - val_binary_accuracy: 0.8738\n",
            "Epoch 213/500\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 5.3749e-08 - binary_accuracy: 1.0000 - val_loss: 1.1607 - val_binary_accuracy: 0.8738\n",
            "Epoch 214/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 5.2462e-08 - binary_accuracy: 1.0000 - val_loss: 1.1624 - val_binary_accuracy: 0.8738\n",
            "Epoch 215/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 5.1231e-08 - binary_accuracy: 1.0000 - val_loss: 1.1636 - val_binary_accuracy: 0.8738\n",
            "Epoch 216/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 5.0026e-08 - binary_accuracy: 1.0000 - val_loss: 1.1664 - val_binary_accuracy: 0.8738\n",
            "Epoch 217/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 4.8807e-08 - binary_accuracy: 1.0000 - val_loss: 1.1676 - val_binary_accuracy: 0.8738\n",
            "Epoch 218/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 4.7690e-08 - binary_accuracy: 1.0000 - val_loss: 1.1701 - val_binary_accuracy: 0.8738\n",
            "Epoch 219/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 4.6517e-08 - binary_accuracy: 1.0000 - val_loss: 1.1716 - val_binary_accuracy: 0.8738\n",
            "Epoch 220/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 4.5451e-08 - binary_accuracy: 1.0000 - val_loss: 1.1723 - val_binary_accuracy: 0.8738\n",
            "Epoch 221/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 4.4354e-08 - binary_accuracy: 1.0000 - val_loss: 1.1750 - val_binary_accuracy: 0.8738\n",
            "Epoch 222/500\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 4.3299e-08 - binary_accuracy: 1.0000 - val_loss: 1.1767 - val_binary_accuracy: 0.8738\n",
            "Epoch 223/500\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 4.2286e-08 - binary_accuracy: 1.0000 - val_loss: 1.1784 - val_binary_accuracy: 0.8738\n",
            "Epoch 224/500\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 4.1291e-08 - binary_accuracy: 1.0000 - val_loss: 1.1805 - val_binary_accuracy: 0.8738\n",
            "Epoch 225/500\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 4.0333e-08 - binary_accuracy: 1.0000 - val_loss: 1.1826 - val_binary_accuracy: 0.8738\n",
            "Epoch 226/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 3.9363e-08 - binary_accuracy: 1.0000 - val_loss: 1.1841 - val_binary_accuracy: 0.8738\n",
            "Epoch 227/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 3.8444e-08 - binary_accuracy: 1.0000 - val_loss: 1.1858 - val_binary_accuracy: 0.8738\n",
            "Epoch 228/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 3.7553e-08 - binary_accuracy: 1.0000 - val_loss: 1.1880 - val_binary_accuracy: 0.8738\n",
            "Epoch 229/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 3.6680e-08 - binary_accuracy: 1.0000 - val_loss: 1.1900 - val_binary_accuracy: 0.8738\n",
            "Epoch 230/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 3.5877e-08 - binary_accuracy: 1.0000 - val_loss: 1.1907 - val_binary_accuracy: 0.8738\n",
            "Epoch 231/500\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 3.5005e-08 - binary_accuracy: 1.0000 - val_loss: 1.1928 - val_binary_accuracy: 0.8738\n",
            "Epoch 232/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 3.4212e-08 - binary_accuracy: 1.0000 - val_loss: 1.1938 - val_binary_accuracy: 0.8738\n",
            "Epoch 233/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 3.3418e-08 - binary_accuracy: 1.0000 - val_loss: 1.1962 - val_binary_accuracy: 0.8738\n",
            "Epoch 234/500\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 3.2648e-08 - binary_accuracy: 1.0000 - val_loss: 1.1981 - val_binary_accuracy: 0.8738\n",
            "Epoch 235/500\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 3.1906e-08 - binary_accuracy: 1.0000 - val_loss: 1.1997 - val_binary_accuracy: 0.8738\n",
            "Epoch 236/500\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 3.1172e-08 - binary_accuracy: 1.0000 - val_loss: 1.2015 - val_binary_accuracy: 0.8738\n",
            "Epoch 237/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 3.0469e-08 - binary_accuracy: 1.0000 - val_loss: 1.2035 - val_binary_accuracy: 0.8738\n",
            "Epoch 238/500\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 2.9778e-08 - binary_accuracy: 1.0000 - val_loss: 1.2050 - val_binary_accuracy: 0.8738\n",
            "Epoch 239/500\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 2.9090e-08 - binary_accuracy: 1.0000 - val_loss: 1.2067 - val_binary_accuracy: 0.8738\n",
            "Epoch 240/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 2.8432e-08 - binary_accuracy: 1.0000 - val_loss: 1.2088 - val_binary_accuracy: 0.8738\n",
            "Epoch 241/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 2.7778e-08 - binary_accuracy: 1.0000 - val_loss: 1.2106 - val_binary_accuracy: 0.8738\n",
            "Epoch 242/500\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 2.7153e-08 - binary_accuracy: 1.0000 - val_loss: 1.2126 - val_binary_accuracy: 0.8738\n",
            "Epoch 243/500\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 2.6542e-08 - binary_accuracy: 1.0000 - val_loss: 1.2139 - val_binary_accuracy: 0.8738\n",
            "Epoch 244/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 2.5941e-08 - binary_accuracy: 1.0000 - val_loss: 1.2158 - val_binary_accuracy: 0.8738\n",
            "Epoch 245/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 2.5357e-08 - binary_accuracy: 1.0000 - val_loss: 1.2181 - val_binary_accuracy: 0.8738\n",
            "Epoch 246/500\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 2.4785e-08 - binary_accuracy: 1.0000 - val_loss: 1.2198 - val_binary_accuracy: 0.8738\n",
            "Epoch 247/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 2.4237e-08 - binary_accuracy: 1.0000 - val_loss: 1.2216 - val_binary_accuracy: 0.8738\n",
            "Epoch 248/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 2.3701e-08 - binary_accuracy: 1.0000 - val_loss: 1.2231 - val_binary_accuracy: 0.8738\n",
            "Epoch 249/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 2.3181e-08 - binary_accuracy: 1.0000 - val_loss: 1.2248 - val_binary_accuracy: 0.8738\n",
            "Epoch 250/500\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 2.2681e-08 - binary_accuracy: 1.0000 - val_loss: 1.2260 - val_binary_accuracy: 0.8738\n",
            "Epoch 251/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 2.2184e-08 - binary_accuracy: 1.0000 - val_loss: 1.2278 - val_binary_accuracy: 0.8738\n",
            "Epoch 252/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 2.1706e-08 - binary_accuracy: 1.0000 - val_loss: 1.2289 - val_binary_accuracy: 0.8738\n",
            "Epoch 253/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 2.1248e-08 - binary_accuracy: 1.0000 - val_loss: 1.2311 - val_binary_accuracy: 0.8738\n",
            "Epoch 254/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 2.0804e-08 - binary_accuracy: 1.0000 - val_loss: 1.2319 - val_binary_accuracy: 0.8738\n",
            "Epoch 255/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 2.0338e-08 - binary_accuracy: 1.0000 - val_loss: 1.2343 - val_binary_accuracy: 0.8738\n",
            "Epoch 256/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.9906e-08 - binary_accuracy: 1.0000 - val_loss: 1.2355 - val_binary_accuracy: 0.8738\n",
            "Epoch 257/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.9479e-08 - binary_accuracy: 1.0000 - val_loss: 1.2378 - val_binary_accuracy: 0.8738\n",
            "Epoch 258/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.9065e-08 - binary_accuracy: 1.0000 - val_loss: 1.2389 - val_binary_accuracy: 0.8738\n",
            "Epoch 259/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.8663e-08 - binary_accuracy: 1.0000 - val_loss: 1.2408 - val_binary_accuracy: 0.8738\n",
            "Epoch 260/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.8261e-08 - binary_accuracy: 1.0000 - val_loss: 1.2422 - val_binary_accuracy: 0.8738\n",
            "Epoch 261/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.7879e-08 - binary_accuracy: 1.0000 - val_loss: 1.2439 - val_binary_accuracy: 0.8738\n",
            "Epoch 262/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.7498e-08 - binary_accuracy: 1.0000 - val_loss: 1.2457 - val_binary_accuracy: 0.8738\n",
            "Epoch 263/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.7130e-08 - binary_accuracy: 1.0000 - val_loss: 1.2470 - val_binary_accuracy: 0.8738\n",
            "Epoch 264/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.6771e-08 - binary_accuracy: 1.0000 - val_loss: 1.2491 - val_binary_accuracy: 0.8738\n",
            "Epoch 265/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.6423e-08 - binary_accuracy: 1.0000 - val_loss: 1.2500 - val_binary_accuracy: 0.8738\n",
            "Epoch 266/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.6080e-08 - binary_accuracy: 1.0000 - val_loss: 1.2520 - val_binary_accuracy: 0.8738\n",
            "Epoch 267/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.5749e-08 - binary_accuracy: 1.0000 - val_loss: 1.2534 - val_binary_accuracy: 0.8738\n",
            "Epoch 268/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.5430e-08 - binary_accuracy: 1.0000 - val_loss: 1.2552 - val_binary_accuracy: 0.8738\n",
            "Epoch 269/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.5118e-08 - binary_accuracy: 1.0000 - val_loss: 1.2564 - val_binary_accuracy: 0.8738\n",
            "Epoch 270/500\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 1.4812e-08 - binary_accuracy: 1.0000 - val_loss: 1.2583 - val_binary_accuracy: 0.8738\n",
            "Epoch 271/500\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 1.4513e-08 - binary_accuracy: 1.0000 - val_loss: 1.2595 - val_binary_accuracy: 0.8738\n",
            "Epoch 272/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.4217e-08 - binary_accuracy: 1.0000 - val_loss: 1.2612 - val_binary_accuracy: 0.8738\n",
            "Epoch 273/500\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 1.3930e-08 - binary_accuracy: 1.0000 - val_loss: 1.2625 - val_binary_accuracy: 0.8738\n",
            "Epoch 274/500\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 1.3653e-08 - binary_accuracy: 1.0000 - val_loss: 1.2641 - val_binary_accuracy: 0.8738\n",
            "Epoch 275/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.3383e-08 - binary_accuracy: 1.0000 - val_loss: 1.2654 - val_binary_accuracy: 0.8738\n",
            "Epoch 276/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.3114e-08 - binary_accuracy: 1.0000 - val_loss: 1.2672 - val_binary_accuracy: 0.8738\n",
            "Epoch 277/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.2858e-08 - binary_accuracy: 1.0000 - val_loss: 1.2692 - val_binary_accuracy: 0.8738\n",
            "Epoch 278/500\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 1.2596e-08 - binary_accuracy: 1.0000 - val_loss: 1.2695 - val_binary_accuracy: 0.8738\n",
            "Epoch 279/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.2352e-08 - binary_accuracy: 1.0000 - val_loss: 1.2719 - val_binary_accuracy: 0.8738\n",
            "Epoch 280/500\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 1.2106e-08 - binary_accuracy: 1.0000 - val_loss: 1.2731 - val_binary_accuracy: 0.8738\n",
            "Epoch 281/500\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 1.1868e-08 - binary_accuracy: 1.0000 - val_loss: 1.2746 - val_binary_accuracy: 0.8738\n",
            "Epoch 282/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 1.1641e-08 - binary_accuracy: 1.0000 - val_loss: 1.2759 - val_binary_accuracy: 0.8738\n",
            "Epoch 283/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 1.1413e-08 - binary_accuracy: 1.0000 - val_loss: 1.2774 - val_binary_accuracy: 0.8738\n",
            "Epoch 284/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 1.1193e-08 - binary_accuracy: 1.0000 - val_loss: 1.2788 - val_binary_accuracy: 0.8738\n",
            "Epoch 285/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 1.0977e-08 - binary_accuracy: 1.0000 - val_loss: 1.2801 - val_binary_accuracy: 0.8738\n",
            "Epoch 286/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 1.0766e-08 - binary_accuracy: 1.0000 - val_loss: 1.2817 - val_binary_accuracy: 0.8738\n",
            "Epoch 287/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 1.0571e-08 - binary_accuracy: 1.0000 - val_loss: 1.2824 - val_binary_accuracy: 0.8738\n",
            "Epoch 288/500\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.0362e-08 - binary_accuracy: 1.0000 - val_loss: 1.2842 - val_binary_accuracy: 0.8738\n",
            "Epoch 289/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 1.0167e-08 - binary_accuracy: 1.0000 - val_loss: 1.2857 - val_binary_accuracy: 0.8738\n",
            "Epoch 290/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 9.9710e-09 - binary_accuracy: 1.0000 - val_loss: 1.2868 - val_binary_accuracy: 0.8738\n",
            "Epoch 291/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 9.7852e-09 - binary_accuracy: 1.0000 - val_loss: 1.2888 - val_binary_accuracy: 0.8738\n",
            "Epoch 292/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 9.6043e-09 - binary_accuracy: 1.0000 - val_loss: 1.2896 - val_binary_accuracy: 0.8738\n",
            "Epoch 293/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 9.4266e-09 - binary_accuracy: 1.0000 - val_loss: 1.2908 - val_binary_accuracy: 0.8738\n",
            "Epoch 294/500\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 9.2478e-09 - binary_accuracy: 1.0000 - val_loss: 1.2925 - val_binary_accuracy: 0.8738\n",
            "Epoch 295/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 9.0749e-09 - binary_accuracy: 1.0000 - val_loss: 1.2944 - val_binary_accuracy: 0.8738\n",
            "Epoch 296/500\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 8.9102e-09 - binary_accuracy: 1.0000 - val_loss: 1.2952 - val_binary_accuracy: 0.8738\n",
            "Epoch 297/500\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 8.7468e-09 - binary_accuracy: 1.0000 - val_loss: 1.2963 - val_binary_accuracy: 0.8738\n",
            "Epoch 298/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 8.5849e-09 - binary_accuracy: 1.0000 - val_loss: 1.2982 - val_binary_accuracy: 0.8738\n",
            "Epoch 299/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 8.4190e-09 - binary_accuracy: 1.0000 - val_loss: 1.2999 - val_binary_accuracy: 0.8738\n",
            "Epoch 300/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 8.2622e-09 - binary_accuracy: 1.0000 - val_loss: 1.3018 - val_binary_accuracy: 0.8738\n",
            "Epoch 301/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 8.1051e-09 - binary_accuracy: 1.0000 - val_loss: 1.3031 - val_binary_accuracy: 0.8738\n",
            "Epoch 302/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 7.9570e-09 - binary_accuracy: 1.0000 - val_loss: 1.3042 - val_binary_accuracy: 0.8738\n",
            "Epoch 303/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 7.8164e-09 - binary_accuracy: 1.0000 - val_loss: 1.3056 - val_binary_accuracy: 0.8738\n",
            "Epoch 304/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 7.6850e-09 - binary_accuracy: 1.0000 - val_loss: 1.3063 - val_binary_accuracy: 0.8738\n",
            "Epoch 305/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 7.5559e-09 - binary_accuracy: 1.0000 - val_loss: 1.3074 - val_binary_accuracy: 0.8738\n",
            "Epoch 306/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 7.4369e-09 - binary_accuracy: 1.0000 - val_loss: 1.3077 - val_binary_accuracy: 0.8738\n",
            "Epoch 307/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 7.3065e-09 - binary_accuracy: 1.0000 - val_loss: 1.3095 - val_binary_accuracy: 0.8738\n",
            "Epoch 308/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 7.1851e-09 - binary_accuracy: 1.0000 - val_loss: 1.3102 - val_binary_accuracy: 0.8738\n",
            "Epoch 309/500\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 7.0680e-09 - binary_accuracy: 1.0000 - val_loss: 1.3113 - val_binary_accuracy: 0.8738\n",
            "Epoch 310/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 6.9529e-09 - binary_accuracy: 1.0000 - val_loss: 1.3121 - val_binary_accuracy: 0.8738\n",
            "Epoch 311/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 6.8392e-09 - binary_accuracy: 1.0000 - val_loss: 1.3130 - val_binary_accuracy: 0.8738\n",
            "Epoch 312/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 6.7311e-09 - binary_accuracy: 1.0000 - val_loss: 1.3137 - val_binary_accuracy: 0.8738\n",
            "Epoch 313/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 6.6316e-09 - binary_accuracy: 1.0000 - val_loss: 1.3141 - val_binary_accuracy: 0.8738\n",
            "Epoch 314/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 6.5372e-09 - binary_accuracy: 1.0000 - val_loss: 1.3144 - val_binary_accuracy: 0.8738\n",
            "Epoch 315/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 6.4358e-09 - binary_accuracy: 1.0000 - val_loss: 1.3157 - val_binary_accuracy: 0.8738\n",
            "Epoch 316/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 6.3330e-09 - binary_accuracy: 1.0000 - val_loss: 1.3168 - val_binary_accuracy: 0.8738\n",
            "Epoch 317/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 6.2426e-09 - binary_accuracy: 1.0000 - val_loss: 1.3172 - val_binary_accuracy: 0.8738\n",
            "Epoch 318/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 6.1416e-09 - binary_accuracy: 1.0000 - val_loss: 1.3183 - val_binary_accuracy: 0.8738\n",
            "Epoch 319/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 6.0519e-09 - binary_accuracy: 1.0000 - val_loss: 1.3195 - val_binary_accuracy: 0.8738\n",
            "Epoch 320/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 5.9560e-09 - binary_accuracy: 1.0000 - val_loss: 1.3199 - val_binary_accuracy: 0.8738\n",
            "Epoch 321/500\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 5.8679e-09 - binary_accuracy: 1.0000 - val_loss: 1.3211 - val_binary_accuracy: 0.8738\n",
            "Epoch 322/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 5.7826e-09 - binary_accuracy: 1.0000 - val_loss: 1.3216 - val_binary_accuracy: 0.8738\n",
            "Epoch 323/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 5.6930e-09 - binary_accuracy: 1.0000 - val_loss: 1.3229 - val_binary_accuracy: 0.8738\n",
            "Epoch 324/500\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 5.6094e-09 - binary_accuracy: 1.0000 - val_loss: 1.3233 - val_binary_accuracy: 0.8738\n",
            "Epoch 325/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 5.5265e-09 - binary_accuracy: 1.0000 - val_loss: 1.3240 - val_binary_accuracy: 0.8738\n",
            "Epoch 326/500\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 5.4427e-09 - binary_accuracy: 1.0000 - val_loss: 1.3255 - val_binary_accuracy: 0.8738\n",
            "Epoch 327/500\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 5.3583e-09 - binary_accuracy: 1.0000 - val_loss: 1.3264 - val_binary_accuracy: 0.8738\n",
            "Epoch 328/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 5.2828e-09 - binary_accuracy: 1.0000 - val_loss: 1.3273 - val_binary_accuracy: 0.8738\n",
            "Epoch 329/500\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 5.2073e-09 - binary_accuracy: 1.0000 - val_loss: 1.3277 - val_binary_accuracy: 0.8738\n",
            "Epoch 330/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 5.1348e-09 - binary_accuracy: 1.0000 - val_loss: 1.3290 - val_binary_accuracy: 0.8738\n",
            "Epoch 331/500\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 5.0611e-09 - binary_accuracy: 1.0000 - val_loss: 1.3301 - val_binary_accuracy: 0.8738\n",
            "Epoch 332/500\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 4.9933e-09 - binary_accuracy: 1.0000 - val_loss: 1.3305 - val_binary_accuracy: 0.8738\n",
            "Epoch 333/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 4.9211e-09 - binary_accuracy: 1.0000 - val_loss: 1.3323 - val_binary_accuracy: 0.8738\n",
            "Epoch 334/500\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 4.8499e-09 - binary_accuracy: 1.0000 - val_loss: 1.3325 - val_binary_accuracy: 0.8738\n",
            "Epoch 335/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 4.7905e-09 - binary_accuracy: 1.0000 - val_loss: 1.3331 - val_binary_accuracy: 0.8738\n",
            "Epoch 336/500\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 4.7307e-09 - binary_accuracy: 1.0000 - val_loss: 1.3339 - val_binary_accuracy: 0.8738\n",
            "Epoch 337/500\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 4.6696e-09 - binary_accuracy: 1.0000 - val_loss: 1.3344 - val_binary_accuracy: 0.8738\n",
            "Epoch 338/500\n",
            "47/47 [==============================] - 1s 11ms/step - loss: 4.6179e-09 - binary_accuracy: 1.0000 - val_loss: 1.3347 - val_binary_accuracy: 0.8738\n",
            "Epoch 339/500\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 4.5534e-09 - binary_accuracy: 1.0000 - val_loss: 1.3359 - val_binary_accuracy: 0.8738\n",
            "Epoch 340/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 4.4989e-09 - binary_accuracy: 1.0000 - val_loss: 1.3361 - val_binary_accuracy: 0.8738\n",
            "Epoch 341/500\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 4.4432e-09 - binary_accuracy: 1.0000 - val_loss: 1.3374 - val_binary_accuracy: 0.8738\n",
            "Epoch 342/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 4.3837e-09 - binary_accuracy: 1.0000 - val_loss: 1.3386 - val_binary_accuracy: 0.8738\n",
            "Epoch 343/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 4.3252e-09 - binary_accuracy: 1.0000 - val_loss: 1.3397 - val_binary_accuracy: 0.8738\n",
            "Epoch 344/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 4.2664e-09 - binary_accuracy: 1.0000 - val_loss: 1.3407 - val_binary_accuracy: 0.8738\n",
            "Epoch 345/500\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 4.2134e-09 - binary_accuracy: 1.0000 - val_loss: 1.3415 - val_binary_accuracy: 0.8738\n",
            "Epoch 346/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 4.1541e-09 - binary_accuracy: 1.0000 - val_loss: 1.3431 - val_binary_accuracy: 0.8738\n",
            "Epoch 347/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 4.1000e-09 - binary_accuracy: 1.0000 - val_loss: 1.3439 - val_binary_accuracy: 0.8738\n",
            "Epoch 348/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 4.0417e-09 - binary_accuracy: 1.0000 - val_loss: 1.3451 - val_binary_accuracy: 0.8738\n",
            "Epoch 349/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 3.9944e-09 - binary_accuracy: 1.0000 - val_loss: 1.3456 - val_binary_accuracy: 0.8738\n",
            "Epoch 350/500\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 3.9459e-09 - binary_accuracy: 1.0000 - val_loss: 1.3458 - val_binary_accuracy: 0.8738\n",
            "Epoch 351/500\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 3.9045e-09 - binary_accuracy: 1.0000 - val_loss: 1.3461 - val_binary_accuracy: 0.8738\n",
            "Epoch 352/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 3.8535e-09 - binary_accuracy: 1.0000 - val_loss: 1.3469 - val_binary_accuracy: 0.8738\n",
            "Epoch 353/500\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 3.8074e-09 - binary_accuracy: 1.0000 - val_loss: 1.3471 - val_binary_accuracy: 0.8738\n",
            "Epoch 354/500\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 3.7640e-09 - binary_accuracy: 1.0000 - val_loss: 1.3481 - val_binary_accuracy: 0.8738\n",
            "Epoch 355/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 3.7206e-09 - binary_accuracy: 1.0000 - val_loss: 1.3482 - val_binary_accuracy: 0.8738\n",
            "Epoch 356/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 3.6713e-09 - binary_accuracy: 1.0000 - val_loss: 1.3491 - val_binary_accuracy: 0.8738\n",
            "Epoch 357/500\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 3.6298e-09 - binary_accuracy: 1.0000 - val_loss: 1.3493 - val_binary_accuracy: 0.8738\n",
            "Epoch 358/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 3.5857e-09 - binary_accuracy: 1.0000 - val_loss: 1.3503 - val_binary_accuracy: 0.8738\n",
            "Epoch 359/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 3.5453e-09 - binary_accuracy: 1.0000 - val_loss: 1.3505 - val_binary_accuracy: 0.8738\n",
            "Epoch 360/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 3.5045e-09 - binary_accuracy: 1.0000 - val_loss: 1.3515 - val_binary_accuracy: 0.8738\n",
            "Epoch 361/500\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 3.4608e-09 - binary_accuracy: 1.0000 - val_loss: 1.3521 - val_binary_accuracy: 0.8738\n",
            "Epoch 362/500\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 3.4266e-09 - binary_accuracy: 1.0000 - val_loss: 1.3522 - val_binary_accuracy: 0.8738\n",
            "Epoch 363/500\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 3.3866e-09 - binary_accuracy: 1.0000 - val_loss: 1.3531 - val_binary_accuracy: 0.8738\n",
            "Epoch 364/500\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 3.3557e-09 - binary_accuracy: 1.0000 - val_loss: 1.3534 - val_binary_accuracy: 0.8738\n",
            "Epoch 365/500\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 3.3163e-09 - binary_accuracy: 1.0000 - val_loss: 1.3542 - val_binary_accuracy: 0.8738\n",
            "Epoch 366/500\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 3.2828e-09 - binary_accuracy: 1.0000 - val_loss: 1.3552 - val_binary_accuracy: 0.8738\n",
            "Epoch 367/500\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 3.2503e-09 - binary_accuracy: 1.0000 - val_loss: 1.3550 - val_binary_accuracy: 0.8738\n",
            "Epoch 368/500\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 3.2153e-09 - binary_accuracy: 1.0000 - val_loss: 1.3562 - val_binary_accuracy: 0.8738\n",
            "Epoch 369/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 3.1806e-09 - binary_accuracy: 1.0000 - val_loss: 1.3567 - val_binary_accuracy: 0.8738\n",
            "Epoch 370/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 3.1517e-09 - binary_accuracy: 1.0000 - val_loss: 1.3573 - val_binary_accuracy: 0.8738\n",
            "Epoch 371/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 3.1210e-09 - binary_accuracy: 1.0000 - val_loss: 1.3574 - val_binary_accuracy: 0.8738\n",
            "Epoch 372/500\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 3.0906e-09 - binary_accuracy: 1.0000 - val_loss: 1.3578 - val_binary_accuracy: 0.8738\n",
            "Epoch 373/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 3.0599e-09 - binary_accuracy: 1.0000 - val_loss: 1.3591 - val_binary_accuracy: 0.8738\n",
            "Epoch 374/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 3.0307e-09 - binary_accuracy: 1.0000 - val_loss: 1.3587 - val_binary_accuracy: 0.8738\n",
            "Epoch 375/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 3.0055e-09 - binary_accuracy: 1.0000 - val_loss: 1.3596 - val_binary_accuracy: 0.8738\n",
            "Epoch 376/500\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 2.9746e-09 - binary_accuracy: 1.0000 - val_loss: 1.3598 - val_binary_accuracy: 0.8738\n",
            "Epoch 377/500\n",
            "47/47 [==============================] - 1s 15ms/step - loss: 2.9482e-09 - binary_accuracy: 1.0000 - val_loss: 1.3603 - val_binary_accuracy: 0.8738\n",
            "Epoch 378/500\n",
            "47/47 [==============================] - 1s 14ms/step - loss: 2.9217e-09 - binary_accuracy: 1.0000 - val_loss: 1.3607 - val_binary_accuracy: 0.8738\n",
            "Epoch 379/500\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 2.8908e-09 - binary_accuracy: 1.0000 - val_loss: 1.3616 - val_binary_accuracy: 0.8738\n",
            "Epoch 380/500\n",
            "47/47 [==============================] - 1s 12ms/step - loss: 2.8636e-09 - binary_accuracy: 1.0000 - val_loss: 1.3626 - val_binary_accuracy: 0.8738\n",
            "Epoch 381/500\n",
            "47/47 [==============================] - 1s 19ms/step - loss: 2.8313e-09 - binary_accuracy: 1.0000 - val_loss: 1.3625 - val_binary_accuracy: 0.8738\n",
            "Epoch 382/500\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 2.8069e-09 - binary_accuracy: 1.0000 - val_loss: 1.3641 - val_binary_accuracy: 0.8738\n",
            "Epoch 383/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 2.7730e-09 - binary_accuracy: 1.0000 - val_loss: 1.3653 - val_binary_accuracy: 0.8738\n",
            "Epoch 384/500\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 2.7502e-09 - binary_accuracy: 1.0000 - val_loss: 1.3656 - val_binary_accuracy: 0.8738\n",
            "Epoch 385/500\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 2.7264e-09 - binary_accuracy: 1.0000 - val_loss: 1.3659 - val_binary_accuracy: 0.8738\n",
            "Epoch 386/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 2.6977e-09 - binary_accuracy: 1.0000 - val_loss: 1.3669 - val_binary_accuracy: 0.8738\n",
            "Epoch 387/500\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 2.6708e-09 - binary_accuracy: 1.0000 - val_loss: 1.3685 - val_binary_accuracy: 0.8738\n",
            "Epoch 388/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 2.6450e-09 - binary_accuracy: 1.0000 - val_loss: 1.3693 - val_binary_accuracy: 0.8738\n",
            "Epoch 389/500\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 2.6194e-09 - binary_accuracy: 1.0000 - val_loss: 1.3697 - val_binary_accuracy: 0.8738\n",
            "Epoch 390/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 2.5965e-09 - binary_accuracy: 1.0000 - val_loss: 1.3706 - val_binary_accuracy: 0.8738\n",
            "Epoch 391/500\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 2.5712e-09 - binary_accuracy: 1.0000 - val_loss: 1.3715 - val_binary_accuracy: 0.8738\n",
            "Epoch 392/500\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 2.5445e-09 - binary_accuracy: 1.0000 - val_loss: 1.3721 - val_binary_accuracy: 0.8738\n",
            "Epoch 393/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 2.5172e-09 - binary_accuracy: 1.0000 - val_loss: 1.3732 - val_binary_accuracy: 0.8738\n",
            "Epoch 394/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 2.4969e-09 - binary_accuracy: 1.0000 - val_loss: 1.3727 - val_binary_accuracy: 0.8738\n",
            "Epoch 395/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 2.4776e-09 - binary_accuracy: 1.0000 - val_loss: 1.3734 - val_binary_accuracy: 0.8738\n",
            "Epoch 396/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 2.4553e-09 - binary_accuracy: 1.0000 - val_loss: 1.3737 - val_binary_accuracy: 0.8738\n",
            "Epoch 397/500\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 2.4371e-09 - binary_accuracy: 1.0000 - val_loss: 1.3734 - val_binary_accuracy: 0.8738\n",
            "Epoch 398/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 2.4225e-09 - binary_accuracy: 1.0000 - val_loss: 1.3742 - val_binary_accuracy: 0.8738\n",
            "Epoch 399/500\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 2.4099e-09 - binary_accuracy: 1.0000 - val_loss: 1.3733 - val_binary_accuracy: 0.8738\n",
            "Epoch 400/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 2.3913e-09 - binary_accuracy: 1.0000 - val_loss: 1.3740 - val_binary_accuracy: 0.8738\n",
            "Epoch 401/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 2.3794e-09 - binary_accuracy: 1.0000 - val_loss: 1.3734 - val_binary_accuracy: 0.8738\n",
            "Epoch 402/500\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 2.3695e-09 - binary_accuracy: 1.0000 - val_loss: 1.3742 - val_binary_accuracy: 0.8738\n",
            "Epoch 403/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 2.3453e-09 - binary_accuracy: 1.0000 - val_loss: 1.3744 - val_binary_accuracy: 0.8738\n",
            "Epoch 404/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 2.3398e-09 - binary_accuracy: 1.0000 - val_loss: 1.3749 - val_binary_accuracy: 0.8738\n",
            "Epoch 405/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 2.3266e-09 - binary_accuracy: 1.0000 - val_loss: 1.3739 - val_binary_accuracy: 0.8738\n",
            "Epoch 406/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 2.3105e-09 - binary_accuracy: 1.0000 - val_loss: 1.3750 - val_binary_accuracy: 0.8738\n",
            "Epoch 407/500\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 2.2986e-09 - binary_accuracy: 1.0000 - val_loss: 1.3740 - val_binary_accuracy: 0.8738\n",
            "Epoch 408/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 2.2875e-09 - binary_accuracy: 1.0000 - val_loss: 1.3746 - val_binary_accuracy: 0.8738\n",
            "Epoch 409/500\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 2.2769e-09 - binary_accuracy: 1.0000 - val_loss: 1.3755 - val_binary_accuracy: 0.8738\n",
            "Epoch 410/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 2.2642e-09 - binary_accuracy: 1.0000 - val_loss: 1.3748 - val_binary_accuracy: 0.8738\n",
            "Epoch 411/500\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 2.2521e-09 - binary_accuracy: 1.0000 - val_loss: 1.3751 - val_binary_accuracy: 0.8738\n",
            "Epoch 412/500\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 2.2441e-09 - binary_accuracy: 1.0000 - val_loss: 1.3752 - val_binary_accuracy: 0.8738\n",
            "Epoch 413/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 2.2334e-09 - binary_accuracy: 1.0000 - val_loss: 1.3753 - val_binary_accuracy: 0.8738\n",
            "Epoch 414/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 2.2255e-09 - binary_accuracy: 1.0000 - val_loss: 1.3746 - val_binary_accuracy: 0.8738\n",
            "Epoch 415/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 2.2139e-09 - binary_accuracy: 1.0000 - val_loss: 1.3764 - val_binary_accuracy: 0.8738\n",
            "Epoch 416/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 2.1981e-09 - binary_accuracy: 1.0000 - val_loss: 1.3765 - val_binary_accuracy: 0.8738\n",
            "Epoch 417/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 2.1927e-09 - binary_accuracy: 1.0000 - val_loss: 1.3766 - val_binary_accuracy: 0.8738\n",
            "Epoch 418/500\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 2.1802e-09 - binary_accuracy: 1.0000 - val_loss: 1.3771 - val_binary_accuracy: 0.8738\n",
            "Epoch 419/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 2.1645e-09 - binary_accuracy: 1.0000 - val_loss: 1.3781 - val_binary_accuracy: 0.8738\n",
            "Epoch 420/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 2.1522e-09 - binary_accuracy: 1.0000 - val_loss: 1.3783 - val_binary_accuracy: 0.8738\n",
            "Epoch 421/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 2.1454e-09 - binary_accuracy: 1.0000 - val_loss: 1.3786 - val_binary_accuracy: 0.8738\n",
            "Epoch 422/500\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 2.1361e-09 - binary_accuracy: 1.0000 - val_loss: 1.3783 - val_binary_accuracy: 0.8738\n",
            "Epoch 423/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 2.1205e-09 - binary_accuracy: 1.0000 - val_loss: 1.3777 - val_binary_accuracy: 0.8738\n",
            "Epoch 424/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 2.1165e-09 - binary_accuracy: 1.0000 - val_loss: 1.3769 - val_binary_accuracy: 0.8738\n",
            "Epoch 425/500\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 2.1158e-09 - binary_accuracy: 1.0000 - val_loss: 1.3767 - val_binary_accuracy: 0.8738\n",
            "Epoch 426/500\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 2.1003e-09 - binary_accuracy: 1.0000 - val_loss: 1.3772 - val_binary_accuracy: 0.8738\n",
            "Epoch 427/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 2.0938e-09 - binary_accuracy: 1.0000 - val_loss: 1.3760 - val_binary_accuracy: 0.8738\n",
            "Epoch 428/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 2.0873e-09 - binary_accuracy: 1.0000 - val_loss: 1.3758 - val_binary_accuracy: 0.8738\n",
            "Epoch 429/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 2.0742e-09 - binary_accuracy: 1.0000 - val_loss: 1.3767 - val_binary_accuracy: 0.8738\n",
            "Epoch 430/500\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 2.0646e-09 - binary_accuracy: 1.0000 - val_loss: 1.3754 - val_binary_accuracy: 0.8738\n",
            "Epoch 431/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 2.0561e-09 - binary_accuracy: 1.0000 - val_loss: 1.3754 - val_binary_accuracy: 0.8738\n",
            "Epoch 432/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 2.0514e-09 - binary_accuracy: 1.0000 - val_loss: 1.3753 - val_binary_accuracy: 0.8738\n",
            "Epoch 433/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 2.0371e-09 - binary_accuracy: 1.0000 - val_loss: 1.3741 - val_binary_accuracy: 0.8738\n",
            "Epoch 434/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 2.0327e-09 - binary_accuracy: 1.0000 - val_loss: 1.3757 - val_binary_accuracy: 0.8738\n",
            "Epoch 435/500\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 2.0223e-09 - binary_accuracy: 1.0000 - val_loss: 1.3745 - val_binary_accuracy: 0.8738\n",
            "Epoch 436/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 2.0128e-09 - binary_accuracy: 1.0000 - val_loss: 1.3750 - val_binary_accuracy: 0.8738\n",
            "Epoch 437/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 2.0048e-09 - binary_accuracy: 1.0000 - val_loss: 1.3734 - val_binary_accuracy: 0.8738\n",
            "Epoch 438/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 1.9952e-09 - binary_accuracy: 1.0000 - val_loss: 1.3741 - val_binary_accuracy: 0.8738\n",
            "Epoch 439/500\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.9883e-09 - binary_accuracy: 1.0000 - val_loss: 1.3732 - val_binary_accuracy: 0.8738\n",
            "Epoch 440/500\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 1.9770e-09 - binary_accuracy: 1.0000 - val_loss: 1.3726 - val_binary_accuracy: 0.8738\n",
            "Epoch 441/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 1.9736e-09 - binary_accuracy: 1.0000 - val_loss: 1.3732 - val_binary_accuracy: 0.8738\n",
            "Epoch 442/500\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 1.9613e-09 - binary_accuracy: 1.0000 - val_loss: 1.3721 - val_binary_accuracy: 0.8738\n",
            "Epoch 443/500\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 1.9550e-09 - binary_accuracy: 1.0000 - val_loss: 1.3738 - val_binary_accuracy: 0.8738\n",
            "Epoch 444/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 1.9443e-09 - binary_accuracy: 1.0000 - val_loss: 1.3723 - val_binary_accuracy: 0.8738\n",
            "Epoch 445/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 1.9422e-09 - binary_accuracy: 1.0000 - val_loss: 1.3726 - val_binary_accuracy: 0.8738\n",
            "Epoch 446/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 1.9302e-09 - binary_accuracy: 1.0000 - val_loss: 1.3733 - val_binary_accuracy: 0.8738\n",
            "Epoch 447/500\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 1.9076e-09 - binary_accuracy: 1.0000 - val_loss: 1.3719 - val_binary_accuracy: 0.8738\n",
            "Epoch 448/500\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 1.9229e-09 - binary_accuracy: 1.0000 - val_loss: 1.3727 - val_binary_accuracy: 0.8738\n",
            "Epoch 449/500\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 1.9073e-09 - binary_accuracy: 1.0000 - val_loss: 1.3721 - val_binary_accuracy: 0.8738\n",
            "Epoch 450/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.9002e-09 - binary_accuracy: 1.0000 - val_loss: 1.3712 - val_binary_accuracy: 0.8738\n",
            "Epoch 451/500\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 1.9012e-09 - binary_accuracy: 1.0000 - val_loss: 1.3713 - val_binary_accuracy: 0.8738\n",
            "Epoch 452/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.8798e-09 - binary_accuracy: 1.0000 - val_loss: 1.3698 - val_binary_accuracy: 0.8738\n",
            "Epoch 453/500\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 1.8862e-09 - binary_accuracy: 1.0000 - val_loss: 1.3687 - val_binary_accuracy: 0.8738\n",
            "Epoch 454/500\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 1.8807e-09 - binary_accuracy: 1.0000 - val_loss: 1.3701 - val_binary_accuracy: 0.8738\n",
            "Epoch 455/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.8637e-09 - binary_accuracy: 1.0000 - val_loss: 1.3687 - val_binary_accuracy: 0.8738\n",
            "Epoch 456/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.8692e-09 - binary_accuracy: 1.0000 - val_loss: 1.3698 - val_binary_accuracy: 0.8738\n",
            "Epoch 457/500\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 1.8530e-09 - binary_accuracy: 1.0000 - val_loss: 1.3673 - val_binary_accuracy: 0.8738\n",
            "Epoch 458/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.8475e-09 - binary_accuracy: 1.0000 - val_loss: 1.3700 - val_binary_accuracy: 0.8738\n",
            "Epoch 459/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.8422e-09 - binary_accuracy: 1.0000 - val_loss: 1.3689 - val_binary_accuracy: 0.8738\n",
            "Epoch 460/500\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 1.8396e-09 - binary_accuracy: 1.0000 - val_loss: 1.3678 - val_binary_accuracy: 0.8738\n",
            "Epoch 461/500\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 1.8373e-09 - binary_accuracy: 1.0000 - val_loss: 1.3676 - val_binary_accuracy: 0.8738\n",
            "Epoch 462/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.8264e-09 - binary_accuracy: 1.0000 - val_loss: 1.3668 - val_binary_accuracy: 0.8738\n",
            "Epoch 463/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.8223e-09 - binary_accuracy: 1.0000 - val_loss: 1.3674 - val_binary_accuracy: 0.8738\n",
            "Epoch 464/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.8175e-09 - binary_accuracy: 1.0000 - val_loss: 1.3666 - val_binary_accuracy: 0.8738\n",
            "Epoch 465/500\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 1.8154e-09 - binary_accuracy: 1.0000 - val_loss: 1.3664 - val_binary_accuracy: 0.8738\n",
            "Epoch 466/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.8081e-09 - binary_accuracy: 1.0000 - val_loss: 1.3673 - val_binary_accuracy: 0.8738\n",
            "Epoch 467/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.7952e-09 - binary_accuracy: 1.0000 - val_loss: 1.3673 - val_binary_accuracy: 0.8738\n",
            "Epoch 468/500\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 1.7896e-09 - binary_accuracy: 1.0000 - val_loss: 1.3666 - val_binary_accuracy: 0.8738\n",
            "Epoch 469/500\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 1.7895e-09 - binary_accuracy: 1.0000 - val_loss: 1.3646 - val_binary_accuracy: 0.8738\n",
            "Epoch 470/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.7811e-09 - binary_accuracy: 1.0000 - val_loss: 1.3666 - val_binary_accuracy: 0.8738\n",
            "Epoch 471/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.7697e-09 - binary_accuracy: 1.0000 - val_loss: 1.3653 - val_binary_accuracy: 0.8738\n",
            "Epoch 472/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.7719e-09 - binary_accuracy: 1.0000 - val_loss: 1.3666 - val_binary_accuracy: 0.8738\n",
            "Epoch 473/500\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 1.7505e-09 - binary_accuracy: 1.0000 - val_loss: 1.3654 - val_binary_accuracy: 0.8738\n",
            "Epoch 474/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.7537e-09 - binary_accuracy: 1.0000 - val_loss: 1.3655 - val_binary_accuracy: 0.8738\n",
            "Epoch 475/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.7508e-09 - binary_accuracy: 1.0000 - val_loss: 1.3678 - val_binary_accuracy: 0.8738\n",
            "Epoch 476/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.7146e-09 - binary_accuracy: 1.0000 - val_loss: 1.3671 - val_binary_accuracy: 0.8738\n",
            "Epoch 477/500\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 1.7212e-09 - binary_accuracy: 1.0000 - val_loss: 1.3651 - val_binary_accuracy: 0.8738\n",
            "Epoch 478/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.7274e-09 - binary_accuracy: 1.0000 - val_loss: 1.3651 - val_binary_accuracy: 0.8738\n",
            "Epoch 479/500\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 1.7267e-09 - binary_accuracy: 1.0000 - val_loss: 1.3634 - val_binary_accuracy: 0.8804\n",
            "Epoch 480/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.7158e-09 - binary_accuracy: 1.0000 - val_loss: 1.3638 - val_binary_accuracy: 0.8804\n",
            "Epoch 481/500\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 1.7113e-09 - binary_accuracy: 1.0000 - val_loss: 1.3648 - val_binary_accuracy: 0.8804\n",
            "Epoch 482/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.6942e-09 - binary_accuracy: 1.0000 - val_loss: 1.3634 - val_binary_accuracy: 0.8804\n",
            "Epoch 483/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.6929e-09 - binary_accuracy: 1.0000 - val_loss: 1.3635 - val_binary_accuracy: 0.8804\n",
            "Epoch 484/500\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 1.6904e-09 - binary_accuracy: 1.0000 - val_loss: 1.3628 - val_binary_accuracy: 0.8804\n",
            "Epoch 485/500\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 1.6903e-09 - binary_accuracy: 1.0000 - val_loss: 1.3645 - val_binary_accuracy: 0.8804\n",
            "Epoch 486/500\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 1.6809e-09 - binary_accuracy: 1.0000 - val_loss: 1.3612 - val_binary_accuracy: 0.8804\n",
            "Epoch 487/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 1.6676e-09 - binary_accuracy: 1.0000 - val_loss: 1.3633 - val_binary_accuracy: 0.8804\n",
            "Epoch 488/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 1.6737e-09 - binary_accuracy: 1.0000 - val_loss: 1.3637 - val_binary_accuracy: 0.8804\n",
            "Epoch 489/500\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.6714e-09 - binary_accuracy: 1.0000 - val_loss: 1.3617 - val_binary_accuracy: 0.8804\n",
            "Epoch 490/500\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 1.6769e-09 - binary_accuracy: 1.0000 - val_loss: 1.3624 - val_binary_accuracy: 0.8804\n",
            "Epoch 491/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 1.6765e-09 - binary_accuracy: 1.0000 - val_loss: 1.3605 - val_binary_accuracy: 0.8804\n",
            "Epoch 492/500\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.6680e-09 - binary_accuracy: 1.0000 - val_loss: 1.3607 - val_binary_accuracy: 0.8804\n",
            "Epoch 493/500\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 1.6681e-09 - binary_accuracy: 1.0000 - val_loss: 1.3605 - val_binary_accuracy: 0.8804\n",
            "Epoch 494/500\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.6695e-09 - binary_accuracy: 1.0000 - val_loss: 1.3598 - val_binary_accuracy: 0.8804\n",
            "Epoch 495/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 1.6640e-09 - binary_accuracy: 1.0000 - val_loss: 1.3595 - val_binary_accuracy: 0.8804\n",
            "Epoch 496/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 1.6630e-09 - binary_accuracy: 1.0000 - val_loss: 1.3608 - val_binary_accuracy: 0.8804\n",
            "Epoch 497/500\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 1.6622e-09 - binary_accuracy: 1.0000 - val_loss: 1.3587 - val_binary_accuracy: 0.8804\n",
            "Epoch 498/500\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 1.6509e-09 - binary_accuracy: 1.0000 - val_loss: 1.3597 - val_binary_accuracy: 0.8804\n",
            "Epoch 499/500\n",
            "47/47 [==============================] - 0s 10ms/step - loss: 1.6621e-09 - binary_accuracy: 1.0000 - val_loss: 1.3591 - val_binary_accuracy: 0.8804\n",
            "Epoch 500/500\n",
            "47/47 [==============================] - 0s 9ms/step - loss: 1.6605e-09 - binary_accuracy: 1.0000 - val_loss: 1.3581 - val_binary_accuracy: 0.8804\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['val_binary_accuracy'])\n",
        "plt.plot(history.history['binary_accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "id": "y6dgf8EcpEE4",
        "outputId": "87735b25-8d7b-462d-f13c-17665698ff13"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7e7b8a392da0>]"
            ]
          },
          "metadata": {},
          "execution_count": 83
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x550 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = np.round(model.predict(X_test)).flatten()\n",
        "\n",
        "results['Neural Network'] = [accuracy_score(y_test, y_pred),\n",
        "                             precision_score(y_test, y_pred, average='weighted'),\n",
        "                             recall_score(y_test, y_pred, average='weighted'),\n",
        "                             f1_score(y_test, y_pred, average='weighted'),\n",
        "                             training_time]\n",
        "print(\"Accuracy:\", results['Neural Network'][0])\n",
        "print(\"Precision:\", results['Neural Network'][1])\n",
        "print(\"Recall:\", results['Neural Network'][2])\n",
        "print(\"F1-score:\", results['Neural Network'][3])\n",
        "print(\"Training Time:\", results['Neural Network'][4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-kWVBeaKbxE",
        "outputId": "555d7e4f-4ddb-4ed2-8c8d-ee24463f0a07"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 0s 2ms/step\n",
            "Accuracy: 0.8803986710963455\n",
            "Precision: 0.9035473154002786\n",
            "Recall: 0.8803986710963455\n",
            "F1-score: 0.8787125621362376\n",
            "Training Time: 156.9871153831482\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Result Comparison and Analysis ðŸ“ˆ"
      ],
      "metadata": {
        "id": "5Svry9nRpSCr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_results = pd.DataFrame.from_dict(results, orient='index', columns=['Accuracy', 'Precision', 'Recall', 'F1-Score', 'Training Time'])\n",
        "\n",
        "df_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "BxPpTKIaZO8k",
        "outputId": "661e75fb-d06c-49af-8486-7f8d80606f1c"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          Accuracy  Precision    Recall  \\\n",
              "Logistic Regression                       0.880399   0.903547  0.880399   \n",
              "K-Nearest Neighbors (KNN)                 0.903654   0.911708  0.903654   \n",
              "Decision Trees                            0.860465   0.890988  0.860465   \n",
              "Random Forest                             0.853821   0.886975  0.853821   \n",
              "Extra Trees                               0.853821   0.886975  0.853821   \n",
              "Support Vector Machines                   0.853821   0.886975  0.853821   \n",
              "Neural Networks (Multi-layer Perceptron)  0.893688   0.912380  0.893688   \n",
              "AdaBoost                                  0.870432   0.897168  0.870432   \n",
              "XGBoost                                   0.870432   0.897168  0.870432   \n",
              "CatBoost                                  0.883721   0.905720  0.883721   \n",
              "Stochastic Gradient Descent (SGD)         0.880399   0.903547  0.880399   \n",
              "Neural Network                            0.880399   0.903547  0.880399   \n",
              "\n",
              "                                          F1-Score  Training Time  \n",
              "Logistic Regression                       0.878713       0.032453  \n",
              "K-Nearest Neighbors (KNN)                 0.903206       0.043700  \n",
              "Decision Trees                            0.857763       0.076415  \n",
              "Random Forest                             0.850704       0.660791  \n",
              "Extra Trees                               0.850704       0.499456  \n",
              "Support Vector Machines                   0.850704       0.266956  \n",
              "Neural Networks (Multi-layer Perceptron)  0.892511       5.046091  \n",
              "AdaBoost                                  0.868278       0.617636  \n",
              "XGBoost                                   0.868278       6.069358  \n",
              "CatBoost                                  0.882174      60.479728  \n",
              "Stochastic Gradient Descent (SGD)         0.878713       0.008234  \n",
              "Neural Network                            0.878713     156.987115  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a113c2ca-bd92-4e50-8e08-83598e3a51fd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1-Score</th>\n",
              "      <th>Training Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Logistic Regression</th>\n",
              "      <td>0.880399</td>\n",
              "      <td>0.903547</td>\n",
              "      <td>0.880399</td>\n",
              "      <td>0.878713</td>\n",
              "      <td>0.032453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>K-Nearest Neighbors (KNN)</th>\n",
              "      <td>0.903654</td>\n",
              "      <td>0.911708</td>\n",
              "      <td>0.903654</td>\n",
              "      <td>0.903206</td>\n",
              "      <td>0.043700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Decision Trees</th>\n",
              "      <td>0.860465</td>\n",
              "      <td>0.890988</td>\n",
              "      <td>0.860465</td>\n",
              "      <td>0.857763</td>\n",
              "      <td>0.076415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Random Forest</th>\n",
              "      <td>0.853821</td>\n",
              "      <td>0.886975</td>\n",
              "      <td>0.853821</td>\n",
              "      <td>0.850704</td>\n",
              "      <td>0.660791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Extra Trees</th>\n",
              "      <td>0.853821</td>\n",
              "      <td>0.886975</td>\n",
              "      <td>0.853821</td>\n",
              "      <td>0.850704</td>\n",
              "      <td>0.499456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Support Vector Machines</th>\n",
              "      <td>0.853821</td>\n",
              "      <td>0.886975</td>\n",
              "      <td>0.853821</td>\n",
              "      <td>0.850704</td>\n",
              "      <td>0.266956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Neural Networks (Multi-layer Perceptron)</th>\n",
              "      <td>0.893688</td>\n",
              "      <td>0.912380</td>\n",
              "      <td>0.893688</td>\n",
              "      <td>0.892511</td>\n",
              "      <td>5.046091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AdaBoost</th>\n",
              "      <td>0.870432</td>\n",
              "      <td>0.897168</td>\n",
              "      <td>0.870432</td>\n",
              "      <td>0.868278</td>\n",
              "      <td>0.617636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGBoost</th>\n",
              "      <td>0.870432</td>\n",
              "      <td>0.897168</td>\n",
              "      <td>0.870432</td>\n",
              "      <td>0.868278</td>\n",
              "      <td>6.069358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CatBoost</th>\n",
              "      <td>0.883721</td>\n",
              "      <td>0.905720</td>\n",
              "      <td>0.883721</td>\n",
              "      <td>0.882174</td>\n",
              "      <td>60.479728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Stochastic Gradient Descent (SGD)</th>\n",
              "      <td>0.880399</td>\n",
              "      <td>0.903547</td>\n",
              "      <td>0.880399</td>\n",
              "      <td>0.878713</td>\n",
              "      <td>0.008234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Neural Network</th>\n",
              "      <td>0.880399</td>\n",
              "      <td>0.903547</td>\n",
              "      <td>0.880399</td>\n",
              "      <td>0.878713</td>\n",
              "      <td>156.987115</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a113c2ca-bd92-4e50-8e08-83598e3a51fd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a113c2ca-bd92-4e50-8e08-83598e3a51fd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a113c2ca-bd92-4e50-8e08-83598e3a51fd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-89a7cdcf-6f77-4c90-88bc-e26fb14dfb25\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-89a7cdcf-6f77-4c90-88bc-e26fb14dfb25')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-89a7cdcf-6f77-4c90-88bc-e26fb14dfb25 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_50d4fd47-2007-4c9e-bdde-6384b7f1565d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_results')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_50d4fd47-2007-4c9e-bdde-6384b7f1565d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_results');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_results",
              "summary": "{\n  \"name\": \"df_results\",\n  \"rows\": 12,\n  \"fields\": [\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01627567935404104,\n        \"min\": 0.8538205980066446,\n        \"max\": 0.9036544850498339,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.8803986710963455,\n          0.9036544850498339,\n          0.8704318936877077\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.009304341514488064,\n        \"min\": 0.8869746891803952,\n        \"max\": 0.9123799788251615,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.9035473154002786,\n          0.911707712931703,\n          0.8971681695934187\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01627567935404104,\n        \"min\": 0.8538205980066446,\n        \"max\": 0.9036544850498339,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.8803986710963455,\n          0.9036544850498339,\n          0.8704318936877077\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1-Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0171174195661583,\n        \"min\": 0.8507043704447707,\n        \"max\": 0.9032058745435307,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.8787125621362376,\n          0.9032058745435307,\n          0.8682781656175076\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Training Time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 46.63943955509955,\n        \"min\": 0.008233785629272461,\n        \"max\": 156.9871153831482,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          0.008233785629272461,\n          60.47972798347473,\n          0.032453060150146484\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analysing Best Performing Model - Linear Discriminant Analysis (LDA)"
      ],
      "metadata": {
        "id": "5CwALZoTpgOm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "\n",
        "# Convert SparseTensor to dense numpy arrays\n",
        "X_train_dense = X_train.toarray()\n",
        "X_test_dense = X_test.toarray()\n",
        "\n",
        "# Initialize Linear Discriminant Analysis (LDA)\n",
        "lda = LinearDiscriminantAnalysis()\n",
        "\n",
        "# Train the classifier\n",
        "start_time = time.time()\n",
        "lda.fit(X_train_dense, y_train)\n",
        "training_time = time.time() - start_time\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = lda.predict(X_test_dense)\n",
        "\n",
        "# Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"Training Time:\", training_time)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHigg7lQpqu4",
        "outputId": "3868fdd2-ea20-40c5-82a0-bdf9e6b3adb2"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9269102990033222\n",
            "Precision: 0.9331301676117203\n",
            "Recall: 0.9269102990033222\n",
            "F1-score: 0.9266626525277157\n",
            "Training Time: 3.5697526931762695\n",
            "CPU times: user 6.2 s, sys: 590 ms, total: 6.79 s\n",
            "Wall time: 3.64 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bc_aBu5pxyU",
        "outputId": "efbf78f2-4e1b-4fcc-9d2f-e36cb3d2f4e1"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.87      0.92       151\n",
            "           1       0.88      0.99      0.93       150\n",
            "\n",
            "    accuracy                           0.93       301\n",
            "   macro avg       0.93      0.93      0.93       301\n",
            "weighted avg       0.93      0.93      0.93       301\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confusion Matrix-"
      ],
      "metadata": {
        "id": "_qxMzBIYp6-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Define class labels\n",
        "classes = ['0', '1']\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.colorbar()\n",
        "tick_marks = np.arange(len(classes))\n",
        "plt.xticks(tick_marks, classes, rotation=45)\n",
        "plt.yticks(tick_marks, classes)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "\n",
        "# Fill the cells of the confusion matrix with values\n",
        "thresh = cm.max() / 2.\n",
        "for i in range(cm.shape[0]):\n",
        "    for j in range(cm.shape[1]):\n",
        "        plt.text(j, i, format(cm[i, j], 'd'),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 601
        },
        "id": "D97HTxxOp5tk",
        "outputId": "45e0b64f-1846-4633-aa10-19c7a651010b"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Iterate over each classifier\n",
        "classifiers = {\n",
        "    'Logistic Regression': logistic,\n",
        "    'K-Nearest Neighbors (KNN)': knn,\n",
        "    'Gaussian Naive Bayes': gnb,\n",
        "    'Decision Trees': dt,\n",
        "    'Random Forest': rf,\n",
        "    'Extra Trees': et,\n",
        "    'Support Vector Machines': svm,\n",
        "    'Neural Networks (Multi-layer Perceptron)': mlp,\n",
        "    'AdaBoost': ada,\n",
        "    'XGBoost': xgboost,\n",
        "    'LightGBM': lgbm,\n",
        "    'CatBoost': cat,\n",
        "    'Stochastic Gradient Descent (SGD)': sgd,\n",
        "    'Linear Discriminant Analysis': lda,\n",
        "    'Quadratic Discriminant Analysis': qda,\n",
        "    'Neural Network': model\n",
        "}\n",
        "\n",
        "for name, classifier in classifiers.items():\n",
        "    try:\n",
        "        # Predict using the classifier\n",
        "        if name == 'Neural Network':  # For neural network model\n",
        "            # Convert SparseTensor to dense numpy arrays\n",
        "            X_test_dense = X_test.toarray()\n",
        "            y_pred = np.round(classifier.predict(X_test_dense)).flatten()\n",
        "        elif name == 'LightGBM':\n",
        "            # Predict using LightGBM model directly\n",
        "            y_pred = classifier.predict(X_test)\n",
        "        else:\n",
        "            # Convert TF-IDF transformed sparse matrices to dense numpy arrays\n",
        "            X_test_dense = X_test.toarray()\n",
        "            y_pred = classifier.predict(X_test_dense)\n",
        "\n",
        "        # Get indices of rows predicted as hate speech\n",
        "        hate_speech_indices = np.where(y_pred == 1)[0]\n",
        "\n",
        "        # Get the rows of speeches predicted as hate speech\n",
        "        hate_speech_rows = df1.iloc[hate_speech_indices]\n",
        "\n",
        "        # Display the hate speech rows\n",
        "        print(f\"Hate speech detected by {name} classifier:\")\n",
        "        print(hate_speech_rows)\n",
        "\n",
        "        # Save the hate speech rows to a CSV file\n",
        "        hate_speech_rows.to_csv(f\"/content/drive/MyDrive/Colab Notebooks/{name}_hate_speech.csv\", index=False)\n",
        "    except AttributeError:\n",
        "        print(f\"AttributeError: Cannot predict using {name}.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXZ-ElHbqkc7",
        "outputId": "dab4f853-7417-4e6f-fba4-aa9007d755e7"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hate speech detected by Logistic Regression classifier:\n",
            "                                                speech  class\n",
            "0    In comparison to cases of violence in Italy ma...      1\n",
            "2       Unfortunately, many Italians commit rapes too.      1\n",
            "3    I don't want to have anything to do with the I...      0\n",
            "4    The statistics state that the rapists are almo...      1\n",
            "5    Violence against women is a problem that does ...      1\n",
            "..                                                 ...    ...\n",
            "292  Are you worried that Italians may have competi...      1\n",
            "293  I do not understand why you perceive this risk...      1\n",
            "294  I am an Italian woman, and I feel neither a pr...      1\n",
            "295  The imposition of the burqa regards the most e...      1\n",
            "298  The respect for each other born like this, acc...      1\n",
            "\n",
            "[186 rows x 2 columns]\n",
            "Hate speech detected by K-Nearest Neighbors (KNN) classifier:\n",
            "                                                speech  class\n",
            "0    In comparison to cases of violence in Italy ma...      1\n",
            "2       Unfortunately, many Italians commit rapes too.      1\n",
            "4    The statistics state that the rapists are almo...      1\n",
            "5    Violence against women is a problem that does ...      1\n",
            "8    The Muslims? Which? All? This statement is mad...      1\n",
            "..                                                 ...    ...\n",
            "292  Are you worried that Italians may have competi...      1\n",
            "293  I do not understand why you perceive this risk...      1\n",
            "294  I am an Italian woman, and I feel neither a pr...      1\n",
            "295  The imposition of the burqa regards the most e...      1\n",
            "298  The respect for each other born like this, acc...      1\n",
            "\n",
            "[171 rows x 2 columns]\n",
            "Hate speech detected by Gaussian Naive Bayes classifier:\n",
            "                                                speech  class\n",
            "0    In comparison to cases of violence in Italy ma...      1\n",
            "2       Unfortunately, many Italians commit rapes too.      1\n",
            "3    I don't want to have anything to do with the I...      0\n",
            "4    The statistics state that the rapists are almo...      1\n",
            "5    Violence against women is a problem that does ...      1\n",
            "..                                                 ...    ...\n",
            "292  Are you worried that Italians may have competi...      1\n",
            "293  I do not understand why you perceive this risk...      1\n",
            "294  I am an Italian woman, and I feel neither a pr...      1\n",
            "295  The imposition of the burqa regards the most e...      1\n",
            "298  The respect for each other born like this, acc...      1\n",
            "\n",
            "[174 rows x 2 columns]\n",
            "Hate speech detected by Decision Trees classifier:\n",
            "                                                speech  class\n",
            "0    In comparison to cases of violence in Italy ma...      1\n",
            "2       Unfortunately, many Italians commit rapes too.      1\n",
            "3    I don't want to have anything to do with the I...      0\n",
            "4    The statistics state that the rapists are almo...      1\n",
            "5    Violence against women is a problem that does ...      1\n",
            "..                                                 ...    ...\n",
            "292  Are you worried that Italians may have competi...      1\n",
            "293  I do not understand why you perceive this risk...      1\n",
            "294  I am an Italian woman, and I feel neither a pr...      1\n",
            "295  The imposition of the burqa regards the most e...      1\n",
            "298  The respect for each other born like this, acc...      1\n",
            "\n",
            "[192 rows x 2 columns]\n",
            "Hate speech detected by Random Forest classifier:\n",
            "                                                speech  class\n",
            "0    In comparison to cases of violence in Italy ma...      1\n",
            "2       Unfortunately, many Italians commit rapes too.      1\n",
            "3    I don't want to have anything to do with the I...      0\n",
            "4    The statistics state that the rapists are almo...      1\n",
            "5    Violence against women is a problem that does ...      1\n",
            "..                                                 ...    ...\n",
            "292  Are you worried that Italians may have competi...      1\n",
            "293  I do not understand why you perceive this risk...      1\n",
            "294  I am an Italian woman, and I feel neither a pr...      1\n",
            "295  The imposition of the burqa regards the most e...      1\n",
            "298  The respect for each other born like this, acc...      1\n",
            "\n",
            "[194 rows x 2 columns]\n",
            "Hate speech detected by Extra Trees classifier:\n",
            "                                                speech  class\n",
            "0    In comparison to cases of violence in Italy ma...      1\n",
            "2       Unfortunately, many Italians commit rapes too.      1\n",
            "3    I don't want to have anything to do with the I...      0\n",
            "4    The statistics state that the rapists are almo...      1\n",
            "5    Violence against women is a problem that does ...      1\n",
            "..                                                 ...    ...\n",
            "292  Are you worried that Italians may have competi...      1\n",
            "293  I do not understand why you perceive this risk...      1\n",
            "294  I am an Italian woman, and I feel neither a pr...      1\n",
            "295  The imposition of the burqa regards the most e...      1\n",
            "298  The respect for each other born like this, acc...      1\n",
            "\n",
            "[194 rows x 2 columns]\n",
            "Hate speech detected by Support Vector Machines classifier:\n",
            "                                                speech  class\n",
            "0    In comparison to cases of violence in Italy ma...      1\n",
            "2       Unfortunately, many Italians commit rapes too.      1\n",
            "3    I don't want to have anything to do with the I...      0\n",
            "4    The statistics state that the rapists are almo...      1\n",
            "5    Violence against women is a problem that does ...      1\n",
            "..                                                 ...    ...\n",
            "292  Are you worried that Italians may have competi...      1\n",
            "293  I do not understand why you perceive this risk...      1\n",
            "294  I am an Italian woman, and I feel neither a pr...      1\n",
            "295  The imposition of the burqa regards the most e...      1\n",
            "298  The respect for each other born like this, acc...      1\n",
            "\n",
            "[194 rows x 2 columns]\n",
            "Hate speech detected by Neural Networks (Multi-layer Perceptron) classifier:\n",
            "                                                speech  class\n",
            "0    In comparison to cases of violence in Italy ma...      1\n",
            "2       Unfortunately, many Italians commit rapes too.      1\n",
            "3    I don't want to have anything to do with the I...      0\n",
            "4    The statistics state that the rapists are almo...      1\n",
            "5    Violence against women is a problem that does ...      1\n",
            "..                                                 ...    ...\n",
            "292  Are you worried that Italians may have competi...      1\n",
            "293  I do not understand why you perceive this risk...      1\n",
            "294  I am an Italian woman, and I feel neither a pr...      1\n",
            "295  The imposition of the burqa regards the most e...      1\n",
            "298  The respect for each other born like this, acc...      1\n",
            "\n",
            "[182 rows x 2 columns]\n",
            "Hate speech detected by AdaBoost classifier:\n",
            "                                                speech  class\n",
            "0    In comparison to cases of violence in Italy ma...      1\n",
            "2       Unfortunately, many Italians commit rapes too.      1\n",
            "3    I don't want to have anything to do with the I...      0\n",
            "4    The statistics state that the rapists are almo...      1\n",
            "5    Violence against women is a problem that does ...      1\n",
            "..                                                 ...    ...\n",
            "292  Are you worried that Italians may have competi...      1\n",
            "293  I do not understand why you perceive this risk...      1\n",
            "294  I am an Italian woman, and I feel neither a pr...      1\n",
            "295  The imposition of the burqa regards the most e...      1\n",
            "298  The respect for each other born like this, acc...      1\n",
            "\n",
            "[189 rows x 2 columns]\n",
            "Hate speech detected by XGBoost classifier:\n",
            "                                                speech  class\n",
            "0    In comparison to cases of violence in Italy ma...      1\n",
            "1         Muslims rape our women and must be neutered.      0\n",
            "2       Unfortunately, many Italians commit rapes too.      1\n",
            "3    I don't want to have anything to do with the I...      0\n",
            "4    The statistics state that the rapists are almo...      1\n",
            "..                                                 ...    ...\n",
            "296         They want to impose the veil on all of us.      0\n",
            "297         They want to impose the veil on all of us.      0\n",
            "298  The respect for each other born like this, acc...      1\n",
            "299       Muslims rape our women and must be neutered.      0\n",
            "300                       They will blow all of us up.      0\n",
            "\n",
            "[301 rows x 2 columns]\n",
            "AttributeError: Cannot predict using LightGBM.\n",
            "Hate speech detected by CatBoost classifier:\n",
            "                                                speech  class\n",
            "0    In comparison to cases of violence in Italy ma...      1\n",
            "2       Unfortunately, many Italians commit rapes too.      1\n",
            "4    The statistics state that the rapists are almo...      1\n",
            "5    Violence against women is a problem that does ...      1\n",
            "8    The Muslims? Which? All? This statement is mad...      1\n",
            "..                                                 ...    ...\n",
            "292  Are you worried that Italians may have competi...      1\n",
            "293  I do not understand why you perceive this risk...      1\n",
            "294  I am an Italian woman, and I feel neither a pr...      1\n",
            "295  The imposition of the burqa regards the most e...      1\n",
            "298  The respect for each other born like this, acc...      1\n",
            "\n",
            "[185 rows x 2 columns]\n",
            "Hate speech detected by Stochastic Gradient Descent (SGD) classifier:\n",
            "                                                speech  class\n",
            "0    In comparison to cases of violence in Italy ma...      1\n",
            "2       Unfortunately, many Italians commit rapes too.      1\n",
            "3    I don't want to have anything to do with the I...      0\n",
            "4    The statistics state that the rapists are almo...      1\n",
            "5    Violence against women is a problem that does ...      1\n",
            "..                                                 ...    ...\n",
            "292  Are you worried that Italians may have competi...      1\n",
            "293  I do not understand why you perceive this risk...      1\n",
            "294  I am an Italian woman, and I feel neither a pr...      1\n",
            "295  The imposition of the burqa regards the most e...      1\n",
            "298  The respect for each other born like this, acc...      1\n",
            "\n",
            "[186 rows x 2 columns]\n",
            "Hate speech detected by Linear Discriminant Analysis classifier:\n",
            "                                                speech  class\n",
            "0    In comparison to cases of violence in Italy ma...      1\n",
            "2       Unfortunately, many Italians commit rapes too.      1\n",
            "3    I don't want to have anything to do with the I...      0\n",
            "4    The statistics state that the rapists are almo...      1\n",
            "5    Violence against women is a problem that does ...      1\n",
            "..                                                 ...    ...\n",
            "292  Are you worried that Italians may have competi...      1\n",
            "293  I do not understand why you perceive this risk...      1\n",
            "294  I am an Italian woman, and I feel neither a pr...      1\n",
            "295  The imposition of the burqa regards the most e...      1\n",
            "298  The respect for each other born like this, acc...      1\n",
            "\n",
            "[168 rows x 2 columns]\n",
            "Hate speech detected by Quadratic Discriminant Analysis classifier:\n",
            "                                                speech  class\n",
            "0    In comparison to cases of violence in Italy ma...      1\n",
            "2       Unfortunately, many Italians commit rapes too.      1\n",
            "4    The statistics state that the rapists are almo...      1\n",
            "5    Violence against women is a problem that does ...      1\n",
            "8    The Muslims? Which? All? This statement is mad...      1\n",
            "..                                                 ...    ...\n",
            "292  Are you worried that Italians may have competi...      1\n",
            "293  I do not understand why you perceive this risk...      1\n",
            "294  I am an Italian woman, and I feel neither a pr...      1\n",
            "295  The imposition of the burqa regards the most e...      1\n",
            "298  The respect for each other born like this, acc...      1\n",
            "\n",
            "[150 rows x 2 columns]\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "Hate speech detected by Neural Network classifier:\n",
            "                                                speech  class\n",
            "0    In comparison to cases of violence in Italy ma...      1\n",
            "2       Unfortunately, many Italians commit rapes too.      1\n",
            "3    I don't want to have anything to do with the I...      0\n",
            "4    The statistics state that the rapists are almo...      1\n",
            "5    Violence against women is a problem that does ...      1\n",
            "..                                                 ...    ...\n",
            "292  Are you worried that Italians may have competi...      1\n",
            "293  I do not understand why you perceive this risk...      1\n",
            "294  I am an Italian woman, and I feel neither a pr...      1\n",
            "295  The imposition of the burqa regards the most e...      1\n",
            "298  The respect for each other born like this, acc...      1\n",
            "\n",
            "[186 rows x 2 columns]\n"
          ]
        }
      ]
    }
  ]
}